# 文档: 01【prompt engineering】Understanding LLMs and Basic Prompting Techniques 总结要点

## 1. LLM 核心概念理解
- **定义**: 基于 Transformer 架构、训练于海量文本数据的人工智能模型，具备自然语言理解和生成能力
- **核心机制**: 通过预测文本序列中的下一个可能词来生成连贯输出
- **关键特性**:
  - 上下文感知能力
  - 泛化到多种语言任务
  - 受限于训练数据（知识截止日期）和上下文窗口长度

## 2. 提示工程基础概念
- **提示**: 与 LLM 交互的输入文本，用于引导模型产生预期输出
- **提示结构**: 典型包含三部分：指令（要做什么） + 上下文（参考信息） + 输入示例（可选）
- **核心目标**: 减少模型的模糊性，提高输出的准确性和相关性

## 3. 基础提示技术
- **Zero-Shot Prompting**: 无需示例，直接让模型完成任务（依赖其预训练知识）
  - 示例："解释什么是机器学习"
- **Few-Shot Prompting**: 提供少量示例后让模型执行任务
  - 示例："猫喜欢吃鱼 → 英文是 Cats like fish；狗喜欢骨头 → Dogs like bones；请翻译：鸟喜欢唱歌"
- **Explicit Prompting**: 明确指定输出格式和要求
  - 示例："总结以下文本，并以 bullet points 列出要点：[文本内容]"

## 4. 基础设计原则
- **清晰具体**: 避免模糊表述，明确任务类型、格式和约束
- **提供上下文**: 补充必要的背景信息或参考数据
- **结果导向**: 直接说明期望的输出效果

## 5. 常见误区与注意事项
- 避免假设模型知道所有信息（注意知识截止日期）
- 不要在一个提示中包含过多任务
