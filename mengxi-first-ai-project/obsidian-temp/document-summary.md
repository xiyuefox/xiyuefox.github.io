# 文档: 01【prompt engineering】Understanding LLMs and Basic Prompting Techniques 总结要点

## 第一部分: LLM 基础理解
1. **LLM 定义**: 大语言模型是训练于海量文本数据的 AI 系统，能够理解和生成人类语言。
2. **核心能力**:
   - 自然语言理解 (NLU): 解析文本含义、意图和情感
   - 自然语言生成 (NLG): 创建连贯、相关的文本输出
3. **工作原理**: 基于统计模式识别，预测文本序列中的下一个最可能的词
4. **上下文窗口**: LLM 能够处理的最大文本长度限制（如 GPT-3.5 为 4k/16k tokens）

## 第二部分: 提示工程基础
1. **提示定义**: 与 LLM 交互的输入文本，用于引导模型产生预期输出
2. **基本结构**: 通常包含指令 (Instruction) + 上下文 (Context) + 输入 (Input) + 输出格式 (Output Format)
3. **核心目标**: 最大化模型输出的相关性、准确性和有用性
4. **关键原则**:
   - 清晰具体 (Clarity): 避免模糊术语
   - 完整性 (Completeness): 提供所有必要信息
   - 相关性 (Relevance): 仅包含与任务相关的内容
5. **基础技巧**:
   - 使用明确指令（如 "总结"、"翻译"、"解释"）
   - 提供上下文和示例
   - 规定输出格式（如列表、JSON、段落）

## 第三部分: 常见应用场景
1. 文本生成（写作、代码、创意内容）
2. 信息提取（摘要、关键词、实体识别）
3. 语言翻译
4. 问答系统
5. 代码辅助

## 第四部分: 初始实践建议
1. 从简单提示开始，逐步增加复杂度
2. 始终测试和迭代提示设计
3. 考虑模型的上下文窗口限制
4. 避免假设模型拥有最新或专有信息
