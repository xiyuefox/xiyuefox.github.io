<!doctype html><html lang=zh-cn><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><title>（）-Text Classification with Natural Language Processing | Mengxi's Blog</title><meta name=title content="（）-Text Classification with Natural Language Processing | Mengxi's Blog"><meta name=description content="Introduction and Text Data Collection
Welcome to today&rsquo;s lesson! As data science and machine learning professionals, particularly in the Natural Language Processing (NLP) field, we often deal with textual data. Today, we dive into the &lsquo;Introduction to Textual Data Collection&rsquo;. Specifically, we&rsquo;ll explore how to collect, understand and analyze text data using Python.
Textual data is usually unstructured, being much harder to analyze than structured data. It can take many forms, such as emails, social media posts, books, or transcripts of conversations. Understanding how to handle such data is a critical part of building effective machine learning models, especially for text classification tasks where we &lsquo;classify&rsquo; or categorize texts. The quality of the data we use for these tasks is of utmost importance. Better, well-structured data leads to models that perform better."><meta property="og:type" content="article"><meta property="og:url" content="https://mengxi.space/posts/misc/e000-cong-arc-da-kai-text-classification-with-natural-language-processing/"><meta property="og:title" content="（）-Text Classification with Natural Language Processing"><meta property="og:description" content="Introduction and Text Data Collection
Welcome to today&rsquo;s lesson! As data science and machine learning professionals, particularly in the Natural Language Processing (NLP) field, we often deal with textual data. Today, we dive into the &lsquo;Introduction to Textual Data Collection&rsquo;. Specifically, we&rsquo;ll explore how to collect, understand and analyze text data using Python.
Textual data is usually unstructured, being much harder to analyze than structured data. It can take many forms, such as emails, social media posts, books, or transcripts of conversations. Understanding how to handle such data is a critical part of building effective machine learning models, especially for text classification tasks where we &lsquo;classify&rsquo; or categorize texts. The quality of the data we use for these tasks is of utmost importance. Better, well-structured data leads to models that perform better."><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://mengxi.space/posts/misc/e000-cong-arc-da-kai-text-classification-with-natural-language-processing/"><meta property="twitter:title" content="（）-Text Classification with Natural Language Processing"><meta property="twitter:description" content="Introduction and Text Data Collection
Welcome to today&rsquo;s lesson! As data science and machine learning professionals, particularly in the Natural Language Processing (NLP) field, we often deal with textual data. Today, we dive into the &lsquo;Introduction to Textual Data Collection&rsquo;. Specifically, we&rsquo;ll explore how to collect, understand and analyze text data using Python.
Textual data is usually unstructured, being much harder to analyze than structured data. It can take many forms, such as emails, social media posts, books, or transcripts of conversations. Understanding how to handle such data is a critical part of building effective machine learning models, especially for text classification tasks where we &lsquo;classify&rsquo; or categorize texts. The quality of the data we use for these tasks is of utmost importance. Better, well-structured data leads to models that perform better."><link href=https://fonts.googleapis.com rel=preconnect><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;600;700&family=Noto+Sans+SC:wght@300;400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel=stylesheet><link rel=icon type=image/png sizes=32x32 href=/%20images/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/%20images/favicon-16x16.png><link rel=stylesheet href=/%20css/unified-styles.css><style>body{opacity:0;animation:fadeInPage .5s ease-out forwards}@keyframes fadeInPage{from{opacity:0}to{opacity:1}}</style></head><body class=theme-knowledge><nav class=u-nav id=top-nav><a href=/ class=u-nav__brand><span style="border:1px solid #fff;padding:0 4px;color:#fff;background:0 0">Y</span>
Mengxi News</a><ul class=u-nav__links><li><a href=/posts class=u-nav__link>new</a></li><li><a href=/graph class=u-nav__link>graph</a></li><li><a href=/timeline class=u-nav__link>timeline</a></li><li><a href=/search class=u-nav__link>search</a></li></ul></nav><main class="u-container u-py-xl"><header class="u-text-center u-mb-xl"><h1>（）-Text Classification with Natural Language Processing</h1><div class="u-flex u-justify-center u-gap-md u-text-light"><span>Dec 15, 2025</span>
<span>•</span>
<span>122 min read</span></div></header><article class=u-card style="max-width:800px;margin:0 auto"><div class=content><h2 id=introduction-and-text-data-collection>Introduction and Text Data Collection</h2><p>Welcome to today&rsquo;s lesson! As data science and machine learning professionals, particularly in the Natural Language Processing (NLP) field, we often deal with textual data. Today, we dive into the &lsquo;Introduction to Textual Data Collection&rsquo;. Specifically, we&rsquo;ll explore how to collect, understand and analyze text data using <code>Python</code>.</p><p>Textual data is usually unstructured, being much harder to analyze than structured data. It can take many forms, such as emails, social media posts, books, or transcripts of conversations. Understanding how to handle such data is a critical part of building effective machine learning models, especially for text classification tasks where we &lsquo;classify&rsquo; or categorize texts. The quality of the data we use for these tasks is of utmost importance. Better, well-structured data leads to models that perform better.</p><h5 id=the-20-newsgroups-dataset>The 20 Newsgroups Dataset</h5><p>The dataset we&rsquo;ll be working with in today&rsquo;s lesson is the <strong>20 Newsgroups dataset</strong>. For some historical background, newsgroups were the precursors to modern internet forums, where people gathered to discuss specific topics. In our case, the dataset consists of approximately 20,000 documents from newsgroup discussions. These texts were originally exchanged through Usenet, a global discussion system that predates many modern Internet forums.</p><p>The dataset is divided nearly evenly across 20 different newsgroups, each corresponding to a separate topic - this segmentation is one of the main reasons why it is especially useful for text classification tasks. The separation of data makes it excellent for training models to distinguish between different classes, or in our case, newsgroup topics.</p><p>From science and religion to politics and sports, the topics covered provide a diversified range of discussions. This diversity adds another layer of complexity and richness, similar to what we might experience with real-world data.</p><h5 id=fetching-and-understanding-the-data-structure>Fetching and Understanding the Data Structure</h5><p>To load this dataset, we use the <code>fetch_20newsgroups()</code> function from the <code>sklearn.datasets</code> module in Python. This function retrieves the 20 newsgroup dataset in a format that&rsquo;s useful for machine learning purposes. Let&rsquo;s fetch and examine the dataset.</p><p>First, let&rsquo;s import the necessary libraries and fetch the data:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>`</span><span class=mi>1</span><span class=c1># Importing necessary libraries 2from sklearn.datasets import fetch_20newsgroups 3 4# Fetch data 5newsgroups = fetch_20newsgroups(subset=&#39;all&#39;)`</span>
</span></span></code></pre></td></tr></table></div></div><p>The datasets fetched from sklearn typically have three attributes—<code>data</code>, <code>target</code>, and <code>target_names</code>. <code>data</code> refers to the actual content, <code>target</code> refers to the labels for the texts, and <code>target_names</code> provides names for the target labels.</p><p>Next, let&rsquo;s understand the structure of the fetched data:</p><p>Python</p><p>CopyPlay</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>`</span><span class=mi>1</span><span class=c1># Understanding the structure of the data 2print(&#34;\n\nData Structure\n-------------&#34;) 3print(f&#39;Type of data: {type(newsgroups.data)}&#39;) 4print(f&#39;Type of target: {type(newsgroups.target)}&#39;)`</span>
</span></span></code></pre></td></tr></table></div></div><p>We are fetching the data and observing the type of the <code>data</code> and <code>target</code>. The <code>type of data</code> tells us what kind of data structure is used to store the text data while the <code>type of target</code> shouts what type of structure is used to store the labels. Here is what the output looks like:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>`</span><span class=mi>1</span><span class=n>Data</span> <span class=n>Structure</span> <span class=mi>2</span><span class=o>-------------</span> <span class=mi>3</span><span class=n>Type</span> <span class=n>of</span> <span class=n>data</span><span class=p>:</span> <span class=o>&lt;</span><span class=k>class</span> <span class=err>&#39;</span><span class=nc>list</span><span class=s1>&#39;&gt; 4Type of target: &lt;class &#39;</span><span class=n>numpy</span><span class=o>.</span><span class=n>ndarray</span><span class=s1>&#39;&gt;`</span>
</span></span></code></pre></td></tr></table></div></div><p>As printed out, the <code>data</code> is stored as a list, and <code>target</code> as a numpy array.</p><h5 id=diving-into-data-exploration>Diving Into Data Exploration</h5><p>Now, let&rsquo;s explore the data points, target variables and the potential classes in the dataset:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>`</span><span class=mi>1</span><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n\n</span><span class=s2>Data Exploration</span><span class=se>\n</span><span class=s2>----------------&#34;</span><span class=p>)</span> <span class=mi>2</span><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Number of datapoints: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>data</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span> <span class=mi>3</span><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Number of target variables: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span> <span class=mi>4</span><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Possible classes: </span><span class=si>{</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span><span class=err>`</span>
</span></span></code></pre></td></tr></table></div></div><p>We get the length of the <code>data</code> list to fetch the number of data points. Also, we get the length of the <code>target</code> array. Lastly, we fetch the possible classes or newsgroups in the dataset. Here is what we get:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>`</span><span class=mi>1</span><span class=n>Data</span> <span class=n>Exploration</span> <span class=mi>2</span><span class=o>----------------</span> <span class=mi>3</span><span class=n>Number</span> <span class=n>of</span> <span class=n>datapoints</span><span class=p>:</span> <span class=mi>18846</span> <span class=mi>4</span><span class=n>Number</span> <span class=n>of</span> <span class=n>target</span> <span class=n>variables</span><span class=p>:</span> <span class=mi>18846</span> <span class=mi>5</span><span class=n>Possible</span> <span class=n>classes</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;alt.atheism&#39;</span><span class=p>,</span> <span class=s1>&#39;comp.graphics&#39;</span><span class=p>,</span> <span class=s1>&#39;comp.os.ms-windows.misc&#39;</span><span class=p>,</span> <span class=s1>&#39;comp.sys.ibm.pc.hardware&#39;</span><span class=p>,</span> <span class=s1>&#39;comp.sys.mac.hardware&#39;</span><span class=p>,</span> <span class=s1>&#39;comp.windows.x&#39;</span><span class=p>,</span> <span class=s1>&#39;misc.forsale&#39;</span><span class=p>,</span> <span class=s1>&#39;rec.autos&#39;</span><span class=p>,</span> <span class=s1>&#39;rec.motorcycles&#39;</span><span class=p>,</span> <span class=s1>&#39;rec.sport.baseball&#39;</span><span class=p>,</span> <span class=s1>&#39;rec.sport.hockey&#39;</span><span class=p>,</span> <span class=s1>&#39;sci.crypt&#39;</span><span class=p>,</span> <span class=s1>&#39;sci.electronics&#39;</span><span class=p>,</span> <span class=s1>&#39;sci.med&#39;</span><span class=p>,</span> <span class=s1>&#39;sci.space&#39;</span><span class=p>,</span> <span class=s1>&#39;soc.religion.christian&#39;</span><span class=p>,</span> <span class=s1>&#39;talk.politics.guns&#39;</span><span class=p>,</span> <span class=s1>&#39;talk.politics.mideast&#39;</span><span class=p>,</span> <span class=s1>&#39;talk.politics.misc&#39;</span><span class=p>,</span> <span class=s1>&#39;talk.religion.misc&#39;</span><span class=p>]</span><span class=err>`</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=sample-data-preview>Sample Data Preview</h5><p>Lastly, let&rsquo;s fetch and understand what a sample data point and its corresponding label looks like:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>`</span><span class=mi>1</span><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n\n</span><span class=s2>Sample datapoint</span><span class=se>\n</span><span class=s2>----------------&#34;</span><span class=p>)</span> <span class=mi>2</span><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>Article:</span><span class=se>\n</span><span class=s1>-------</span><span class=se>\n</span><span class=si>{</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=mi>10</span><span class=p>]</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span> <span class=mi>3</span><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>Corresponding Topic:</span><span class=se>\n</span><span class=s1>------------------</span><span class=se>\n</span><span class=si>{</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>[</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target</span><span class=p>[</span><span class=mi>10</span><span class=p>]]</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span><span class=err>`</span>
</span></span></code></pre></td></tr></table></div></div><p>The <code>Article</code> fetched is the 10th article in the dataset and <code>Corresponding Topic</code> is the actual topic that the article belongs to. Here&rsquo;s the output:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>`</span><span class=mi>1</span><span class=n>Sample</span> <span class=n>datapoint</span> <span class=mi>2</span><span class=o>----------------</span> <span class=mi>3</span> <span class=mi>4</span><span class=n>Article</span><span class=p>:</span> <span class=mi>5</span><span class=o>-------</span> <span class=mi>6</span><span class=n>From</span><span class=p>:</span> <span class=n>sandvik</span><span class=nd>@newton.apple.com</span> <span class=p>(</span><span class=n>Kent</span> <span class=n>Sandvik</span><span class=p>)</span> <span class=mi>7</span><span class=n>Subject</span><span class=p>:</span> <span class=n>Re</span><span class=p>:</span> <span class=mi>14</span> <span class=n>Apr</span> <span class=mi>93</span>   <span class=n>God</span><span class=s1>&#39;s Promise in 1 John 1: 7 8Organization: Cookamunga Tourist Bureau 9Lines: 17 10 11In article &lt;1qknu0INNbhv@shelley.u.washington.edu&gt;, &gt; Christian:  washed in 12the blood of the lamb. 13&gt; Mithraist:  washed in the blood of the bull. 14&gt;  15&gt; If anyone in .netland is in the process of devising a new religion, 16&gt; do not use the lamb or the bull, because they have already been 17&gt; reserved.  Please choose another animal, preferably one not 18&gt; on the Endangered Species List.   19 20This will be a hard task, because most cultures used most animals 21for blood sacrifices. It has to be something related to our current 22post-modernism state. Hmm, what about used computers? 23 24Cheers, 25Kent 26--- 27sandvik@newton.apple.com. ALink: KSAND -- Private activities on the net. 28 29 30Corresponding Topic: 31------------------ 32talk.religion.misc`</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=lesson-summary>Lesson Summary</h5><p>Nice work! Through today&rsquo;s lesson, you&rsquo;ve learned to fetch and analyze text data for text classification. If you&rsquo;ve followed along, you should now understand the structure of text data and how to fetch and analyze it using Python.</p><p>But our journey to text classification is just starting. In upcoming lessons, we&rsquo;ll dive deeper into related topics such as cleaning textual data, handling missing values, and restructuring textual data for analysis. Each step forward improves your expertise in text classification. Keep going!</p><h2 id=practice1explore-more-of-the-20-newsgroups-dataset>「Practice1」Explore More of the 20 Newsgroups Dataset</h2><h2 id=practice2uncover-the-end-of-20-newsgroups-dataset>「Practice2」Uncover the End of 20 Newsgroups Dataset</h2><p>Celestial Traveler, your journey continues! Fill in the blanks (<code>____</code>) to import and explore our dataset. We aim to extract and display the <strong>last three articles</strong> and their corresponding <strong>topics</strong>. Can you reveal what&rsquo;s at the end of our dataset?</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>newsgroups</span> <span class=o>=</span> <span class=n>____</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch last three articles</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>last_three_articles</span> <span class=o>=</span> <span class=n>newsgroups</span><span class=o>.</span><span class=n>____</span><span class=p>[</span><span class=o>-</span><span class=mi>3</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the corresponding topics</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>corresponding_topics</span> <span class=o>=</span> <span class=p>[</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>newsgroups</span><span class=o>.</span><span class=n>____</span><span class=p>[</span><span class=o>-</span><span class=mi>3</span><span class=p>:]]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display Last three articles and their corresponding topics</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>Last article </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>last_three_articles</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Corresponding Topic </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>corresponding_topics</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>&ldquo;Here is the completed code to import and explore the dataset, extracting and displaying the last three articles and their corresponding topics.&rdquo;</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch last three articles</span>
</span></span><span class=line><span class=cl><span class=n>last_three_articles</span> <span class=o>=</span> <span class=n>newsgroups</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=o>-</span><span class=mi>3</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the corresponding topics</span>
</span></span><span class=line><span class=cl><span class=n>corresponding_topics</span> <span class=o>=</span> <span class=p>[</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>newsgroups</span><span class=o>.</span><span class=n>target</span><span class=p>[</span><span class=o>-</span><span class=mi>3</span><span class=p>:]]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display last three articles and their corresponding topics</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>Last article </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>last_three_articles</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Corresponding Topic </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>corresponding_topics</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=practice3fetch-specific-categories-from-dataset>「Practice3」Fetch Specific Categories from Dataset</h2><p>Celestial Traveler, let&rsquo;s narrow down our data collection. Modify the provided code to fetch only the <code>'alt.atheism'</code> and <code>'talk.religion.misc'</code> categories from our <strong>dataset</strong>. Then, display the first two articles from these categories along with their corresponding labels.<br>天体旅行者，让我们缩小数据收集范围。修改提供的代码，使其仅从我们的数据集中获取 <code>'alt.atheism'</code> 和 <code>'talk.religion.misc'</code> 类别。然后，显示来自这些类别的前两篇文章</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch a subset of the dataset containing selected categories. Update the categories as needed.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>newsgroups_subset</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>,</span> <span class=n>categories</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;comp.graphics&#39;</span><span class=p>,</span> <span class=s1>&#39;sci.space&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the first two articles and their corresponding topics from this subset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>Article </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>newsgroups_subset</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Corresponding Topic </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>newsgroups_subset</span><span class=o>.</span><span class=n>target_names</span><span class=p>[</span><span class=n>newsgroups_subset</span><span class=o>.</span><span class=n>target</span><span class=p>[</span><span class=n>i</span><span class=p>]]</span><span class=si>}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>&ldquo;Here is the modified code to fetch only the <code>'alt.atheism'</code> and <code>'talk.religion.misc'</code> categories from the dataset, and to display the first two articles along with their corresponding labels.&rdquo;</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch a subset of the dataset containing selected categories</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_subset</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>,</span> <span class=n>categories</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;alt.atheism&#39;</span><span class=p>,</span> <span class=s1>&#39;talk.religion.misc&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the first two articles and their corresponding topics from this subset</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>Article </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>newsgroups_subset</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Corresponding Topic </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>newsgroups_subset</span><span class=o>.</span><span class=n>target_names</span><span class=p>[</span><span class=n>newsgroups_subset</span><span class=o>.</span><span class=n>target</span><span class=p>[</span><span class=n>i</span><span class=p>]]</span><span class=si>}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>输出</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Article 1:  
</span></span><span class=line><span class=cl>From: agr00@ccc.amdahl.com (Anthony G Rose)  
</span></span><span class=line><span class=cl>Subject: Re: Who&#39;s next?  Mormons and Jews?  
</span></span><span class=line><span class=cl>Reply-To: agr00@JUTS.ccc.amdahl.com (Anthony G Rose)  
</span></span><span class=line><span class=cl>Organization: Amdahl Corporation, Sunnyvale CA  
</span></span><span class=line><span class=cl>Lines: 18  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>In article &lt;1993Apr20.142356.456@ra.royalroads.ca&gt; mlee@post.RoyalRoads.ca (Malcolm Lee) writes:  
</span></span><span class=line><span class=cl>&gt;  
</span></span><span class=line><span class=cl>&gt;In article &lt;C5rLps.Fr5@world.std.com&gt;, jhallen@world.std.com (Joseph H Allen) writes:  
</span></span><span class=line><span class=cl>&gt;|&gt; In article &lt;1qvk8sINN9vo@clem.handheld.com&gt; jmd@cube.handheld.com (Jim De Arras) writes:  
</span></span><span class=line><span class=cl>&gt;|&gt;   
</span></span><span class=line><span class=cl>&gt;|&gt; It was interesting to watch the 700 club today.  Pat Robertson said that the  
</span></span><span class=line><span class=cl>&gt;|&gt; &#34;Branch Dividians had met the firey end for worshipping their false god.&#34; He  
</span></span><span class=line><span class=cl>&gt;|&gt; also said that this was a terrible tragedy and that the FBI really blew it.  
</span></span><span class=line><span class=cl>&gt;  
</span></span><span class=line><span class=cl>&gt;I don&#39;t necessarily agree with Pat Robertson.  Every one will be placed before  
</span></span><span class=line><span class=cl>&gt;the judgement seat eventually and judged on what we have done or failed to do  
</span></span><span class=line><span class=cl>&gt;on this earth.  God allows people to choose who and what they want to worship.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>I&#39;m sorry, but He does not!  Ever read the FIRST commandment?  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>&gt;Worship of money is one of the greatest religions in this country.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>You mean, false religion!  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>Corresponding Topic 1:  
</span></span><span class=line><span class=cl>talk.religion.misc  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>Article 2:  
</span></span><span class=line><span class=cl>From: frank@D012S658.uucp (Frank O&#39;Dwyer)  
</span></span><span class=line><span class=cl>Subject: Re: Tieing Abortion to Health Reform -- Is Clinton Nuts?  
</span></span><span class=line><span class=cl>Organization: Siemens-Nixdorf AG  
</span></span><span class=line><span class=cl>Lines: 21  
</span></span><span class=line><span class=cl>NNTP-Posting-Host: d012s658.ap.mchp.sni.de  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>In article &lt;1993Apr26.163627.11364@csrd.uiuc.edu&gt; g-skinner@uiuc.edu writes:  
</span></span><span class=line><span class=cl>#I find myself unable to put these two statements together in a  
</span></span><span class=line><span class=cl>#sensible way:  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#  
</span></span><span class=line><span class=cl>#&gt;Abortion is done because the mother can not afford the *pregnancy*.  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#  
</span></span><span class=line><span class=cl>#[...]  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#  
</span></span><span class=line><span class=cl>#&gt;If we refused to pay for the more expensive choice of birth, *then*  
</span></span><span class=line><span class=cl>#&gt;your statement would make sense.  But that is not the case, so it doesn&#39;t.  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>#  
</span></span><span class=line><span class=cl>#Are we paying for the birth or not, Mr. Parker?  If so, why can&#39;t the  
</span></span><span class=line><span class=cl>#mother afford the pregnancy?  If not, what is the meaning of the  
</span></span><span class=line><span class=cl>#latter objection?  You can&#39;t have it both ways.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>Birth != pregnancy.  If they were the same, the topic of abortion would   
</span></span><span class=line><span class=cl>hardly arise, would it, Mr. Skinner?  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>--   
</span></span><span class=line><span class=cl>Frank O&#39;Dwyer                                  &#39;I&#39;m not hatching That&#39;  
</span></span><span class=line><span class=cl>odwyer@sse.ie                                  from &#34;Hens&#34;,  by Evelyn Conlon  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>Corresponding Topic 2:  
</span></span><span class=line><span class=cl>talk.religion.misc
</span></span></code></pre></td></tr></table></div></div><h2 id=practicefetching-the-third-article-from-dataset>「Practice」Fetching the Third Article from Dataset</h2><p>Well done, Stellar Navigator! Next, fill in the missing line in the code below to fetch and display the third article from the <strong>20 Newsgroups dataset</strong> with its corresponding topic. Prepare your spacecraft for another adventure in data exploration!<br>干得好，星际导航员！接下来，填写以下代码中缺少的行，以获取并显示 20 Newsgroups 数据集中第三篇文章及其对应主题。准备好你的宇宙飞船，开始另一场数据探索冒险之旅吧！</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>newsgroups</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Fetch the third article and its corresponding topic</span>
</span></span></code></pre></td></tr></table></div></div><p>&ldquo;Here is the completed code to fetch and display the third article from the 20 Newsgroups dataset along with its corresponding topic.&rdquo;</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the third article and its corresponding topic</span>
</span></span><span class=line><span class=cl><span class=n>third_article</span> <span class=o>=</span> <span class=n>newsgroups</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>third_topic</span> <span class=o>=</span> <span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>[</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target</span><span class=p>[</span><span class=mi>2</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the third article and its corresponding topic</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Article 3:</span><span class=se>\n</span><span class=si>{</span><span class=n>third_article</span><span class=si>}</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Corresponding Topic 3: </span><span class=si>{</span><span class=n>third_topic</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>输出</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Article 3:  
</span></span><span class=line><span class=cl>From: hilmi-er@dsv.su.se (Hilmi Eren)  
</span></span><span class=line><span class=cl>Subject: Re: ARMENIA SAYS IT COULD SHOOT DOWN TURKISH PLANES (Henrik)  
</span></span><span class=line><span class=cl>Lines: 95  
</span></span><span class=line><span class=cl>Nntp-Posting-Host: viktoria.dsv.su.se  
</span></span><span class=line><span class=cl>Reply-To: hilmi-er@dsv.su.se (Hilmi Eren)  
</span></span><span class=line><span class=cl>Organization: Dept. of Computer and Systems Sciences, Stockholm University  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>|&gt;The student of &#34;regional killings&#34; alias Davidian (not the Davidian religios sect) writes:  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>|&gt;Greater Armenia would stretch from Karabakh, to the Black Sea, to the  
</span></span><span class=line><span class=cl>|&gt;Mediterranean, so if you use the term &#34;Greater Armenia&#34; use it with care.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>	Finally you said what you dream about. Mediterranean???? That was new....  
</span></span><span class=line><span class=cl>	The area will be &#34;greater&#34; after some years, like your &#34;holocaust&#34; numbers......  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>|&gt;It has always been up to the Azeris to end their announced winning of Karabakh   
</span></span><span class=line><span class=cl>|&gt;by removing the Armenians! When the president of Azerbaijan, Elchibey, came to   
</span></span><span class=line><span class=cl>|&gt;power last year, he announced he would be be &#34;swimming in Lake Sevan [in   
</span></span><span class=line><span class=cl>|&gt;Armeniaxn] by July&#34;.  
</span></span><span class=line><span class=cl>		*****  
</span></span><span class=line><span class=cl>	Is&#39;t July in USA now????? Here in Sweden it&#39;s April and still cold.  
</span></span><span class=line><span class=cl>	Or have you changed your calendar???  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>|&gt;Well, he was wrong! If Elchibey is going to shell the   
</span></span><span class=line><span class=cl>|&gt;Armenians of Karabakh from Aghdam, his people will pay the price! If Elchibey   
</span></span><span class=line><span class=cl>						    ****************  
</span></span><span class=line><span class=cl>|&gt;is going to shell Karabakh from Fizuli his people will pay the price! If   
</span></span><span class=line><span class=cl>						    ******************  
</span></span><span class=line><span class=cl>|&gt;Elchibey thinks he can get away with bombing Armenia from the hills of   
</span></span><span class=line><span class=cl>|&gt;Kelbajar, his people will pay the price.   
</span></span><span class=line><span class=cl>			    ***************  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>	NOTHING OF THE MENTIONED IS TRUE, BUT LET SAY IT&#39;s TRUE.  
</span></span><span class=line><span class=cl>	  
</span></span><span class=line><span class=cl>	SHALL THE AZERI WOMEN AND CHILDREN GOING TO PAY THE PRICE WITH  
</span></span><span class=line><span class=cl>						    **************  
</span></span><span class=line><span class=cl>	BEING RAPED, KILLED AND TORTURED BY THE ARMENIANS??????????  
</span></span><span class=line><span class=cl>	  
</span></span><span class=line><span class=cl>	HAVE YOU HEARDED SOMETHING CALLED: &#34;GENEVA CONVENTION&#34;???????  
</span></span><span class=line><span class=cl>	YOU FACIST!!!!!  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>	Ohhh i forgot, this is how Armenians fight, nobody has forgot  
</span></span><span class=line><span class=cl>	you killings, rapings and torture against the Kurds and Turks once  
</span></span><span class=line><span class=cl>	upon a time!
</span></span></code></pre></td></tr></table></div></div><h2 id=practiceexploring-text-length-in-newsgroups-dataset>「Practice」Exploring Text Length in Newsgroups Dataset</h2><p>Great job, Space Voyager! Now, as a final task, write a Python script that calculates and displays the lengths of the first five articles (in terms of the number of characters) from the <em>20 Newsgroups</em> dataset.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries and modules</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Fetch the 20 Newsgroups dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Iterate over the first five articles,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Calculate their length in terms of the number of characters and display it</span>
</span></span></code></pre></td></tr></table></div></div><p>&ldquo;Here is the completed Python script to calculate and display the lengths of the first five articles in terms of the number of characters from the 20 Newsgroups dataset.&rdquo;</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries and modules</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the 20 Newsgroups dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Iterate over the first five articles</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>article_length</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Length of Article </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>: </span><span class=si>{</span><span class=n>article_length</span><span class=si>}</span><span class=s1> characters&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=lesson2mastering-text-cleaning-for-nlp-techniques-and-applications>Lesson 2：Mastering Text Cleaning for NLP: Techniques and Applications</h2><h3 id=introduction引言>Introduction 引言</h3><p>Welcome to today&rsquo;s lesson on <strong>Text Cleaning Techniques</strong>! In any Natural Language Processing (NLP) project, the quality of your results depends heavily on the quality of your input. Hence, cleaning our textual data becomes critical for the accuracy of our project. Our main objective for today is to delve into how to clean textual data using Python. By the end of this session, you will be comfortable with creating and applying a simple text cleaning pipeline in Python.<br>欢迎来到今天关于文本清理技术的课程！在任何自然语言处理 (NLP) 项目中，结果的质量在很大程度上取决于输入的质量。因此，清理文本数据对于项目的准确性至关重要。我们今天的主要目标是深入研究如何使用 Python 清理文本数据。在本课程结束时，您将能够轻松地使用 Python 创建和应用简单的文本清理管道。</p><h5 id=understanding-text-cleaning>Understanding Text Cleaning</h5><p>理解文本清洗</p><p><strong>Text cleaning</strong> is essential in NLP, involving the preparation of text data for analysis. Why is it necessary? Imagine trying to perform text classification on social media posts; people often use colloquial language, abbreviations, and emojis. In many cases, posts might also be in different languages. These variations make it challenging for machines to understand context without undergoing preprocessing.<br>文本清洗在自然语言处理 (NLP) 中至关重要，涉及为分析准备文本数据。为什么需要它？想象一下尝试对社交媒体帖子进行文本分类；人们经常使用口语、缩写和表情符号。在许多情况下，帖子也可能使用不同的语言。这些差异使得机器在未经预处理的情况下难以理解上下文。</p><p>We get rid of superfluous variations and distractions to make the text understandable for algorithms, thereby increasing accuracy. These distractions could range from punctuation, special symbols, numbers, to even common words that do not carry significant meaning (commonly referred to as &ldquo;stop words&rdquo;).<br>我们去除多余的变化和干扰因素，使文本易于算法理解，从而提高准确性。这些干扰因素包括标点符号、特殊符号、数字，甚至是不具有重要意义的常见词（通常称为“停用词”）。</p><p>Python&rsquo;s <strong>Regex</strong> (Regular Expression) library, <code>re</code>, is an ideal tool for such text cleaning tasks, as it is specifically designed to work with string patterns. Within this library, we will be using <code>re.sub</code>, a method employed to replace parts of a string. This method operates by accepting three arguments: <code>re.sub(pattern, repl, string)</code>. Here, <code>pattern</code> is the character pattern we&rsquo;re looking to replace, <code>repl</code> is the replacement string, and <code>string</code> is the text being processed. In essence, any part of the <code>string</code> argument that matches the <code>pattern</code> argument gets replaced by the <code>repl</code> argument.<br>Python 的正则表达式 (Regex) 库 <code> </code>re<code> </code> 是此类文本清理任务的理想工具，因为它专门用于处理字符串模式。在这个库中，我们将使用 <code> </code>re.sub<code> </code> 方法来替换字符串的某些部分。此方法接受三个参数：<code> </code>re.sub(pattern, repl, string)<code> </code>。其中，<code> </code>pattern<code> </code> 是我们要替换的字符模式，<code> </code>repl<code> </code> 是替换字符串，<code> </code>string<code> </code> 是正在处理的文本。本质上，<code> </code>string<code> </code> 参数中与 <code> </code>pattern<code> </code> 参数匹配的任何部分都将被 <code> </code>repl<code> </code> 参数替换。</p><p>As we proceed, a clearer understanding of the functionality and application of <code>re.sub</code> will be provided. Now, let&rsquo;s delve into it!<br>随着我们的深入，我们将对 <code>re.sub</code> 的功能和应用有更清晰的了解。现在，让我们开始吧！</p><h3 id=text-cleaning-process文本清理流程>Text Cleaning Process 文本清理流程</h3><p>The text cleaning process comprises multiple steps where each step aims to reduce the complexity of the text. Let&rsquo;s take you through the process using a Python function, <code>clean_text</code>.<br>文本清理过程包含多个步骤，每个步骤都旨在降低文本的复杂性。让我们通过一个 Python 函数 <code>clean_text</code> 来带您了解整个过程。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>  <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span>
</span></span></code></pre></td></tr></table></div></div><p>In the function above we can see how each line corresponds to a step in the cleaning process:<br>在上面的函数中，我们可以看到每一行是如何对应于清洁过程中的一个步骤的：</p><ol><li><strong>Lowercase:</strong> We convert all text to lower case, so every word looks the same unless it carries a different meaning. This way, words like &lsquo;The&rsquo; and &rsquo;the&rsquo; are no longer seen as different.<br>小写：我们将所有文本转换为小写，因此每个单词看起来都一样，除非它具有不同的含义。这样，“The”和“the”就不再被视为不同的词。</li><li><strong>Email addresses:</strong> Email addresses don&rsquo;t usually provide useful information unless we&rsquo;re specifically looking for them. This line of code removes any email addresses found.<br>电子邮件地址：电子邮件地址通常不会提供有用信息，除非我们专门查找它们。这行代码会删除找到的任何电子邮件地址。</li><li><strong>URLs:</strong> Similarly, URLs are removed as they are typically not useful in text classification tasks.<br>URL：类似地，URL 通常在文本分类任务中没有用处，因此会被删除。</li><li><strong>Special Characters:</strong> We remove any non-word characters (<code>\W</code>) and replace it with space using regex. This includes special characters and punctuation.<br>特殊字符：我们使用正则表达式删除任何非单词字符（ <code>\W</code> ）并将其替换为空格。这包括特殊字符和标点符号。</li><li><strong>Numbers:</strong> We&rsquo;re dealing with text data, so numbers are also considered distractions unless they carry significant meaning.<br>数字：我们处理的是文本数据，因此除非数字具有重要意义，否则它们也被视为干扰因素。</li><li><strong>Extra spaces:</strong> Any resulting extra spaces from the previous steps are removed.<br>从先前步骤产生的任何额外空格都将被删除。</li></ol><p>Let&rsquo;s go ahead and run this function on some demo input to see it in action!<br>让我们继续，在一些演示输入上运行此函数，看看它的实际效果！</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>clean_text</span><span class=p>(</span><span class=s1>&#39;Check out the course at www.codesignal.com/course123&#39;</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:<br>以上代码的输出将是：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>check</span> <span class=n>out</span> <span class=n>the</span> <span class=n>course</span> <span class=n>at</span> <span class=n>www</span> <span class=n>codesignal</span> <span class=n>com</span> <span class=n>course</span> 
</span></span></code></pre></td></tr></table></div></div><h5 id=implementing-text-cleaning-function>Implementing Text Cleaning Function</h5><p>实现文本清洗功能</p><p>Now that you are familiar with the workings of the function let&rsquo;s implement it in the <strong>20 Newsgroups</strong> dataset.<br>现在你已经熟悉了函数的工作原理，让我们在 20 Newsgroups 数据集中实现它。</p><p>To apply our cleaning function on the dataset, we will make use of the DataFrame data structure from <code>Pandas</code>, another powerful data manipulation tool in Python.<br>为了在数据集上应用我们的清洗函数，我们将利用 <code>Pandas</code> 中的 DataFrame 数据结构，它是 Python 中另一个强大的数据操作工具。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetching the 20 Newsgroups Dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>nlp_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>newsgroups_data</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=n>columns</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Applied the cleaning function to the text data</span>
</span></span><span class=line><span class=cl><span class=n>nlp_df</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>nlp_df</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Checking the cleaned text</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>nlp_df</span><span class=o>.</span><span class=n>head</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:<br>以上代码的输出将是：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>0  from where s my thing subject what car is this...
</span></span><span class=line><span class=cl>1  from guy kuo subject si clock poll final call ...
</span></span><span class=line><span class=cl>2  from thomas e willis subject pb questions orga...
</span></span><span class=line><span class=cl>3  from joe green subject re weitek p organizatio...
</span></span><span class=line><span class=cl>4  from jonathan mcdowell subject re shuttle laun...
</span></span></code></pre></td></tr></table></div></div><p>In this code, we&rsquo;re applying the <code>clean_text</code> function to each &rsquo;text&rsquo; in our DataFrame using the <code>apply</code> function. The <code>apply</code> function passes every value of the DataFrame column to the <code>clean_text</code> function one by one.<br>在这段代码中，我们使用 <code>apply</code> 函数将 <code>clean_text</code> 函数应用于 DataFrame 中的每个“文本”。 <code>apply</code> 函数将 DataFrame 列的每个值逐个传递给 <code>clean_text</code> 函数。</p><h3 id=understanding-effectiveness-of-text-cleaning-function>Understanding Effectiveness of Text Cleaning Function</h3><p>理解文本清洗功能的有效性</p><p>We want to understand the impact of our text cleaning function. We can achieve this by looking at our text before and after cleaning. Let&rsquo;s use some new examples:<br>我们想要理解文本清洗函数的影响。我们可以通过查看清洗前后的文本内容来实现这一点。让我们使用一些新的例子：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_texts</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;This is an EXAMPLE!&#39;</span><span class=p>,</span> <span class=s1>&#39;Another ex:ample123 with special characters $#@!&#39;</span><span class=p>,</span> <span class=s1>&#39;example@mail.com is an email address.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>test_texts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Original: </span><span class=si>{</span><span class=n>text</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Cleaned: </span><span class=si>{</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:<br>以上代码的输出将是：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Original</span><span class=p>:</span> <span class=n>This</span> <span class=ow>is</span> <span class=n>an</span> <span class=n>EXAMPLE</span><span class=err>!</span>
</span></span><span class=line><span class=cl><span class=n>Cleaned</span><span class=p>:</span> <span class=n>this</span> <span class=ow>is</span> <span class=n>an</span> <span class=n>example</span> 
</span></span><span class=line><span class=cl><span class=o>--</span>
</span></span><span class=line><span class=cl><span class=n>Original</span><span class=p>:</span> <span class=n>Another</span> <span class=n>ex</span><span class=p>:</span><span class=n>ample123</span> <span class=k>with</span> <span class=n>special</span> <span class=n>characters</span> <span class=err>$</span><span class=c1>#@!</span>
</span></span><span class=line><span class=cl><span class=n>Cleaned</span><span class=p>:</span> <span class=n>another</span> <span class=n>ex</span> <span class=n>ample</span> <span class=k>with</span> <span class=n>special</span> <span class=n>characters</span> 
</span></span><span class=line><span class=cl><span class=o>--</span>
</span></span><span class=line><span class=cl><span class=n>Original</span><span class=p>:</span> <span class=n>example</span><span class=nd>@mail.com</span> <span class=ow>is</span> <span class=n>an</span> <span class=n>email</span> <span class=n>address</span><span class=o>.</span>
</span></span><span class=line><span class=cl><span class=n>Cleaned</span><span class=p>:</span> <span class=ow>is</span> <span class=n>an</span> <span class=n>email</span> <span class=n>address</span> 
</span></span><span class=line><span class=cl><span class=o>--</span>
</span></span></code></pre></td></tr></table></div></div><p>In the example above, you will see that our function successfully transforms all text to lower case and removes punctuation, digits, and email addresses!<br>在上面的例子中，你会看到我们的函数成功地将所有文本转换为小写，并删除了标点符号、数字和电子邮件地址！</p><h5 id=lesson-summary-and-practice-exercises>Lesson Summary and Practice Exercises</h5><p>课文总结和练习题</p><p>Today we delved into the text cleaning process in Natural Language Processing. We shared why it is necessary and how to implement it in Python. We then applied our text cleaning function on a textual dataset.<br>今天我们深入探讨了自然语言处理中的文本清洗过程。我们分享了为什么需要文本清洗以及如何在 Python 中实现它。然后，我们将文本清洗函数应用于一个文本数据集。</p><p>We have a few exercises lined up based on what we learned today. Keep swimming ahead, and remember, you learn the most by doing. Happy cleaning!<br>我们准备了一些练习，都是基于今天所学的内容。继续加油练习，记住，实践出真知。祝你顺利完成！</p><h2 id=practice1>「Practice1」</h2><p>Well done, Space Voyager! Now, to further explore the workings of our text cleaning function, let&rsquo;s use a different sentence. Replace the first sentence in the <code>test_texts</code> list with the phrase &ldquo;I love learning at CodeSignal; it&rsquo;s so interactive and fun!&rdquo;. Then run the <code>clean_text</code> function with the updated list.<br>干得好，太空旅行者！现在，为了进一步探索我们文本清理功能的工作原理，让我们使用不同的句子。将 <code>test_texts</code> 列表中的第一句话替换为“我喜欢在 Co 学习<br>干得好，太空旅行家！现在，为了进一步探索文本清理函数的工作原理，让我们使用不同的句子。将 <code>test_texts</code> 列表中的第一句话替换为“我喜欢在代码学习</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;[^\w\s]&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters but leave spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Normalize whitespace to single spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=c1># Strip leading and trailing spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_texts</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;This is an EXAMPLE!&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;Another ex:ample123 with special characters $#@!&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;example@mail.com is an email address.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>test_texts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Original: </span><span class=si>{</span><span class=n>text</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Cleaned: </span><span class=si>{</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>输出</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Original</span><span class=p>:</span> <span class=n>I</span> <span class=n>love</span> <span class=n>learning</span> <span class=n>at</span> <span class=n>CodeSignal</span><span class=p>;</span> <span class=n>it</span><span class=s1>&#39;s so interactive and fun!  </span>
</span></span><span class=line><span class=cl><span class=n>Cleaned</span><span class=p>:</span> <span class=n>i</span> <span class=n>love</span> <span class=n>learning</span> <span class=n>at</span> <span class=n>codesignal</span> <span class=n>its</span> <span class=n>so</span> <span class=n>interactive</span> <span class=ow>and</span> <span class=n>fun</span>  
</span></span><span class=line><span class=cl><span class=o>--</span>  
</span></span><span class=line><span class=cl><span class=n>Original</span><span class=p>:</span> <span class=n>Another</span> <span class=n>ex</span><span class=p>:</span><span class=n>ample123</span> <span class=n>with</span> <span class=n>special</span> <span class=n>characters</span> <span class=o>$</span><span class=c1>#@!  </span>
</span></span><span class=line><span class=cl><span class=n>Cleaned</span><span class=p>:</span> <span class=n>another</span> <span class=n>example</span> <span class=n>with</span> <span class=n>special</span> <span class=n>characters</span>  
</span></span><span class=line><span class=cl><span class=o>--</span>  
</span></span><span class=line><span class=cl><span class=n>Original</span><span class=p>:</span> <span class=n>example</span><span class=err>@</span><span class=n>mail</span><span class=o>.</span><span class=n>com</span> <span class=n>is</span> <span class=n>an</span> <span class=n>email</span> <span class=n>address</span><span class=o>.</span>  
</span></span><span class=line><span class=cl><span class=n>Cleaned</span><span class=p>:</span> <span class=n>is</span> <span class=n>an</span> <span class=n>email</span> <span class=n>address</span>  
</span></span><span class=line><span class=cl><span class=o>--</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=practice2filling-in-python-functions-and-regex-patterns>「Practice2」Filling in Python Functions and Regex Patterns</h2><p>Superb job! Now, let&rsquo;s ensure you have grasped the core <strong>Python functions</strong> and <strong>regex patterns</strong> used in text cleaning.<br>干得好！现在，让我们来确保你已经掌握了文本清理中使用的核心 Python 函数和正则表达式。</p><p>Fill in the blanks (<code>____</code>) to transform all text to lowercase and remove extra spaces.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>____</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\____\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_texts</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;Another ex:ample123 with special characters $#@!&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;example@mail.com is an email address.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>test_texts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Original: </span><span class=si>{</span><span class=n>text</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Cleaned: </span><span class=si>{</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>解释</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>  <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_texts</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;Another ex:ample123 with special characters $#@!&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;example@mail.com is an email address.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>test_texts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Original: </span><span class=si>{</span><span class=n>text</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Cleaned: </span><span class=si>{</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>输出</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Original</span><span class=p>:</span> <span class=n>Fill</span> <span class=n>me</span> <span class=n>In</span><span class=err>!</span> <span class=n>I</span> <span class=n>enjoy</span> <span class=n>problem</span><span class=o>-</span><span class=n>solving</span> <span class=n>tasks</span> <span class=n>like</span> <span class=n>these</span><span class=p>;</span> <span class=n>they</span> <span class=n>are</span> <span class=n>quite</span> <span class=n>engaging</span><span class=o>.</span>  
</span></span><span class=line><span class=cl><span class=n>Cleaned</span><span class=p>:</span> <span class=n>fill</span> <span class=n>me</span> <span class=ow>in</span> <span class=n>i</span> <span class=n>enjoy</span> <span class=n>problem</span> <span class=n>solving</span> <span class=n>tasks</span> <span class=n>like</span> <span class=n>these</span> <span class=n>they</span> <span class=n>are</span> <span class=n>quite</span> <span class=n>engaging</span>  
</span></span><span class=line><span class=cl><span class=o>--</span>  
</span></span><span class=line><span class=cl><span class=n>Original</span><span class=p>:</span> <span class=n>Another</span> <span class=n>ex</span><span class=p>:</span><span class=n>ample123</span> <span class=k>with</span> <span class=n>special</span> <span class=n>characters</span> <span class=err>$</span><span class=c1>#@!  </span>
</span></span><span class=line><span class=cl><span class=n>Cleaned</span><span class=p>:</span> <span class=n>another</span> <span class=n>ex</span> <span class=n>ample</span> <span class=k>with</span> <span class=n>special</span> <span class=n>characters</span>  
</span></span><span class=line><span class=cl><span class=o>--</span>  
</span></span><span class=line><span class=cl><span class=n>Original</span><span class=p>:</span> <span class=n>example</span><span class=nd>@mail.com</span> <span class=ow>is</span> <span class=n>an</span> <span class=n>email</span> <span class=n>address</span><span class=o>.</span>  
</span></span><span class=line><span class=cl><span class=n>Cleaned</span><span class=p>:</span> <span class=ow>is</span> <span class=n>an</span> <span class=n>email</span> <span class=n>address</span>  
</span></span><span class=line><span class=cl><span class=o>--</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=practice2filling-in-python-functions-and-regex-patterns-1>「Practice2」Filling in Python Functions and Regex Patterns</h2><p>Superb job! Now, let&rsquo;s ensure you have grasped the core <strong>Python functions</strong> and <strong>regex patterns</strong> used in text cleaning.</p><p>Fill in the blanks (<code>____</code>) to transform all text to lowercase and remove extra spaces.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>____</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\____\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_texts</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;Another ex:ample123 with special characters $#@!&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;example@mail.com is an email address.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>test_texts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Original: </span><span class=si>{</span><span class=n>text</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Cleaned: </span><span class=si>{</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
Certainly! Here&rsquo;s the completed Python code with the blanks filled:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>  <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_texts</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;Another ex:ample123 with special characters $#@!&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;example@mail.com is an email address.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>test_texts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Original: </span><span class=si>{</span><span class=n>text</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Cleaned: </span><span class=si>{</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Explanation:</p><ul><li>The <code>lower()</code> method converts all text to lowercase.</li><li>The regex pattern <code>r'\s+'</code> matches one or more whitespace characters, which are then replaced by a single space to remove extra spaces.</li></ul><h3 id=输出>输出</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Original: Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.  
</span></span><span class=line><span class=cl>Cleaned: fill me in i enjoy problem solving tasks like these they are quite engaging  
</span></span><span class=line><span class=cl>--  
</span></span><span class=line><span class=cl>Original: Another ex:ample123 with special characters $#@!  
</span></span><span class=line><span class=cl>Cleaned: another ex ample with special characters  
</span></span><span class=line><span class=cl>--  
</span></span><span class=line><span class=cl>Original: example@mail.com is an email address.  
</span></span><span class=line><span class=cl>Cleaned: is an email address  
</span></span><span class=line><span class=cl>--
</span></span></code></pre></td></tr></table></div></div><h2 id=practice3mastering-text-cleaning-with-python-regex>Practice 3：Mastering Text Cleaning with Python Regex</h2><p>Charming maneuvering, Stellar Navigator!</p><p>Now, I want to see more of your Python prowess. Replace the missing parts (<code>____</code>), ensuring that they perform the right operations. We aim to <strong>transform all text to lowercase</strong> and <strong>eliminate email addresses</strong>, <strong>URLs</strong>, <strong>special characters</strong>, <strong>digits</strong>, and <strong>extra spaces</strong>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>____</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;____&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;____&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;____&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;____&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;____&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_texts</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Sample Text with EMAIL! mailsample@mail.com&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;URL example: https://www.codesignal.com&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;Special characters #formed.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;Digits included: 1234!!&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;Extra spaces included.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>test_texts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Original: </span><span class=si>{</span><span class=n>text</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Cleaned: </span><span class=si>{</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
To clean the text by transforming it to lowercase and removing email addresses, URLs, special characters, digits, and extra spaces, you can fill in the missing parts of the provided Python code as follows:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\b[\w\.-]+?@\w+?\.\w+?\b&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+|www\.\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;[^\w\s]&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_texts</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;Sample Text with EMAIL! mailsample@mail.com&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;URL example: https://www.codesignal.com&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;Special characters #formed.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;Digits included: 1234!!&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;Extra spaces included.  &#39;</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>test_texts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Original: </span><span class=si>{</span><span class=n>text</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Cleaned: </span><span class=si>{</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Explanation of the substitutions:</p><ol><li><code>text.lower()</code>: Converts the text to lowercase.</li><li><code>re.sub(r'\b[\w\.-]+?@\w+?\.\w+?\b', '', text)</code>: Removes email addresses by matching common email patterns.</li><li><code>re.sub(r'http\S+|www\.\S+', '', text)</code>: Removes URLs by matching patterns that start with &ldquo;http&rdquo; or &ldquo;www&rdquo;.</li><li><code>re.sub(r'[^\w\s]', ' ', text)</code>: Removes special characters by replacing anything that is not a word character or whitespace with a space.</li><li><code>re.sub(r'\d+', '', text)</code>: Removes digits by matching one or more digits.</li><li><code>re.sub(r'\s+', ' ', text)</code>: Replaces multiple spaces with a single space.</li></ol><p>This code will transform the given text according to the specified requirements.</p><h2 id=practice>「Practice」</h2><p>Off to a flying start, Celestial Traveler! Your new task requires you to insert missing code into two sections. First, <strong>write code</strong> that transforms the collected dataset into a <code>DataFrame</code>. Then, ensure that you apply the <code>clean_text</code> function to the <code>DataFrame</code> to clean up the textual data. Bon Voyage!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Normalize whitespace to single spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=c1># Strip leading and trailing spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create DataFrame from the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Write the required code to create a dataframe from the dataset. Name the dataframe as nlp_df and the column as &#39;text&#39;.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the clean_text function to the text data in the DataFrame</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Write the code to apply the clean_text function to the &#39;text&#39; column in the dataframe.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check the cleaned text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>nlp_df</span><span class=o>.</span><span class=n>head</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
Certainly! Let&rsquo;s expand on your query to ensure comprehensive coverage. You are asking for the code needed to transform a dataset collected from the <code>fetch_20newsgroups</code> function into a pandas <code>DataFrame</code>. The task also involves applying a <code>clean_text</code> function to the text data within this <code>DataFrame</code> to clean it up by removing email addresses, URLs, punctuation, digits, and normalizing whitespace. Below is the complete code to achieve this:</p><ol><li>Transform the fetched dataset into a <code>DataFrame</code>.</li><li>Apply the <code>clean_text</code> function to the text column in this <code>DataFrame</code>.</li></ol><p>Here&rsquo;s the completed code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Normalize whitespace to single spaces</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span> <span class=c1># Strip leading and trailing spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create DataFrame from the dataset</span>
</span></span><span class=line><span class=cl><span class=n>nlp_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span><span class=s1>&#39;text&#39;</span><span class=p>:</span> <span class=n>newsgroups_data</span><span class=o>.</span><span class=n>data</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the clean_text function to the text data in the DataFrame</span>
</span></span><span class=line><span class=cl><span class=n>nlp_df</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>nlp_df</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=n>clean_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check the cleaned text</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>nlp_df</span><span class=o>.</span><span class=n>head</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=explanation>Explanation:</h3><ol><li><strong>Fetching Data</strong>: The <code>fetch_20newsgroups</code> function from <code>sklearn.datasets</code> is used to fetch the dataset.</li><li><strong>Creating DataFrame</strong>: A pandas <code>DataFrame</code> is created from the dataset, with a single column named <code>text</code>.</li><li><strong>Cleaning Text</strong>: The <code>clean_text</code> function is applied to each entry in the <code>text</code> column of the DataFrame to clean the text.</li><li><strong>Display Cleaned Data</strong>: The first few rows of the cleaned DataFrame are printed to verify the cleaning process.</li></ol><p>This code ensures that the dataset is not only structured properly but also cleaned efficiently, ready for any further text processing or analysis tasks.
输出</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>0  from where s my thing subject what car is this...  
</span></span><span class=line><span class=cl>1  from guy kuo subject si clock poll final call ...  
</span></span><span class=line><span class=cl>2  from thomas e willis subject pb questions orga...  
</span></span><span class=line><span class=cl>3  from joe green subject re weitek p organizatio...  
</span></span><span class=line><span class=cl>4  from jonathan mcdowell subject re shuttle laun...
</span></span></code></pre></td></tr></table></div></div><h2 id=practice-1>「Practice」</h2><p>Excellent work so far, Stellar Navigator! This time, you&rsquo;ll master <strong>how to clean textual data</strong>. We aim to transform pieces of text into cleaner versions, making them more suitable for further analysis. Let&rsquo;s put the focus on the cleaning functions you&rsquo;ve built previously. Implement a combined function that runs all these cleaning operations in sequence: converting text to lowercase letters, removing email addresses, <strong>URLs</strong>, <strong>special characters</strong>, <strong>digits</strong>, and <strong>extra spaces</strong>. Finally,<strong>apply this unified cleaning function to a dataset</strong>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>lower_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_email</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_url</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_special_chars</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_digits</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_extra_spaces</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Implement a function clean_text that runs all the functions above in a sequence</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Create a DataFrame from the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Apply the cleaning functions to the DataFrame</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Check the cleaned text</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=practice5mastering-text-cleaning-with-python-regex-on-a-dataset>「Practice 5」：Mastering Text Cleaning with Python Regex on a Dataset</h2><p>Excellent work so far, Stellar Navigator! This time, you&rsquo;ll master <strong>how to clean textual data</strong>. We aim to transform pieces of text into cleaner versions, making them more suitable for further analysis. Let&rsquo;s put the focus on the cleaning functions you&rsquo;ve built previously. Implement a combined function that runs all these cleaning operations in sequence: converting text to lowercase letters, removing email addresses, <strong>URLs</strong>, <strong>special characters</strong>, <strong>digits</strong>, and <strong>extra spaces</strong>. Finally,<strong>apply this unified cleaning function to a dataset</strong>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>lower_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_email</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_url</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_special_chars</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_digits</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_extra_spaces</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Implement a function clean_text that runs all the functions above in a sequence</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Create a DataFrame from the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Apply the cleaning functions to the DataFrame</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Check the cleaned text</span>
</span></span></code></pre></td></tr></table></div></div><p>Certainly! Let&rsquo;s rephrase and expand your request to ensure a comprehensive solution.</p><p>You want to implement a combined function that performs a series of text cleaning operations, which include converting text to lowercase, removing email addresses, URLs, special characters, digits, and extra spaces. After defining this unified cleaning function, you will apply it to a dataset and inspect the cleaned text.</p><p>Here&rsquo;s the step-by-step process to achieve this:</p><ol><li><strong>Implement a function <code>clean_text</code> that sequentially applies all the cleaning operations.</strong></li><li><strong>Fetch a dataset (in this case, the 20 Newsgroups dataset).</strong></li><li><strong>Create a DataFrame from the fetched dataset.</strong></li><li><strong>Apply the <code>clean_text</code> function to the text data in the DataFrame.</strong></li><li><strong>Inspect the cleaned text.</strong></li></ol><p>Let&rsquo;s start by defining the <code>clean_text</code> function:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Individual cleaning functions</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>lower_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_email</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_url</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_special_chars</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_digits</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_extra_spaces</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Combined cleaning function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>lower_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_email</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_url</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_special_chars</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_digits</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_extra_spaces</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create a DataFrame from the dataset</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span><span class=s1>&#39;text&#39;</span><span class=p>:</span> <span class=n>newsgroups_data</span><span class=o>.</span><span class=n>data</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the cleaning functions to the DataFrame</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;cleaned_text&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=n>clean_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check the cleaned text</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;cleaned_text&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>head</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>This script does the following:</p><ul><li>Defines each individual cleaning function.</li><li>Creates a <code>clean_text</code> function that applies all the cleaning steps in sequence.</li><li>Fetches the 20 Newsgroups dataset.</li><li>Creates a DataFrame from the dataset, with the text data in a column named &rsquo;text&rsquo;.</li><li>Applies the <code>clean_text</code> function to each text entry in the DataFrame.</li><li>Prints the first few cleaned text entries to verify the results.</li></ul><p>By running this code, you will transform the text data into a cleaner version suitable for further analysis, ensuring it is free from unwanted characters and formatted consistently.
Certainly! Let&rsquo;s rephrase and expand your request to ensure a comprehensive solution.</p><p>You want to implement a combined function that performs a series of text cleaning operations, which include converting text to lowercase, removing email addresses, URLs, special characters, digits, and extra spaces. After defining this unified cleaning function, you will apply it to a dataset and inspect the cleaned text.</p><p>Here&rsquo;s the step-by-step process to achieve this:</p><ol><li><strong>Implement a function <code>clean_text</code> that sequentially applies all the cleaning operations.</strong></li><li><strong>Fetch a dataset (in this case, the 20 Newsgroups dataset).</strong></li><li><strong>Create a DataFrame from the fetched dataset.</strong></li><li><strong>Apply the <code>clean_text</code> function to the text data in the DataFrame.</strong></li><li><strong>Inspect the cleaned text.</strong></li></ol><p>Let&rsquo;s start by defining the <code>clean_text</code> function:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Individual cleaning functions</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>lower_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_email</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_url</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_special_chars</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_digits</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_extra_spaces</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Combined cleaning function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>lower_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_email</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_url</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_special_chars</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_digits</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_extra_spaces</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetch the dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create a DataFrame from the dataset</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span><span class=s1>&#39;text&#39;</span><span class=p>:</span> <span class=n>newsgroups_data</span><span class=o>.</span><span class=n>data</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the cleaning functions to the DataFrame</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;cleaned_text&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=n>clean_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Check the cleaned text</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;cleaned_text&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>head</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>This script does the following:</p><ul><li>Defines each individual cleaning function.</li><li>Creates a <code>clean_text</code> function that applies all the cleaning steps in sequence.</li><li>Fetches the 20 Newsgroups dataset.</li><li>Creates a DataFrame from the dataset, with the text data in a column named &rsquo;text&rsquo;.</li><li>Applies the <code>clean_text</code> function to each text entry in the DataFrame.</li><li>Prints the first few cleaned text entries to verify the results.</li></ul><p>By running this code, you will transform the text data into a cleaner version suitable for further analysis, ensuring it is free from unwanted characters and formatted consistently.</p><h1 id=lesson>lesson</h1><p>Blast through text preprocessing with ease! 🚀 Keep up the great work - you&rsquo;re doing stellar!</p><h5 id=introduction>Introduction</h5><p>Hello and welcome to this lesson on <strong>Removing Stop Words and Stemming</strong>! In this lesson, we will dive deep into two essential steps to prepare text data for machine learning models: removing stop words and stemming. These techniques will help us improve the efficiency and accuracy of our models. Let&rsquo;s get started!</p><h5 id=understanding-stop-words>Understanding Stop Words</h5><p>Stop words in Natural Language Processing (NLP) refer to the most common words in a language. Examples include &ldquo;and&rdquo;, &ldquo;the&rdquo;, &ldquo;is&rdquo;, and others that do not provide significant meaning and are often removed to speed up processing without losing crucial information. For this purpose, Python&rsquo;s Natural Language Tool Kit (NLTK) provides a pre-defined list of stop words. Let&rsquo;s have a look:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Defining the stop words</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print 5 stop words</span>
</span></span><span class=line><span class=cl><span class=n>examples_of_stopwords</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>stop_words</span><span class=p>)[:</span><span class=mi>5</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Examples of stop words: </span><span class=si>{</span><span class=n>examples_of_stopwords</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Examples</span> <span class=n>of</span> <span class=n>stop</span> <span class=n>words</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;or&#39;</span><span class=p>,</span> <span class=s1>&#39;some&#39;</span><span class=p>,</span> <span class=s1>&#39;couldn&#39;</span><span class=p>,</span> <span class=s1>&#39;hasn&#39;</span><span class=p>,</span> <span class=s1>&#39;after&#39;</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>Here, the <code>stopwords.words('english')</code> function returns a list of English stop words. You might sometimes need to add domain-specific stop words to this list based on the nature of your text data.</p><h5 id=introduction-to-stemming>Introduction to Stemming</h5><p>Stemming is a technique that reduces a word to its root form. Although the stemmed word may not always be a real or grammatically correct word in English, it does help to consolidate different forms of the same word to a common base form, reducing the complexity of text data. This simplification leads to quicker computation and potentially better performance when implementing Natural Language Processing (NLP) algorithms, as there are fewer unique words to consider.</p><p>For example, the words &ldquo;run&rdquo;, &ldquo;runs&rdquo;, &ldquo;running&rdquo; might all be stemmed to the common root &ldquo;run&rdquo;. This helps our algorithm understand that these words are related and they carry a similar semantic meaning.</p><p>Let&rsquo;s illustrate this with Porter Stemmer, a well-known stemming algorithm from the NLTK library:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Stemming with NLTK Porter Stemmer</span>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stemmed_word</span> <span class=o>=</span> <span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=s1>&#39;running&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Stemmed word: </span><span class=si>{</span><span class=n>stemmed_word</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Stemmed word: run
</span></span></code></pre></td></tr></table></div></div><p>The <code>PorterStemmer</code> class comes with the <code>stem</code> method that takes in a word and returns its root form. In this case, &ldquo;running&rdquo; is correctly stemmed to its root word &ldquo;run&rdquo;. This form of preprocessing, although it may lead to words that are not recognizable, is a standard practice in text preprocessing for NLP tasks.</p><h5 id=stop-words-removal-and-stemming-in-action>Stop Words Removal and Stemming in Action</h5><p>Having understood stop words and stemming, let&rsquo;s develop a function that removes stop words and applies stemming to a given text. We will tokenize the text (split it into individual words) and apply these transformations word by word.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenized_text</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>filtered_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>tokenized_text</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>example_text</span> <span class=o>=</span> <span class=s2>&#34;This is a example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Original Text: </span><span class=si>{</span><span class=n>example_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Processed Text: </span><span class=si>{</span><span class=n>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>example_text</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Original Text: This is a example text to demonstrate the removal of stop words and stemming.
</span></span><span class=line><span class=cl>Processed Text: thi exampl text demonstr remov stop word stem .
</span></span></code></pre></td></tr></table></div></div><p>The <code>remove_stopwords_and_stem</code> function does the required processing and provides the cleaned-up text.</p><h5 id=stop-words-removal-and-stemming-on-a-dataset>Stop Words Removal and Stemming on a Dataset</h5><p>Let&rsquo;s implement the above concepts on a real-world text dataset – the <strong>20 Newsgroups Dataset</strong>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetching 20 newsgroups dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Limit to first 100 data points for efficient code execution</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>newsgroups_data</span><span class=p>[</span><span class=s1>&#39;data&#39;</span><span class=p>][:</span><span class=mi>100</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>processed_newsgroups_data</span> <span class=o>=</span> <span class=p>[</span><span class=n>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>)</span> <span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>newsgroups_data</span><span class=p>[:</span><span class=mi>100</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print first 100 characters of first document</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;First 100 characters of first processed document:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>processed_newsgroups_data</span><span class=p>[</span><span class=mi>0</span><span class=p>][:</span><span class=mi>100</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>First</span> <span class=mi>100</span> <span class=n>characters</span> <span class=n>of</span> <span class=n>first</span> <span class=n>processed</span> <span class=n>document</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=p>:</span> <span class=n>mamatha</span> <span class=n>devineni</span> <span class=n>ratnam</span> <span class=o>&lt;</span> <span class=n>mr47</span><span class=o>+</span> <span class=o>@</span> <span class=n>andrew</span><span class=o>.</span><span class=n>cmu</span><span class=o>.</span><span class=n>edu</span> <span class=o>&gt;</span> <span class=n>subject</span> <span class=p>:</span> <span class=n>pen</span> <span class=n>fan</span> <span class=n>reaction</span> <span class=n>organ</span> <span class=p>:</span> <span class=n>post</span> <span class=n>of</span>
</span></span></code></pre></td></tr></table></div></div><p>This process can take a while for large datasets, but the output will be much cleaner and easier for a machine learning model to work with.</p><h5 id=summary-and-conclusion>Summary and Conclusion</h5><p>And that&rsquo;s a wrap! In today&rsquo;s lesson, we&rsquo;ve learned about stop words and stemming as crucial steps in text preprocessing for machine learning models. We&rsquo;ve used Python&rsquo;s NLTK library to work with stop words and perform stemming. We have processed some example sentences and a real-world dataset to practice these concepts.</p><p>As we proceed to more advanced NLP tasks, pre-processing techniques like removing stop words and stemming would serve as a solid foundation. In the upcoming lessons, we will delve deeper into handling missing text data and learn about reshaping textual data for analysis. Let&rsquo;s keep going!</p><p>Start practice</p><h2 id=practice1-1>「practice1」</h2><p>Excellent work so far, Stellar Navigator! Now it&rsquo;s time to <strong>tweak the implemented text preprocessing method</strong>. Replace the use of <code>LancasterStemmer</code> with <code>PorterStemmer</code>. Remember to import <code>PorterStemmer</code> from <code>nltk.stem</code>. After adjusting your code, run it and observe the differences in your processed text.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>LancasterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Defining the stop words</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Creating an instance of LancasterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>LancasterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenized_text</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>filtered_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>tokenized_text</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>example_text</span> <span class=o>=</span> <span class=s2>&#34;This is a example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>processed_text</span> <span class=o>=</span> <span class=n>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>example_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Original Text: </span><span class=si>{</span><span class=n>example_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Processed Text: </span><span class=si>{</span><span class=n>processed_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=解释>解释</h3><p>好的，我们需要将文本预处理方法中的 <code>LancasterStemmer</code> 替换为 <code>PorterStemmer</code>。让我们导入 <code>PorterStemmer</code> 并修改代码以使用新的词干提取器。这里是调整后的代码：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Defining the stop words</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Creating an instance of PorterStemmer</span>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenized_text</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>filtered_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>tokenized_text</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>example_text</span> <span class=o>=</span> <span class=s2>&#34;This is an example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span class=line><span class=cl><span class=n>processed_text</span> <span class=o>=</span> <span class=n>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>example_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Original Text: </span><span class=si>{</span><span class=n>example_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Processed Text: </span><span class=si>{</span><span class=n>processed_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=具体解释>具体解释</h5><ol><li><p><strong>导入库和模块</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span></code></pre></td></tr></table></div></div><p>我们从 <code>nltk.corpus</code> 导入 <code>stopwords</code>，从 <code>nltk.stem</code> 导入 <code>PorterStemmer</code>，并从 <code>nltk.tokenize</code> 导入 <code>word_tokenize</code>。</p></li><li><p><strong>定义停止词</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>我们定义了一组停止词，这些是常见的、在分析中通常会被移除的词（如 &ldquo;is&rdquo;, &ldquo;and&rdquo;, &ldquo;the&rdquo; 等）。</p></li><li><p><strong>创建 PorterStemmer 实例</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>我们创建了一个 <code>PorterStemmer</code> 的实例，用于词干提取。</p></li><li><p><strong>定义去除停止词和词干提取的函数</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenized_text</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>filtered_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>tokenized_text</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>这个函数首先将输入文本进行分词，然后移除停止词并进行词干提取，最后将处理后的词重新组合成字符串。</p></li><li><p><strong>示例文本和处理结果</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>example_text</span> <span class=o>=</span> <span class=s2>&#34;This is an example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span class=line><span class=cl><span class=n>processed_text</span> <span class=o>=</span> <span class=n>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>example_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Original Text: </span><span class=si>{</span><span class=n>example_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Processed Text: </span><span class=si>{</span><span class=n>processed_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>我们使用示例文本来展示处理前后的效果。</p></li></ol><h5 id=运行结果>运行结果</h5><p>运行代码后，我们会看到处理前后的文本：</p><ul><li><strong>Original Text</strong>: This is an example text to demonstrate the removal of stop words and stemming.</li><li><strong>Processed Text</strong>: thi exampl text demonstr remov stop word stem</li></ul><p>可以观察到，使用 <code>PorterStemmer</code> 后，文本中的词被简化为它们的词干形式，例如 &ldquo;demonstrate&rdquo; 被简化为 &ldquo;demonstr&rdquo;。与 <code>LancasterStemmer</code> 相比，<code>PorterStemmer</code> 更为常用且更为温和，在实际应用中更为常见。</p><h2 id=practice-2>「Practice」</h2><p>Well done on completing the first practice, stellar navigator! Now it&rsquo;s time to put your skills further to the test.</p><p>The skeleton code for this task is already written for you. You just need to fill in the blank spots (<code>____</code>) to make the code run without errors.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>casual_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>string</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>____</span><span class=o>.</span><span class=n>____</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Adding string punctuation to stop words to filter them out</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stop_words</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>string</span><span class=o>.</span><span class=n>punctuation</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ex_text</span> <span class=o>=</span> <span class=s2>&#34;Here&#39;s a sample sentence to remove stop words from. It has generic and specific words.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Tokenize the sample sentence with casual_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ex_words</span> <span class=o>=</span> <span class=n>_____</span><span class=p>(</span><span class=n>ex_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Remove stop words and punctuation from the list of tokenized words</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>filtered_words</span> <span class=o>=</span> <span class=p>[</span><span class=n>word</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>ex_words</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Filtered words:&#34;</span><span class=p>,</span> <span class=n>filtered_words</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>当然，让我们一步一步地填补代码中的空白，并解释其中的主要知识点。</p><h4 id=填补空白>填补空白</h4><p>我们需要填补以下空白：</p><ol><li>从 <code>nltk.corpus</code> 导入 <code>stopwords</code>。</li><li>使用 <code>casual_tokenize</code> 函数来分词。</li><li>使用 <code>stopwords.words('english')</code> 获取英文停止词。</li></ol><p>填补后的代码如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>casual_tokenize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>string</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 获取英语停止词</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 将标点符号添加到停止词中</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>string</span><span class=o>.</span><span class=n>punctuation</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ex_text</span> <span class=o>=</span> <span class=s2>&#34;Here&#39;s a sample sentence to remove stop words from. It has generic and specific words.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用 casual_tokenize 分词</span>
</span></span><span class=line><span class=cl><span class=n>ex_words</span> <span class=o>=</span> <span class=n>casual_tokenize</span><span class=p>(</span><span class=n>ex_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 从分词后的单词列表中移除停止词和标点符号</span>
</span></span><span class=line><span class=cl><span class=n>filtered_words</span> <span class=o>=</span> <span class=p>[</span><span class=n>word</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>ex_words</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Filtered words:&#34;</span><span class=p>,</span> <span class=n>filtered_words</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=主要知识点解释>主要知识点解释</h4><ol><li><p><strong>导入必要模块</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>casual_tokenize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>string</span>
</span></span></code></pre></td></tr></table></div></div><p>我们从 <code>nltk.tokenize</code> 导入 <code>casual_tokenize</code> 函数用于分词，从 <code>nltk.corpus</code> 导入 <code>stopwords</code> 用于获取停止词，并导入 <code>string</code> 模块来处理标点符号。</p></li><li><p><strong>获取停止词并更新</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>string</span><span class=o>.</span><span class=n>punctuation</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>这里，我们使用 <code>stopwords.words('english')</code> 获取一组英语停止词，并将其转换为集合以便高效查找。然后，我们使用 <code>stop_words.update(string.punctuation)</code> 将所有标点符号添加到停止词集合中，以确保它们在后续处理中被移除。</p></li><li><p><strong>示例文本</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ex_text</span> <span class=o>=</span> <span class=s2>&#34;Here&#39;s a sample sentence to remove stop words from. It has generic and specific words.&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>我们定义了一个示例文本，其中包含了需要处理的单词和标点符号。</p></li><li><p><strong>分词</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ex_words</span> <span class=o>=</span> <span class=n>casual_tokenize</span><span class=p>(</span><span class=n>ex_text</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>使用 <code>casual_tokenize</code> 函数将示例文本分词，这个函数特别适用于处理社交媒体文本，因为它能处理缩略词、表情符号等。</p></li><li><p><strong>移除停止词和标点符号</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>filtered_words</span> <span class=o>=</span> <span class=p>[</span><span class=n>word</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>ex_words</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>这个列表推导式遍历了所有分词后的单词，移除了所有在 <code>stop_words</code> 集合中的单词。我们使用 <code>word.lower()</code> 确保比较时不区分大小写。</p></li><li><p><strong>输出结果</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Filtered words:&#34;</span><span class=p>,</span> <span class=n>filtered_words</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>最后，我们输出处理后的单词列表，这个列表不包含任何停止词或标点符号。</p></li></ol><h4 id=运行结果-1>运行结果</h4><p>假设代码成功运行，输出将是：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Filtered words: [&#39;sample&#39;, &#39;sentence&#39;, &#39;remove&#39;, &#39;stop&#39;, &#39;words&#39;, &#39;generic&#39;, &#39;specific&#39;, &#39;words&#39;]
</span></span></code></pre></td></tr></table></div></div><p>在这个结果中，所有的停止词（如 &ldquo;Here&rsquo;s&rdquo;, &ldquo;a&rdquo;, &ldquo;to&rdquo;, &ldquo;from&rdquo;, &ldquo;it&rdquo;, &ldquo;has&rdquo;）和标点符号都被移除了，只剩下有意义的单词。这种处理在文本分析和自然语言处理（NLP）中非常重要，有助于提高模型的性能和分析的准确性。</p><h2 id=practice-3>「Practice」</h2><p>Stellar work so far, Space Voyager! Now it&rsquo;s time to hone your skills in <em>stemming</em>. Fill in the blank spots (<code>____</code>) to make the code functional. Stem the provided words, and print the stemmed versions. Let&rsquo;s get processing!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>____</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># List of sample words</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>example_words</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;connection&#34;</span><span class=p>,</span> <span class=s2>&#34;connections&#34;</span><span class=p>,</span> <span class=s2>&#34;connective&#34;</span><span class=p>,</span> <span class=s2>&#34;connected&#34;</span><span class=p>,</span> <span class=s2>&#34;connecting&#34;</span><span class=p>,</span> <span class=s2>&#34;connection&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create object of the Porter Stemmer Class</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>____</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Stem each word in the list of words</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stemmed_words</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>____</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>example_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Stemmed words: &#34;</span><span class=p>,</span> <span class=n>stemmed_words</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
To fill in the blanks for this code using the NLTK library, let&rsquo;s detail the process of stemming words using the Porter Stemmer from NLTK. The code aims to create an instance of the Porter Stemmer class and use it to stem a list of example words.</p><p>Here&rsquo;s the expanded code with the blanks filled in:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># List of sample words</span>
</span></span><span class=line><span class=cl><span class=n>example_words</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;connection&#34;</span><span class=p>,</span> <span class=s2>&#34;connections&#34;</span><span class=p>,</span> <span class=s2>&#34;connective&#34;</span><span class=p>,</span> <span class=s2>&#34;connected&#34;</span><span class=p>,</span> <span class=s2>&#34;connecting&#34;</span><span class=p>,</span> <span class=s2>&#34;connection&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create object of the Porter Stemmer Class</span>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Stem each word in the list of words</span>
</span></span><span class=line><span class=cl><span class=n>stemmed_words</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>example_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Stemmed words: &#34;</span><span class=p>,</span> <span class=n>stemmed_words</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Explanation:</p><ol><li>The <code>from nltk.stem import PorterStemmer</code> line imports the Porter Stemmer class from the NLTK library.</li><li>The <code>example_words</code> list contains words that need to be stemmed.</li><li>The <code>stemmer = PorterStemmer()</code> line creates an instance of the Porter Stemmer class.</li><li>The list comprehension <code>[stemmer.stem(word) for word in example_words]</code> stems each word in the <code>example_words</code> list using the <code>stem</code> method of the Porter Stemmer instance.</li><li>The <code>print</code> statement outputs the stemmed words.</li></ol><h2 id=practice-4>「Practice」</h2><p>Celestial Traveler, let’s put our text preprocessing skills to the test. Can you add the missing line inside the function <code>remove_stopwords_and_stem</code> to tokenize the given text, remove stop words, stem the remaining words, and return the processed text? Give it a shot!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Defining the stop words</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Creating an instance of PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Add the code to tokenize the text, remove stopwords and apply stemming</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>example_text</span> <span class=o>=</span> <span class=s2>&#34;This is a example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>processed_text</span> <span class=o>=</span> <span class=n>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>example_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Original Text: </span><span class=si>{</span><span class=n>example_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Processed Text: </span><span class=si>{</span><span class=n>processed_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
Celestial Traveler, let’s put our text preprocessing skills to the test. Can you add the missing line inside the function <code>remove_stopwords_and_stem</code> to tokenize the given text, remove stop words, stem the remaining words, and return the processed text? Give it a shot!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Defining the stop words</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Creating an instance of PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Add the code to tokenize the text, remove stopwords and apply stemming</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>example_text</span> <span class=o>=</span> <span class=s2>&#34;This is a example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>processed_text</span> <span class=o>=</span> <span class=n>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>example_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Original Text: </span><span class=si>{</span><span class=n>example_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Processed Text: </span><span class=si>{</span><span class=n>processed_text</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>输出</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Original Text: This is an example text to demonstrate the removal of stop words and stemming.  
</span></span><span class=line><span class=cl>Processed Text: exampl text demonstr remov stop word stem .
</span></span></code></pre></td></tr></table></div></div><h2 id=practice-5>「Practice」</h2><p>Good job, Stellar Navigator! Could you now define the <strong>stop words</strong> and instantiate the <code>PorterStemmer</code> using NLTK&rsquo;s predefined English stop words and <code>PorterStemmer</code>? Additionally, could you implement the tokenization of the text, remove stop words, apply stemming, and return the processed text in the function <code>remove_stopwords_and_stem</code>? After doing so, you will preprocess the first newsgroup article and display it. The stars are in your favor!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Define the stop words and instantiate the PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Implement the process to tokenize the text, remove stopwords and apply stemming</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetching 20 newsgroups dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)[</span><span class=s1>&#39;data&#39;</span><span class=p>][:</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Process and display the first newsgroup article</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cleaned_data</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>newsgroups_data</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;First newsgroup article after cleaning and textual preprocessing:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>cleaned_data</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
Certainly, let’s complete the <code>clean_text</code> and <code>remove_stopwords_and_stem</code> functions by defining stop words, instantiating the Porter Stemmer, and implementing the text preprocessing steps.</p><p>Here is the complete code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define the stop words and instantiate the PorterStemmer</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s1>&#39;english&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>  <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_stopwords_and_stem</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Tokenize the text</span>
</span></span><span class=line><span class=cl>    <span class=n>tokens</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Remove stop words and apply stemming</span>
</span></span><span class=line><span class=cl>    <span class=n>filtered_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>tokens</span> <span class=k>if</span> <span class=n>word</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetching 20 newsgroups dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)[</span><span class=s1>&#39;data&#39;</span><span class=p>][:</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Process and display the first newsgroup article</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_data</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>newsgroups_data</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;First newsgroup article after cleaning and textual preprocessing:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>cleaned_data</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Explanation:</p><ol><li><code>stop_words</code> is defined using NLTK&rsquo;s predefined English stop words.</li><li><code>stemmer</code> is instantiated using NLTK&rsquo;s <code>PorterStemmer</code>.</li><li>In the <code>clean_text</code> function:<ul><li>The text is converted to lowercase.</li><li>Email addresses are removed.</li><li>URLs are removed.</li><li>Punctuation and special characters are removed.</li><li>Digits are removed.</li><li>Extra spaces are removed.</li><li>The text is processed by the <code>remove_stopwords_and_stem</code> function.</li></ul></li><li>In the <code>remove_stopwords_and_stem</code> function:<ul><li>The text is tokenized using <code>word_tokenize</code>.</li><li>Stop words are removed, and the remaining words are stemmed using a list comprehension.</li></ul></li><li>The first article from the 20 newsgroups dataset is processed and displayed.</li></ol><h3 id=output>output</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>First</span> <span class=n>newsgroup</span> <span class=n>article</span> <span class=n>after</span> <span class=n>cleaning</span> <span class=ow>and</span> <span class=n>textual</span> <span class=n>preprocessing</span><span class=p>:</span>  
</span></span><span class=line><span class=cl><span class=n>mamatha</span> <span class=n>devineni</span> <span class=n>ratnam</span> <span class=n>subject</span> <span class=n>pen</span> <span class=n>fan</span> <span class=n>reaction</span> <span class=n>organ</span> <span class=n>post</span> <span class=n>offic</span> <span class=n>carnegi</span> <span class=n>mellon</span> <span class=n>pittsburgh</span> <span class=n>pa</span> <span class=n>line</span> <span class=n>nntp</span> <span class=n>post</span> <span class=n>host</span> <span class=n>po</span> <span class=n>andrew</span> <span class=n>cmu</span> <span class=n>edu</span> <span class=n>sure</span> <span class=n>basher</span> <span class=n>pen</span> <span class=n>fan</span> <span class=n>pretti</span> <span class=n>confus</span> <span class=n>lack</span> <span class=n>kind</span> <span class=n>post</span> <span class=n>recent</span> <span class=n>pen</span> <span class=n>massacr</span> <span class=n>devil</span> <span class=n>actual</span> <span class=n>bit</span> <span class=n>puzzl</span> <span class=n>bit</span> <span class=n>reliev</span> <span class=n>howev</span> <span class=n>go</span> <span class=n>put</span> <span class=n>end</span> <span class=n>non</span> <span class=n>pittsburgh</span> <span class=n>relief</span> <span class=n>bit</span> <span class=n>prais</span> <span class=n>pen</span> <span class=n>man</span> <span class=n>kill</span> <span class=n>devil</span> <span class=n>wors</span> <span class=n>thought</span> <span class=n>jagr</span> <span class=n>show</span> <span class=n>much</span> <span class=n>better</span> <span class=n>regular</span> <span class=n>season</span> <span class=n>stat</span> <span class=n>also</span> <span class=n>lot</span> <span class=n>fo</span> <span class=n>fun</span> <span class=n>watch</span> <span class=n>playoff</span> <span class=n>bowman</span> <span class=n>let</span> <span class=n>jagr</span> <span class=n>lot</span> <span class=n>fun</span> <span class=nb>next</span> <span class=n>coupl</span> <span class=n>game</span> <span class=n>sinc</span> <span class=n>pen</span> <span class=n>go</span> <span class=n>beat</span> <span class=n>pulp</span> <span class=n>jersey</span> <span class=n>anyway</span> <span class=n>disappoint</span> <span class=n>see</span> <span class=n>island</span> <span class=n>lose</span> <span class=n>final</span> <span class=n>regular</span> <span class=n>season</span> <span class=n>game</span> <span class=n>pen</span> <span class=n>rule</span>
</span></span></code></pre></td></tr></table></div></div><h1 id=lesson4>lesson4</h1><p>Brace yourself for an out-of-this-world journey through text classification using n-grams! 🚀 We&rsquo;re getting closer to mastering this skill, and I&rsquo;m right here to navigate this adventure with you. Keep going, space explorer!</p><h5 id=topic-overview-and-goal>Topic Overview and Goal</h5><p>Hello, and welcome to today&rsquo;s lesson on <strong>n-grams</strong>! If you&rsquo;ve ever wondered how language models or text classifiers can understand the context or sequence in text, it&rsquo;s usually courtesy of our today&rsquo;s hero — n-grams. In this lesson, we&rsquo;ll delve into the magic of n-grams and how essential they prove in processing textual data. Specifically, we&rsquo;ll learn how to create n-grams from text data using Python, covering unigrams and bigrams.</p><h5 id=topic-overview-and-goal-1>Topic Overview and Goal</h5><p>Hello, and welcome to today&rsquo;s lesson on <strong>n-grams</strong>! If you&rsquo;ve ever wondered how language models or text classifiers can understand the context or sequence in text, it&rsquo;s usually courtesy of our today&rsquo;s hero — n-grams. In this lesson, we&rsquo;ll delve into the magic of n-grams and how essential they prove in processing textual data. Specifically, we&rsquo;ll learn how to create n-grams from text data using Python, covering unigrams and bigrams.</p><h4 id=what-are-n-grams>What are n-grams?</h4><p>In Natural Language Processing, when we analyze text, it&rsquo;s often beneficial to consider not only individual words but sequences of words. This approach helps to grasp the context better. Here is where n-grams come in handy.</p><p>An n-gram is a contiguous sequence of n items from a given sample of text or speech. The &rsquo;n&rsquo; stands for the number of words in the sequence. For instance, in &ldquo;I love dogs,&rdquo; a 1-gram (or unigram) is just one word, like &ldquo;love.&rdquo; A 2-gram (or bigram) would be a sequence of 2 words, like &ldquo;I love&rdquo; or &ldquo;love dogs&rdquo;.</p><p>N-grams help preserve the sequential information or context in text data, contributing significantly to many language models or text classifiers.</p><h4 id=preparing-data-for-n-grams-creation>Preparing Data for n-Grams Creation</h4><p>Before we can create n-grams, we need clean, structured text data. The text needs to be cleaned and preprocessed into a desirable format, after which it can be used for feature extraction or modeling.</p><p>Here&rsquo;s an already familiar code where we apply cleaning on our text, removing stop words and stemming the remaining words. These steps include lower-casing words, removing punctuations, useless words (stopwords), and reducing all words to their base or stemmed form.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Function to clean text and perform stemming</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>  <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>tokenized_text</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>filtered_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>tokenized_text</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=creating-n-grams-with-python-setting-up-the-vectorizer>Creating n-grams with Python: Setting up the Vectorizer</h3><p>Python&rsquo;s <code>sklearn</code> library provides an accessible way to generate n-grams. The <code>CountVectorizer</code> class in the <code>sklearn.feature_extraction.text</code> module can convert a given text into its matrix representation and allows us to specify the type of n-grams we want.</p><p>Let&rsquo;s set up our vectorizer as a preliminary step towards creating n-grams:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span> <span class=c1># Generate unigram and bigram</span>
</span></span></code></pre></td></tr></table></div></div><p>The <code>ngram_range=(1, 2)</code> parameter instructs our vectorizer to generate n-grams where n ranges from 1 to 2. So, the CountVectorizer will generate both unigrams and bigrams. If we wanted unigrams, bigrams, and trigrams, we could use `ngram_range=(1, 3</p><h5 id=creating-n-grams-with-python-applying-the-vectorizer>Creating n-grams with Python: Applying the Vectorizer</h5><p>Now that we&rsquo;ve set up our n-gram generating machine let&rsquo;s use it on some real-world data.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fetching 20 newsgroups dataset and restricting to first 100 records for performance</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)[</span><span class=s1>&#39;data&#39;</span><span class=p>][:</span><span class=mi>100</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Clean and preprocess the newsgroup data</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_data</span> <span class=o>=</span> <span class=p>[</span><span class=n>clean_text</span><span class=p>(</span><span class=n>data</span><span class=p>)</span> <span class=k>for</span> <span class=n>data</span> <span class=ow>in</span> <span class=n>newsgroups_data</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>Applying the vectorizer to our cleaned text data will create the n-grams:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the CountVectorizer on the cleaned data to create n-grams</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>cleaned_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the shape of X</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Shape of X with n-grams: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the total number of features</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Total number of features: &#34;</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>features</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print features from index 100 to 110</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Features from index 100 to 110: &#34;</span><span class=p>,</span> <span class=n>features</span><span class=p>[</span><span class=mi>100</span><span class=p>:</span><span class=mi>111</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Shape</span> <span class=n>of</span> <span class=n>X</span> <span class=k>with</span> <span class=n>n</span><span class=o>-</span><span class=n>grams</span><span class=p>:</span>  <span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>16246</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>Total</span> <span class=n>number</span> <span class=n>of</span> <span class=n>features</span><span class=p>:</span>  <span class=mi>16246</span>
</span></span><span class=line><span class=cl><span class=n>Features</span> <span class=kn>from</span> <span class=nn>index</span> <span class=mi>100</span> <span class=n>to</span> <span class=mi>110</span><span class=p>:</span>  <span class=p>[</span><span class=s1>&#39;accid figur&#39;</span> <span class=s1>&#39;accid worri&#39;</span> <span class=s1>&#39;accomod&#39;</span> <span class=s1>&#39;accomod like&#39;</span> <span class=s1>&#39;accord&#39;</span>
</span></span><span class=line><span class=cl> <span class=s1>&#39;accord document&#39;</span> <span class=s1>&#39;accord lynn&#39;</span> <span class=s1>&#39;accord mujanov&#39;</span> <span class=s1>&#39;accord previou&#39;</span>
</span></span><span class=line><span class=cl> <span class=s1>&#39;account&#39;</span> <span class=s1>&#39;account curiou&#39;</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>The shape of <code>X</code> is <code>(100, 16246)</code>, indicating we have a high-dimensional feature space. The first number, <code>100</code>, represents the number of documents or records in your dataset (here, it&rsquo;s 100 as we limited our fetching to the first 100 records of the dataset), whereas <code>16246</code> represents the unique n-grams or features created from all the 100 documents.</p><p>By printing <code>features[100:111]</code> we get a glance into our features where each string represents an n-gram from our cleaned text data. The returned n-grams <code>['accid figur', 'accid worri', 'accomod', ...]</code> include both unigrams (single words like <code>accomod</code>, <code>account</code>) and bigrams (two-word phrases like <code>accid figur</code>, <code>accid worri</code>).</p><p>As you can see, generating n-grams adds a new level of complexity to our analysis, as we now have multiple types of features or tokens - unigrams and bigrams. You can experiment with the <code>ngram_range</code> parameter in <code>CountVectorizer</code> to include trigrams or higher-level n-grams, depending on your specific context and requirements. Remember, each choice will have implications for the complexity and interpretability of your models, and it&rsquo;s always a balance between the two.</p><h5 id=lesson-summary-1>Lesson Summary</h5><p>Congratulations, you&rsquo;ve finished today&rsquo;s lesson on n-grams! We&rsquo;ve explored what n-grams are and their importance in text classification. We then moved on to preparing data for creating n-grams before we dived into generating them using Python&rsquo;s <code>CountVectorizer</code> class in the <code>sklearn</code> library.</p><p>Now, it&rsquo;s time to get hands-on. Try generating trigrams or 4-grams from the same cleaned newsgroups data and notice the differences. Practicing these skills will not only reinforce the concepts learned in this lesson but also enable you to understand when and how much context is needed for certain tasks.</p><p>As always, happy learning!</p><h3 id=practice1-2>「Practice1」</h3><p>Excellent work, Space Voyager! Now, let&rsquo;s deepen our understanding of <strong>n-grams</strong> in Python. Modify the <code>ngram_range</code> parameter in <code>CountVectorizer</code> in the starter code to generate only <strong>bigrams</strong> and <strong>trigrams</strong>, instead of unigrams, bigrams, and trigrams. Change <code>ngram_range</code> from <code>(1, 3)</code> to <code>(2, 3)</code>. Display the output and observe the differences.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s2>&#34;english&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define function for text cleaning and stemming</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove extra spaces</span>
</span></span></code></pre></td></tr></table></div></div><p>Here is the modified code to generate only bigrams and trigrams using CountVectorizer:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s2>&#34;english&#34;</span><span class=p>))</span> 
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define function for text cleaning and stemming</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses </span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Tokenize text and remove stop words</span>
</span></span><span class=line><span class=cl>    <span class=n>tokens</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tokens</span> <span class=o>=</span> <span class=p>[</span><span class=n>token</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokens</span> <span class=k>if</span> <span class=n>token</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Stem tokens</span>
</span></span><span class=line><span class=cl>    <span class=n>stemmed_tokens</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>token</span><span class=p>)</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokens</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s1>&#39; &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>stemmed_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load 20 newsgroups dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_train</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>,</span> <span class=n>remove</span><span class=o>=</span><span class=p>(</span><span class=s1>&#39;headers&#39;</span><span class=p>,</span> <span class=s1>&#39;footers&#39;</span><span class=p>,</span> <span class=s1>&#39;quotes&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Clean and preprocess text </span>
</span></span><span class=line><span class=cl><span class=n>cleaned_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span> <span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>newsgroups_train</span><span class=o>.</span><span class=n>data</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize CountVectorizer with bigrams and trigrams only</span>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit and transform cleaned text</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>cleaned_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get feature names</span>
</span></span><span class=line><span class=cl><span class=n>feature_names</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print some bigrams and trigrams</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Some bigrams and trigrams:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>feature_names</span><span class=p>[:</span><span class=mi>20</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>Output:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Some bigrams and trigrams:
</span></span><span class=line><span class=cl>[&#39;aa aa&#39; &#39;aa ab&#39; &#39;aa ac&#39; &#39;aa ag&#39; &#39;aa al&#39; &#39;aa am&#39; &#39;aa ap&#39; &#39;aa ar&#39; &#39;aa at&#39; &#39;aa au&#39;
</span></span><span class=line><span class=cl> &#39;aa av&#39; &#39;aa aw&#39; &#39;aa ax&#39; &#39;aa ba&#39; &#39;aa be&#39; &#39;aa bi&#39; &#39;aa bl&#39; &#39;aa bo&#39; &#39;aa br&#39; &#39;aa bu&#39;]
</span></span></code></pre></td></tr></table></div></div><p>Key changes made:</p><ul><li>Modified <code>ngram_range</code> from <code>(1, 3)</code> to <code>(2, 3)</code> in the CountVectorizer initialization to generate only bigrams and trigrams</li><li>Printed out the first 20 features from <code>feature_names</code> to show some example bigrams and trigrams</li></ul><p>By changing the <code>ngram_range</code> to <code>(2, 3)</code>, the output now contains only bigram and trigram features, without any unigrams. This allows capturing more context by considering pairs and triplets of words together[1][2].</p><p>The bigrams and trigrams can provide additional insights compared to just unigrams. For example, &ldquo;new york&rdquo; as a bigram has a different meaning than the individual unigrams &ldquo;new&rdquo; and &ldquo;york&rdquo;[4]. Trigrams extend this to three word phrases.</p><p>However, using higher-order n-grams also increases the dimensionality of the feature space substantially[3]. So there is a tradeoff between capturing more context with longer n-grams versus the resulting size of the vocabulary.</p><p>Citations:
[1] <a href=https://stackoverflow.com/questions/24005762/understanding-the-ngram-range-argument-in-a-countvectorizer-in-sklearn>https://stackoverflow.com/questions/24005762/understanding-the-ngram-range-argument-in-a-countvectorizer-in-sklearn</a>
[2] <a href=https://www.ibm.com/reference/python/countvectorizer>https://www.ibm.com/reference/python/countvectorizer</a>
[3] <a href=https://maartengr.github.io/BERTopic/getting_started/vectorizers/vectorizers.html>https://maartengr.github.io/BERTopic/getting_started/vectorizers/vectorizers.html</a>
[4] <a href=https://pages.github.rpi.edu/kuruzj/website_introml_rpi/notebooks/08-intro-nlp/03-scikit-learn-text.html>https://pages.github.rpi.edu/kuruzj/website_introml_rpi/notebooks/08-intro-nlp/03-scikit-learn-text.html</a>
[5] <a href=https://kavita-ganesan.com/how-to-use-countvectorizer/>https://kavita-ganesan.com/how-to-use-countvectorizer/</a></p><p>Let&rsquo;s deepen our understanding of n-grams in Python by modifying the <code>ngram_range</code> parameter in <code>CountVectorizer</code>. We&rsquo;ll change it to generate only bigrams and trigrams, instead of unigrams, bigrams, and trigrams. Here’s the complete code including the necessary modifications and output display:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s2>&#34;english&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define function for text cleaning and stemming</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>  <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>    <span class=n>words</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>  <span class=c1># Tokenize the text</span>
</span></span><span class=line><span class=cl>    <span class=n>words</span> <span class=o>=</span> <span class=p>[</span><span class=n>word</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>words</span> <span class=k>if</span> <span class=n>word</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>  <span class=c1># Remove stop words</span>
</span></span><span class=line><span class=cl>    <span class=n>words</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>words</span><span class=p>]</span>  <span class=c1># Apply stemming</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s1>&#39; &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>words</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the dataset</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>corpus</span> <span class=o>=</span> <span class=n>newsgroups_data</span><span class=o>.</span><span class=n>data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Clean the text data</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_corpus</span> <span class=o>=</span> <span class=p>[</span><span class=n>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>)</span> <span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>corpus</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize CountVectorizer with ngram_range set to (2, 3)</span>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>cleaned_corpus</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Convert the output to a DataFrame for better readability</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get feature names and create DataFrame</span>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>(),</span> <span class=n>columns</span><span class=o>=</span><span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the DataFrame</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>ace_tools</span> <span class=k>as</span> <span class=nn>tools</span><span class=p>;</span> <span class=n>tools</span><span class=o>.</span><span class=n>display_dataframe_to_user</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s2>&#34;N-gram Feature Matrix&#34;</span><span class=p>,</span> <span class=n>dataframe</span><span class=o>=</span><span class=n>df</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>In this script:</p><ol><li><strong>Data Cleaning</strong>: We clean and preprocess the text data by removing email addresses, URLs, punctuation, special characters, and digits. We also remove stop words and apply stemming.</li><li><strong>CountVectorizer</strong>: We set the <code>ngram_range</code> to <code>(2, 3)</code> in the <code>CountVectorizer</code>, which will generate only bigrams and trigrams.</li><li><strong>Output Display</strong>: The transformed data is converted into a DataFrame to display the bigrams and trigrams.</li></ol><p>Running this code will generate a feature matrix where the features are bigrams and trigrams extracted from the text data. You will be able to see the differences compared to when unigrams are included in the feature set.</p><h3 id=practice-6>「Practice」</h3><p>For the next task, we will simplify our data input and use a simple short string. Through this, we will generate bigrams and trigrams from it. This will give us a more immediate understanding of generating n-grams. Can you fill in the blanks (<code>____</code>) to get the code up and running? Remember, we need to use <code>CountVectorizer</code> to generate bigrams and trigrams. After that, display the features created.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Simple short text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s2>&#34;I love studying data science&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Setup the CountVectorizer to generate bigrams and trigrams</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>____</span><span class=p>(</span><span class=n>ngram_range</span><span class=o>=</span><span class=n>____</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the CountVectorizer on the text to create n-grams</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>([</span><span class=n>text</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the shape of X and some features</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Shape of X with n-grams: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Features: &#34;</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Here&rsquo;s the completed code with the necessary blanks filled in to generate bigrams and trigrams using <code>CountVectorizer</code>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Simple short text</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s2>&#34;I love studying data science&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Setup the CountVectorizer to generate bigrams and trigrams</span>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the CountVectorizer on the text to create n-grams</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>([</span><span class=n>text</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the shape of X and some features</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Shape of X with n-grams: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Features: &#34;</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>In this code:</p><ul><li><code>CountVectorizer(ngram_range=(2, 3))</code> sets up the vectorizer to create bigrams (2-grams) and trigrams (3-grams).</li><li>The <code>fit_transform</code> method is applied to the input text to create the n-grams.</li><li>The shape of the resulting matrix <code>X</code> is printed, as well as the feature names, which represent the bigrams and trigrams generated from the text.</li></ul><blockquote><p>[!tip]</p></blockquote><h3 id=practice3generating-bigrams-and-trigrams-from-two-texts>Practice 3：Generating Bigrams and Trigrams from Two Texts</h3><p>Bravo, Space Voyager! Now let&rsquo;s try generating n-grams again, but with slightly different text. However, this time, the <code>fit_transform</code> function and its invoker have been removed. You need to fill in the blanks (<code>____</code>) to get the code running successfully.</p><p>The <code>fit_transform</code> function takes input as a list of texts. It will transform the texts into a matrix of token counts and return a sparse representation of this matrix, which we are storing as <code>X</code>. The <code>fit_transform</code> function is convenient when we want to learn a vocabulary dictionary and return document-term matrix at the same time.</p><p>For this exercise, we&rsquo;ve made it a bit easier and more meaningful. We&rsquo;re only generating unigrams (individual words) this time, meaning n is equal to 1.</p><p>The text we&rsquo;re using this time is not a proper English sentence but a list of stemmed words to better illustrate how n-grams work on a finer level.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define two simple short texts</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text1</span> <span class=o>=</span> <span class=s2>&#34;data love data science passion&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text2</span> <span class=o>=</span> <span class=s2>&#34;science love algorithm data passion&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Setup the CountVectorizer to generate unigrams only</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the CountVectorizer on the text to create n-grams</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>____</span><span class=o>.</span><span class=n>____</span><span class=p>([</span><span class=n>text1</span><span class=p>,</span> <span class=n>text2</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the shape of X and some features</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Shape of X with n-grams: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Features: &#34;</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Matrix X: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
Sure, let&rsquo;s complete the code snippet to use <code>CountVectorizer</code> to generate unigrams and transform the input texts into a matrix of token counts.</p><p>Here&rsquo;s the completed code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define two simple short texts</span>
</span></span><span class=line><span class=cl><span class=n>text1</span> <span class=o>=</span> <span class=s2>&#34;data love data science passion&#34;</span>
</span></span><span class=line><span class=cl><span class=n>text2</span> <span class=o>=</span> <span class=s2>&#34;science love algorithm data passion&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Setup the CountVectorizer to generate unigrams only</span>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the CountVectorizer on the text to create n-grams</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>([</span><span class=n>text1</span><span class=p>,</span> <span class=n>text2</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the shape of X and some features</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Shape of X with n-grams: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Features: &#34;</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Matrix X: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>In this snippet:</p><ul><li>The <code>CountVectorizer</code> is set up to generate unigrams (n-gram range of 1, 1).</li><li>The <code>fit_transform</code> method of <code>vectorizer</code> is applied to the list of texts <code>[text1, text2]</code> to create the document-term matrix <code>X</code>.</li><li>The shape of <code>X</code>, the feature names (unigrams), and the dense representation of the matrix <code>X</code> are printed out.</li></ul><p>This will output the shape of the matrix, the features (unique unigrams), and the matrix itself, showing the counts of each unigram in the given texts.</p><h1 id=practice-7>「Practice」</h1><p>You are doing an excellent job, Galactic Pioneer!</p><p>Now, let&rsquo;s dive a bit deeper into creating <strong>bigrams</strong>. Set up the <code>CountVectorizer</code> to generate bigrams, then apply it to the cleaned data. Once you accomplish this, you&rsquo;ll need to display the <code>shape</code> of <code>X</code>, the <code>feature names</code>, and the matrix <code>X</code>. You can do it!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span><span class=lnt>91
</span><span class=lnt>92
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s2>&#34;english&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define function for text cleaning and stemming</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span> <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenized_text</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>filtered_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>tokenized_text</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Simple short sentences</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text1</span> <span class=o>=</span> <span class=s2>&#34;I love studying data science&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text2</span> <span class=o>=</span> <span class=s2>&#34;Science is a field I am passionate about&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text3</span> <span class=o>=</span> <span class=s2>&#34;Algorithms fascinate me&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text4</span> <span class=o>=</span> <span class=s2>&#34;It is a joy to work on data algorithms&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Clean and preprocess the text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_1</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_2</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_3</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_4</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Setup the CountVectorizer to generate bigrams only</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Apply the CountVectorizer on the cleaned data to create n-grams</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the shape of X and some features</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Shape of X with n-grams: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Features: &#34;</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Matrix X: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
To generate bigrams from the given cleaned data, we need to use <code>CountVectorizer</code> from the <code>sklearn.feature_extraction.text</code> module with the parameter <code>ngram_range</code> set to <code>(2, 2)</code>. This will configure the <code>CountVectorizer</code> to create bigrams.</p><p>Here&rsquo;s the complete code, including the setup of <code>CountVectorizer</code> to generate bigrams, applying it to the cleaned data, and then displaying the shape of <code>X</code>, the feature names, and the matrix <code>X</code>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s2>&#34;english&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define function for text cleaning and stemming</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>  <span class=c1># Convert text to lower case</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove email addresses</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove URLs</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove punctuation and special characters</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove digits</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># Remove extra spaces</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>tokenized_text</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>filtered_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>tokenized_text</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Simple short sentences</span>
</span></span><span class=line><span class=cl><span class=n>text1</span> <span class=o>=</span> <span class=s2>&#34;I love studying data science&#34;</span>
</span></span><span class=line><span class=cl><span class=n>text2</span> <span class=o>=</span> <span class=s2>&#34;Science is a field I am passionate about&#34;</span>
</span></span><span class=line><span class=cl><span class=n>text3</span> <span class=o>=</span> <span class=s2>&#34;Algorithms fascinate me&#34;</span>
</span></span><span class=line><span class=cl><span class=n>text4</span> <span class=o>=</span> <span class=s2>&#34;It is a joy to work on data algorithms&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Clean and preprocess the text</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_1</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_2</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_3</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_4</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cleaned_data</span> <span class=o>=</span> <span class=p>[</span><span class=n>cleaned_text_1</span><span class=p>,</span> <span class=n>cleaned_text_2</span><span class=p>,</span> <span class=n>cleaned_text_3</span><span class=p>,</span> <span class=n>cleaned_text_4</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Setup the CountVectorizer to generate bigrams only</span>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply the CountVectorizer on the cleaned data to create bigrams</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>cleaned_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Display the shape of X and some features</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Shape of X with n-grams: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Features: &#34;</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Matrix X: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=explanation-1>Explanation</h3><ol><li><strong>Import Libraries</strong>: Necessary libraries are imported, including <code>CountVectorizer</code>, <code>stopwords</code>, <code>word_tokenize</code>, and <code>PorterStemmer</code>.</li><li><strong>Clean Text Function</strong>: A function <code>clean_text</code> is defined to preprocess and clean the input text by removing email addresses, URLs, punctuation, digits, and extra spaces. It also converts text to lowercase and stems the words, removing stopwords.</li><li><strong>Clean and Preprocess</strong>: Four short sentences are defined, cleaned, and preprocessed using the <code>clean_text</code> function.</li><li><strong>CountVectorizer for Bigrams</strong>: A <code>CountVectorizer</code> is set up with <code>ngram_range=(2, 2)</code> to generate bigrams only.</li><li><strong>Apply CountVectorizer</strong>: The vectorizer is applied to the cleaned data to create a bigram frequency matrix <code>X</code>.</li><li><strong>Display Results</strong>: The shape of <code>X</code>, the feature names (bigrams), and the matrix <code>X</code> itself are printed.</li></ol><p>This code effectively preprocesses the text, generates bigrams, and displays the results as required.
好的，我来用三年级儿童能理解的方式解释这个过程！</p><h3 id=清理和处理文本>清理和处理文本</h3><p>我们先要清理和处理这些句子，就像整理书桌一样，把不需要的东西清理掉。我们有一些句子：</p><ul><li>我爱学习数据科学</li><li>科学是我热爱的领域</li><li>算法让我着迷</li><li>工作在数据算法上是一种快乐</li></ul><p>我们做这些清理工作：</p><ol><li><strong>变成小写字母</strong>：把所有大写字母变成小写。</li><li><strong>去掉多余的东西</strong>：比如去掉邮件地址、网址、标点符号、数字和多余的空格。</li><li><strong>去掉不需要的词</strong>：比如“的”、“是”等这些常用词。</li><li><strong>词根化</strong>：把不同形式的词变成它们的基本形式，比如“学习”和“学”就变成一样的。</li></ol><h3 id=创建二元组bigrams>创建二元组（bigrams）</h3><p>接下来，我们要把句子变成一对一对的词，比如“数据科学”就变成了一个二元组。就像我们把糖果配对成糖果对一样。</p><p>我们用一个工具叫<code>CountVectorizer</code>来做这个工作。这个工具会帮助我们找到所有句子里的词对，并数一数每个词对出现了多少次。</p><h3 id=结果>结果</h3><p>我们把这些清理后的句子用<code>CountVectorizer</code>工具处理，得到这些结果：</p><ol><li><strong>形状</strong>：就像我们把所有的糖果对放在一个大盒子里，看一看这个盒子有多大。</li><li><strong>特征（词对）</strong>：我们列出所有的词对，看看有哪些词对，比如“数据 科学”、“科学 热爱”等。</li><li><strong>矩阵</strong>：我们得到一个表格，告诉我们每个句子里有多少次出现了这些词对。</li></ol><h3 id=完整代码>完整代码</h3><p>下面是我们完整的代码，你可以想象这是一个超级机器人，帮我们做所有这些工作：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 导入必要的工具</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>stopwords</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.tokenize</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.stem</span> <span class=kn>import</span> <span class=n>PorterStemmer</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 停用词列表和词干提取器</span>
</span></span><span class=line><span class=cl><span class=n>stop_words</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>stopwords</span><span class=o>.</span><span class=n>words</span><span class=p>(</span><span class=s2>&#34;english&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>stemmer</span> <span class=o>=</span> <span class=n>PorterStemmer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义清理文本的函数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clean_text</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>  <span class=c1># 变成小写字母</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\S*@\S*\s?&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># 去掉邮件地址</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;http\S+&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># 去掉网址</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\W&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># 去掉标点符号</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\d&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># 去掉数字</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>sub</span><span class=p>(</span><span class=sa>r</span><span class=s1>&#39;\s\s+&#39;</span><span class=p>,</span> <span class=s1>&#39; &#39;</span><span class=p>,</span> <span class=n>text</span><span class=p>)</span>  <span class=c1># 去掉多余的空格</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>tokenized_text</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>filtered_text</span> <span class=o>=</span> <span class=p>[</span><span class=n>stemmer</span><span class=o>.</span><span class=n>stem</span><span class=p>(</span><span class=n>word</span><span class=p>)</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>tokenized_text</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>stop_words</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>filtered_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 一些简单的短句</span>
</span></span><span class=line><span class=cl><span class=n>text1</span> <span class=o>=</span> <span class=s2>&#34;I love studying data science&#34;</span>
</span></span><span class=line><span class=cl><span class=n>text2</span> <span class=o>=</span> <span class=s2>&#34;Science is a field I am passionate about&#34;</span>
</span></span><span class=line><span class=cl><span class=n>text3</span> <span class=o>=</span> <span class=s2>&#34;Algorithms fascinate me&#34;</span>
</span></span><span class=line><span class=cl><span class=n>text4</span> <span class=o>=</span> <span class=s2>&#34;It is a joy to work on data algorithms&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 清理和处理文本</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_1</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_2</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_3</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>cleaned_text_4</span> <span class=o>=</span> <span class=n>clean_text</span><span class=p>(</span><span class=n>text4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cleaned_data</span> <span class=o>=</span> <span class=p>[</span><span class=n>cleaned_text_1</span><span class=p>,</span> <span class=n>cleaned_text_2</span><span class=p>,</span> <span class=n>cleaned_text_3</span><span class=p>,</span> <span class=n>cleaned_text_4</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 设置CountVectorizer只生成二元组</span>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>(</span><span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 应用CountVectorizer到清理后的数据上，生成二元组</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>cleaned_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 显示X的形状和一些特征</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;X的形状: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>features</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;特征: &#34;</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;矩阵X: &#34;</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>希望这个解释对你有帮助！这样我们就可以用这些工具来分析和理解文本中的词对啦！</p><h5 id=introduction-and-overview>Introduction and Overview</h5><p>引言与概述</p><p>Ready for our next lesson? Today, we&rsquo;re delving into <strong>quantiles</strong> and the <strong>Interquartile Range</strong> (IQR). Quantiles divide our data into equal parts, and the IQR reveals where half of our data lies. These tools aid us in understanding the distribution of our data and in identifying outliers. With Python&rsquo;s <code>pandas</code> and <code>NumPy</code> libraries, we&rsquo;ll explore how to calculate these measures.<br>准备好下一课了吗？今天，我们将深入探讨分位数和四分位距 (IQR)。分位数将我们的数据分成相等的部分，而 IQR 揭示了我们数据的一半位于何处。这些工具帮助我们理解数据的分布并识别异常值。我们将使用 Python 的 <code>pandas</code> 和 <code>NumPy</code> 库来探索如何计算这些指标。</p><h5 id=defining-quantiles分位数的定义>Defining Quantiles 分位数的定义</h5><p>Quantiles segment data into equal intervals. For example, when we divide a group of student grades into four equal parts, we employ quartiles (Q1 - 25th percentile, Q2 - 50th percentile or median, and Q3 - 75th percentile).<br>分位数将数据分割成相等的区间。例如，当我们将一组学生成绩分成四个相等的部分时，我们使用的是四分位数（Q1 - 第 25 百分位数，Q2 - 第 50 百分位数或中位数，以及 Q3 - 第 75 百分位数）。</p><h5 id=understanding-the-interquartile-range>Understanding the Interquartile Range</h5><p>理解四分位距</p><p>The <strong>Interquartile Range</strong> (IQR) shows where half of our data lies. It&rsquo;s resistant to outliers; for instance, when analyzing salaries, the IQR omits extreme values, thereby depicting the range where most salaries fall.<br>四分位距（IQR）显示了我们数据中一半数据的位置。它不受异常值的影响；例如，在分析工资时，IQR 会忽略极端值，从而描述大多数工资所在的范围。</p><h5 id=calculating-quantiles-with-python>Calculating Quantiles with Python</h5><p>使用 Python 计算分位数</p><p>Python&rsquo;s <code>NumPy</code> function, <code>percentile()</code>, calculates quantiles.<br>Python 的 <code>NumPy</code> 函数 <code>percentile()</code> 用于计算分位数。</p><p>Quantiles are essentially just cuts at specific points in your data when it&rsquo;s sorted in ascending order. The first quartile (Q1) is the point below which 25% of the data falls, while the third quartile (Q3) is the point below which 75% of the data falls. The second quartile or the median is the mid-point of the data when it&rsquo;s sorted in ascending order.<br>分位数本质上是在按升序排序的数据中特定点的切割。第一个四分位数 (Q1) 是指低于该点的数据占 25%，而第三个四分位数 (Q3) 是指低于该点的数据占 75%。第二个四分位数或中位数是数据按升序排序时的中间点。</p><p>These values are important in identifying the spread and skewness of your data. Let&rsquo;s consider a dataset of student scores:<br>这些值对于确定数据的离散程度和偏度非常重要。让我们考虑一个学生分数数据集：</p><p>Python</p><p>CopyPlay</p><p><code>1import numpy as np 2 3scores = np.array([76, 85, 67, 45, 89, 70, 92, 82]) 4 5# Calculate median 6median_w1 = np.percentile(scores, 50) 7print(median_w1) # Output: 79.0 8# Check if it is the same as median 9median_w2 = np.median(scores) 10print(median_w2) # Output 79.0 11 12# Calculate Q1 and Q3 13Q1 = np.percentile(scores, 25) 14print(Q1) # Output: 69.25 15Q3 = np.percentile(scores, 75) 16print(Q3) # Output: 86.0</code></p><p>Here, <code>percentile()</code> is used to calculate the 1st, 2nd and 3rd quartiles. When we input 25, the function gives us the value below which 25% of the data lies, i.e., the first quartile Q1. Similarly, when we input 75, it gives the third quartile Q3. The 50th percentile is the median of the dataset.<br>这里， <code>percentile()</code> 被用来计算第一、第二和第三四分位数。当我们输入 25 时，函数给出的是数据中 25%低于该值的值，即第一四分位数 Q1。同样，当我们输入 75 时，它给出的是第三四分位数 Q3。第 50 个百分位数是数据集的中位数。</p><h5 id=calculating-the-interquartile-range-with-python>Calculating the Interquartile Range with Python</h5><p>使用 Python 计算四分位距</p><p>The <strong>Interquartile Range</strong> (<code>IQR</code>) is computed as <code>Q3 - Q1</code>.<br>四分位距（ <code>IQR</code> ）计算公式为 <code>Q3 - Q1</code> 。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>math_scores</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
</span></span><span class=line><span class=cl>  <span class=s1>&#39;Name&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Jerome&#39;</span><span class=p>,</span> <span class=s1>&#39;Jessica&#39;</span><span class=p>,</span> <span class=s1>&#39;Jeff&#39;</span><span class=p>,</span> <span class=s1>&#39;Jennifer&#39;</span><span class=p>,</span> <span class=s1>&#39;Jackie&#39;</span><span class=p>,</span> <span class=s1>&#39;Jimmy&#39;</span><span class=p>,</span> <span class=s1>&#39;Joshua&#39;</span><span class=p>,</span> <span class=s1>&#39;Julia&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=s1>&#39;Score&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>56</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>54</span><span class=p>,</span> <span class=mi>48</span><span class=p>,</span> <span class=mi>49</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>62</span><span class=p>,</span> <span class=mi>55</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># IQR for scores</span>
</span></span><span class=line><span class=cl><span class=n>Q1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>math_scores</span><span class=p>[</span><span class=s1>&#39;Score&#39;</span><span class=p>],</span> <span class=mi>25</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>Q3</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>math_scores</span><span class=p>[</span><span class=s1>&#39;Score&#39;</span><span class=p>],</span> <span class=mi>75</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>IQR</span> <span class=o>=</span> <span class=n>Q3</span> <span class=o>-</span> <span class=n>Q1</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>IQR_score</span><span class=p>)</span>  <span class=c1># Output: 8.75</span>
</span></span></code></pre></td></tr></table></div></div><p>The IQR represents the range within which the middle half of the scores fall. It exposes potential outliers, defined as values that either lie below <code>Q1 - 1.5 * IQR</code> or above <code>Q3 + 1.5 * IQR</code>. Multiplying the <code>IQR</code> by <code>1.5</code> roughly sets a boundary that encapsulates <code>99.3</code>% of the data assuming a normal distribution. So anything outside this range could be viewed as potential outliers.<br>IQR 表示一半数据所在的范围。它揭示了潜在的异常值，定义为低于 <code>Q1 - 1.5 * IQR</code> 或高于 <code>Q3 + 1.5 * IQR</code> 的值。将 <code>IQR</code> 乘以 <code>1.5</code> 大致设定了一个边界，在假设数据呈正态分布的情况下，该边界包含了 <code>99.3</code> %的数据。因此，超出此范围的任何数据点都可能被视为潜在的异常值。</p><p>This boundary of <code>1.5</code> times the <code>IQR</code> is a generally accepted rule of thumb and helps to balance between being overly sensitive to slight deviations in the data versus not being sensitive enough to detect potential anomalies or outliers. This rule is particularly useful when data is large and complex when it&rsquo;s hard to discern outliers just by observation.<br><code>1.5</code> 倍 <code>IQR</code> 的边界是一条普遍接受的经验法则，它有助于在对数据的轻微偏差过于敏感和对检测潜在异常值或离群值不够敏感之间取得平衡。当数据量大且复杂，仅凭观察难以识别异常值时，这条规则特别有用。</p><h5 id=finding-outliers查找异常值>Finding Outliers 查找异常值</h5><p>Let&rsquo;s select and print out all the outliers using the rule above. We will apply <code>NumPy</code>&rsquo;s boolean selection, which works just fine with <code>pandas</code>:<br>让我们使用上述规则选择并打印出所有异常值。我们将应用 <code>NumPy</code> 的布尔选择，它与 <code>pandas</code> 可以很好地配合使用：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>scores</span> <span class=o>=</span> <span class=n>math_scores</span><span class=p>[</span><span class=s1>&#39;Score&#39;</span><span class=p>]</span>  <span class=c1># to simplify next expression</span>
</span></span><span class=line><span class=cl><span class=n>outliers_scores</span> <span class=o>=</span> <span class=n>scores</span><span class=p>[(</span><span class=n>scores</span> <span class=o>&lt;</span> <span class=n>Q1</span> <span class=o>-</span> <span class=mf>1.5</span> <span class=o>*</span> <span class=n>IQR</span><span class=p>)</span> <span class=o>|</span> <span class=p>(</span><span class=n>scores</span> <span class=o>&gt;</span> <span class=n>Q3</span> <span class=o>+</span> <span class=mf>1.5</span> <span class=o>*</span> <span class=n>IQR</span><span class=p>)]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>outliers_scores</span><span class=p>)</span>  <span class=c1># Outputs 13 and 100</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=summary-and-look-ahead总结与展望>Summary and Look Ahead 总结与展望</h5><p>Congratulations! You&rsquo;ve learned about two key statistical measures: quantiles and the <strong>Interquartile Range</strong>, as well as how to calculate them using Python.<br>恭喜！您已经学习了两个关键的统计指标：分位数和四分位距，以及如何使用 Python 计算它们。</p><p>In the next lesson, we&rsquo;ll practice these concepts; prepare for some hands-on exercises. Practice aids in mastering these concepts. Let&rsquo;s get started. Are you ready for the next lesson? Happy learning!<br>下一课我们将练习这些概念，准备好进行一些实践练习。练习有助于掌握这些概念。让我们开始吧。你准备好下一课了吗？祝你学习愉快！</p><h5 id=introduction-1>Introduction</h5><p>Welcome to our lesson on <strong>Named Entity Recognition</strong>! Today, we&rsquo;ll be diving deep into the world of <strong>NLP</strong> and discovering how we can identify informative chunks of text, namely &ldquo;Named Entities&rdquo;. The goal of this lesson is to learn about <strong>Part of Speech (POS) tagging</strong> and <strong>Named Entity Recognition (NER)</strong>. By the end, you&rsquo;ll be able to gather specific types of data from text and get a few steps closer to mastering text classification.</p><h1 id=lesson-1>lesson</h1><h5 id=introduction引言-1>Introduction 引言</h5><p>Welcome to our lesson on <strong>Named Entity Recognition</strong>! Today, we&rsquo;ll be diving deep into the world of <strong>NLP</strong> and discovering how we can identify informative chunks of text, namely &ldquo;Named Entities&rdquo;. The goal of this lesson is to learn about <strong>Part of Speech (POS) tagging</strong> and <strong>Named Entity Recognition (NER)</strong>. By the end, you&rsquo;ll be able to gather specific types of data from text and get a few steps closer to mastering text classification.<br>欢迎来到我们的命名实体识别课程！今天，我们将深入 NLP 的世界，探索如何识别信息丰富的文本块，即“命名实体”。本课程的目标是学习词性 (POS) 标注和命名实体识别 (NER)。在本课程结束时，您将能够从文本中收集特定类型的数据，并向掌握文本分类迈进几步。</p><h5 id=what-is-named-entity-recognition>What is Named Entity Recognition?</h5><p>命名实体识别是什么？</p><p>Imagine we have a piece of text and we want to get some quick insights. What are the main subjects? Are there any specific locations or organizations being talked about? This is where Named Entity Recognition (NER) comes in handy.<br>假设我们有一段文本，我们想快速了解它。主要主题是什么？有没有提到具体的地点或组织？这就是命名实体识别 (NER) 的用武之地。
In natural language processing (NLP), NER is a subtask of information extraction that seeks to locate and classify named entities in text into pre-defined categories such as names of persons, organizations, locations, expressions of times, quantities, monetary values, and percentages.<br>在自然语言处理（NLP）中，命名实体识别（NER）是信息提取的一个子任务，旨在定位文本中出现的命名实体，并将其分类到预先定义的类别中，例如人名、组织机构名、地点、时间表达式、数量、货币值和百分比。
For instance, consider the sentence: &ldquo;Apple Inc. is planning to open a new store in San Francisco.&rdquo; Using NER, we could identify that &ldquo;Apple Inc.&rdquo; is an organization and &ldquo;San Francisco&rdquo; is a location. Such information can be incredibly valuable for numerous NLP tasks.<br>例如，考虑这句话：“苹果公司计划在旧金山开设一家新店。” 使用 NER，我们可以识别出“苹果公司”是一个组织，“旧金山”是一个地点。 这些信息对于众多 NLP 任务来说非常宝贵。</p><h5 id=part-of-speech-pos-tagging>Part of Speech (POS) Tagging</h5><p>词性标注 (POS)</p><p>Every word in a sentence has a particular role. Some words are objects, some are verbs, some are adjectives, and so on. Tagging these parts of speech, or POS tagging, can be a critical component to many NLP tasks. It can help answer many questions, like what are the main objects in a sentence, what actions are being taken, and what&rsquo;s the context of these actions?<br>句子中的每个词都有特定的词性。有些词是宾语，有些词是动词，有些词是形容词，等等。对这些词性进行标记，或者说词性标注，是许多自然语言处理任务的关键组成部分。它可以帮助回答许多问题，例如句子中的主要宾语是什么，正在采取什么行动，以及这些行动的背景是什么？
Let&rsquo;s start with a sentence example: &ldquo;Apple Inc. is planning to open a new store in San Francisco.&rdquo; We are going to use <code>NLTK</code>&lsquo;s <code>pos_tag</code> function to tag the part of speech for each word in this sentence.<br>让我们从一个例句开始：“苹果公司计划在旧金山开设一家新店。”我们将使用 <code>NLTK</code> 的 <code>pos_tag</code> 函数来标记这个句子中每个词的词性。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>pos_tag</span><span class=p>,</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>example_sentence</span> <span class=o>=</span> <span class=s2>&#34;Apple Inc. is planning to open a new store in San Francisco.&#34;</span>
</span></span><span class=line><span class=cl><span class=n>tokens</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>example_sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>pos_tags</span> <span class=o>=</span> <span class=n>pos_tag</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;The first 5 POS tags are: </span><span class=si>{</span><span class=n>pos_tags</span><span class=p>[:</span><span class=mi>5</span><span class=p>]</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:<br>以上代码的输出将是：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>The</span> <span class=n>first</span> <span class=mi>5</span> <span class=n>POS</span> <span class=n>tags</span> <span class=n>are</span><span class=p>:</span> <span class=p>[(</span><span class=s1>&#39;Apple&#39;</span><span class=p>,</span> <span class=s1>&#39;NNP&#39;</span><span class=p>),</span> <span class=p>(</span><span class=s1>&#39;Inc.&#39;</span><span class=p>,</span> <span class=s1>&#39;NNP&#39;</span><span class=p>),</span> <span class=p>(</span><span class=s1>&#39;is&#39;</span><span class=p>,</span> <span class=s1>&#39;VBZ&#39;</span><span class=p>),</span> <span class=p>(</span><span class=s1>&#39;planning&#39;</span><span class=p>,</span> <span class=s1>&#39;VBG&#39;</span><span class=p>),</span> <span class=p>(</span><span class=s1>&#39;to&#39;</span><span class=p>,</span> <span class=s1>&#39;TO&#39;</span><span class=p>)]</span>
</span></span></code></pre></td></tr></table></div></div><p>Here, every word from our sentence gets tagged with a corresponding part of speech. This is the first step towards performing Named Entity Recognition.<br>在这里，我们句子中的每个词都被标记了相应的词性。这是进行命名实体识别（NER）的第一步。</p><h5 id=named-entity-recognition-with-nltk>Named Entity Recognition with NLTK</h5><p>使用 NLTK 进行命名实体识别</p><p>Now, what about Named Entity Recognition? Well, Named Entity Recognition (or NER) can be considered a step beyond regular POS tagging. It groups together one or more words that signify a named entity such as &ldquo;San Francisco&rdquo; or &ldquo;Apple Inc.&rdquo; into a single category, i.e., location or organization in this case.<br>那么，命名实体识别呢？命名实体识别（NER）可以被视为比常规词性标注更进一步的技术。它将表示命名实体的一个或多个单词（例如“旧金山”或“苹果公司”）归类到单个类别中，在本例中分别是地点或组织。
We can use the <code>ne_chunk</code> function in NLTK to perform NER on our POS-tagged sentence, like so:<br>我们可以使用 NLTK 中的 <code>ne_chunk</code> 函数对我们 POS 标注的句子执行 NER，如下所示：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>ne_chunk</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>named_entities</span> <span class=o>=</span> <span class=n>ne_chunk</span><span class=p>(</span><span class=n>pos_tags</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;The named entities in our example sentences are:</span><span class=se>\n</span><span class=si>{</span><span class=n>named_entities</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:<br>以上代码的输出将是：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>The</span> <span class=n>named</span> <span class=n>entities</span> <span class=ow>in</span> <span class=n>our</span> <span class=n>example</span> <span class=n>sentences</span> <span class=n>are</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=n>S</span>
</span></span><span class=line><span class=cl>  <span class=p>(</span><span class=n>PERSON</span> <span class=n>Apple</span><span class=o>/</span><span class=n>NNP</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>(</span><span class=n>ORGANIZATION</span> <span class=n>Inc</span><span class=o>./</span><span class=n>NNP</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=ow>is</span><span class=o>/</span><span class=n>VBZ</span>
</span></span><span class=line><span class=cl>  <span class=n>planning</span><span class=o>/</span><span class=n>VBG</span>
</span></span><span class=line><span class=cl>  <span class=n>to</span><span class=o>/</span><span class=n>TO</span>
</span></span><span class=line><span class=cl>  <span class=nb>open</span><span class=o>/</span><span class=n>VB</span>
</span></span><span class=line><span class=cl>  <span class=n>a</span><span class=o>/</span><span class=n>DT</span>
</span></span><span class=line><span class=cl>  <span class=n>new</span><span class=o>/</span><span class=n>JJ</span>
</span></span><span class=line><span class=cl>  <span class=n>store</span><span class=o>/</span><span class=n>NN</span>
</span></span><span class=line><span class=cl>  <span class=ow>in</span><span class=o>/</span><span class=n>IN</span>
</span></span><span class=line><span class=cl>  <span class=p>(</span><span class=n>GPE</span> <span class=n>San</span><span class=o>/</span><span class=n>NNP</span> <span class=n>Francisco</span><span class=o>/</span><span class=n>NNP</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=o>./.</span><span class=p>)</span>  
</span></span></code></pre></td></tr></table></div></div><p>Let&rsquo;s break down this output:<br>让我们分析一下这个输出：</p><ul><li>The &lsquo;S&rsquo; at the beginning signifies the start of a sentence.<br>句首的“S”表示一个句子的开始。</li><li>Words inside paretheses, prefixed with labels such as PERSON, ORGANIZATION, or GPE are recognized named entities. For example, &lsquo;(PERSON Apple/NNP)&rsquo; indicates that &lsquo;Apple&rsquo; is recognized as a named entity representing a Person and &lsquo;Apple&rsquo; has been POS tagged as &lsquo;NNP&rsquo; (Proper Noun, Singular).<br>括号中的词语，如果带有诸如 PERSON、ORGANIZATION 或 GPE 等标签，则表示识别出的命名实体。例如，&rsquo;(PERSON Apple/NNP)&rsquo; 表示“Apple”被识别为代表人物的命名实体，并且“Apple”已被词性标注为“NNP”（专有名词，单数）。<ul><li>Words outside parentheses are not recognized as part of a named entity but are part of the sentence and each of them is associated with a POS tag. For instance, &lsquo;is/VBZ&rsquo; means that &lsquo;is&rsquo; is recognized as a verb in present tense, 3rd person singular form.<br>圆括号外的单词不被识别为命名实体的一部分，而是句子的一部分，并且每个单词都与一个词性标签相关联。例如，“is/VBZ”表示“is”被识别为现在时、第三人称单数形式的动词。</li><li>&lsquo;(GPE San/NNP Francisco/NNP)&rsquo; indicates that &lsquo;San Francisco&rsquo;, a two-word entity, is recognized as a geopolitical entity, such as a city, state, or country.<br>&lsquo;(GPE San/NNP Francisco/NNP)&rsquo; 表示“旧金山”这个由两个词组成的实体被识别为一个地缘政治实体，例如城市、州或国家。
While Named Entity Recognition offers richer insights than simple POS tagging, it might not always be perfectly accurate due to the ambiguity and context-dependent nature of language. Despite this, it&rsquo;s a powerful tool in any NLP practitioner&rsquo;s arsenal.<br>虽然命名实体识别比简单的词性标注提供了更丰富的见解，但由于语言的歧义性和语境依赖性，它可能并不总是完全准确。尽管如此，它仍然是任何自然语言处理从业者武器库中的有力工具。</li></ul></li></ul><h5 id=applying-pos-tagging-and-ner-to-a-real-dataset>Applying PoS Tagging and NER to a Real Dataset</h5><p>将词性标注和命名实体识别应用于真实数据集</p><p>Examining these NLP techniques in action on larger, more complex datasets allows us to understand the power of Natural Language Processing better. To this end, let&rsquo;s use POS tagging and Named Entity Recognition on a real-world dataset - the 20 Newsgroups dataset.<br>在更大、更复杂的数据集上考察这些 NLP 技术的实际应用，可以让我们更好地理解自然语言处理的强大功能。为此，让我们在真实世界的数据集——20 Newsgroups 数据集——上使用词性标注和命名实体识别技术。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>pos_tag</span><span class=p>,</span> <span class=n>ne_chunk</span><span class=p>,</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Loading the data with metadata removed</span>
</span></span><span class=line><span class=cl><span class=n>newsgroups_data</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>,</span> <span class=n>remove</span><span class=o>=</span><span class=p>(</span><span class=s1>&#39;headers&#39;</span><span class=p>,</span> <span class=s1>&#39;footers&#39;</span><span class=p>,</span> <span class=s1>&#39;quotes&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Selecting the first document </span>
</span></span><span class=line><span class=cl><span class=n>first_doc</span> <span class=o>=</span> <span class=n>newsgroups_data</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Trimming the document&#39;s text down to the first 67 characters</span>
</span></span><span class=line><span class=cl><span class=n>first_doc</span> <span class=o>=</span> <span class=n>first_doc</span><span class=p>[:</span><span class=mi>67</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Tokenizing the text</span>
</span></span><span class=line><span class=cl><span class=n>tokens_first_doc</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>first_doc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Applying POS tagging</span>
</span></span><span class=line><span class=cl><span class=n>pos_tags_first_doc</span> <span class=o>=</span> <span class=n>pos_tag</span><span class=p>(</span><span class=n>tokens_first_doc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Applying Named Entity Recognition</span>
</span></span><span class=line><span class=cl><span class=n>named_entities</span> <span class=o>=</span> <span class=n>ne_chunk</span><span class=p>(</span><span class=n>pos_tags_first_doc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;The first chunk of named entities in the first document are:</span><span class=se>\n</span><span class=si>{</span><span class=n>named_entities</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Here&rsquo;s the output you can expect:<br>请提供您需要翻译的文本内容。我将尽力将其准确地翻译成简体中文，并保持原文的学术语气，不添加任何解释。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>The</span> <span class=n>first</span> <span class=n>chunk</span> <span class=n>of</span> <span class=n>named</span> <span class=n>entities</span> <span class=ow>in</span> <span class=n>the</span> <span class=n>first</span> <span class=n>document</span> <span class=n>are</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=n>S</span>
</span></span><span class=line><span class=cl>  <span class=n>I</span><span class=o>/</span><span class=n>PRP</span>
</span></span><span class=line><span class=cl>  <span class=n>was</span><span class=o>/</span><span class=n>VBD</span>
</span></span><span class=line><span class=cl>  <span class=n>wondering</span><span class=o>/</span><span class=n>VBG</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span><span class=o>/</span><span class=n>IN</span>
</span></span><span class=line><span class=cl>  <span class=n>anyone</span><span class=o>/</span><span class=n>NN</span>
</span></span><span class=line><span class=cl>  <span class=n>out</span><span class=o>/</span><span class=n>IN</span>
</span></span><span class=line><span class=cl>  <span class=n>there</span><span class=o>/</span><span class=n>RB</span>
</span></span><span class=line><span class=cl>  <span class=n>could</span><span class=o>/</span><span class=n>MD</span>
</span></span><span class=line><span class=cl>  <span class=n>enlighten</span><span class=o>/</span><span class=n>VB</span>
</span></span><span class=line><span class=cl>  <span class=n>me</span><span class=o>/</span><span class=n>PRP</span>
</span></span><span class=line><span class=cl>  <span class=n>on</span><span class=o>/</span><span class=n>IN</span>
</span></span><span class=line><span class=cl>  <span class=n>this</span><span class=o>/</span><span class=n>DT</span>
</span></span><span class=line><span class=cl>  <span class=n>car</span><span class=o>/</span><span class=n>NN</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>As you can see, even when we&rsquo;re working with a slimmed-down text input, both POS tagging and NER deliver valuable insights. We&rsquo;ve applied these techniques to just a portion of a complex, real-world dataset, demonstrating how NLP can uncover important information from vast amounts of textual data. This highlights the critical role NLP plays in fields ranging from data analysis to AI and machine learning.<br>正如您所见，即使我们处理的是精简的文本输入，词性标注和命名实体识别也能提供有价值的见解。我们已将这些技术应用于复杂、真实的数据库的一部分，展示了自然语言处理如何从海量文本数据中发现重要信息。这凸显了自然语言处理在从数据分析到人工智能和机器学习等各个领域的关键作用。</p><h5 id=lesson-summary-and-practice>Lesson Summary and Practice</h5><p>课程总结与练习</p><p>In this lesson, we have covered <strong>Part of Speech (POS) tagging</strong>, <strong>Named Entity Recognition (NER)</strong>, and even applied these techniques to a real-world dataset! These concepts are fundamental to text preprocessing in Natural Language Processing (NLP). Having a grasp over these will allow you to approach more advanced topics in NLP with ease.<br>在本课中，我们学习了词性标注 (POS)、命名实体识别 (NER)，甚至将这些技术应用到了真实的数据集！这些概念是自然语言处理 (NLP) 中文本预处理的基础。掌握这些将使您能够轻松地处理 NLP 中更高级的主题。
You have the upcoming tasks to practice these techniques, reinforcing your understanding and improving your Natural Language Processing skills. Let&rsquo;s head onto them and keep learning! Practice is key when it comes to mastering these techniques. Enjoy the hands-on session. Keep Learning!<br>你接下来将要完成的任务可以帮助你练习这些技巧，巩固理解并提升自然语言处理技能。让我们开始吧，持续学习！熟练掌握这些技巧的关键在于练习。享受实践的过程吧！持续学习！</p><h2 id=practice-8>「Practice」</h2><p>Great job! Now, let&rsquo;s shift our focus to another set of student scores, this time in <strong>Math</strong>. The given code calculates upper outlier bound, using the <strong>Interquartile Range (IQR)</strong> method, described in the lesson.</p><p>Your goal is to update code to calculate lower outlier bound instead, using the same principle.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>math_scores</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>92</span><span class=p>,</span> <span class=mi>75</span><span class=p>,</span> <span class=mi>88</span><span class=p>,</span> <span class=mi>78</span><span class=p>,</span> <span class=mi>90</span><span class=p>,</span> <span class=mi>80</span><span class=p>,</span> <span class=mi>88</span><span class=p>,</span> <span class=mi>80</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate Q1 and Q3 for math scores</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Q1_math</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>math_scores</span><span class=p>,</span> <span class=mi>25</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Q3_math</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>math_scores</span><span class=p>,</span> <span class=mi>75</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the Interquartile Range for math scores</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>IQR_math</span> <span class=o>=</span> <span class=n>Q3_math</span> <span class=o>-</span> <span class=n>Q1_math</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>upper_outlier_bound</span> <span class=o>=</span> <span class=n>Q3_math</span> <span class=o>+</span> <span class=mf>1.5</span> <span class=o>*</span> <span class=n>IQR_math</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>upper_outlier_bound</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
To update the given code to calculate the lower outlier bound using the Interquartile Range (IQR) method, we need to follow these steps:</p><ol><li>Calculate the first quartile (Q1) and the third quartile (Q3) for the math scores.</li><li>Calculate the Interquartile Range (IQR) by subtracting Q1 from Q3.</li><li>Use the IQR to calculate the lower outlier bound by subtracting (1.5 \times \text{IQR}) from Q1.</li></ol><p>Here is the updated code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Given math scores</span>
</span></span><span class=line><span class=cl><span class=n>math_scores</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>92</span><span class=p>,</span> <span class=mi>75</span><span class=p>,</span> <span class=mi>88</span><span class=p>,</span> <span class=mi>78</span><span class=p>,</span> <span class=mi>90</span><span class=p>,</span> <span class=mi>80</span><span class=p>,</span> <span class=mi>88</span><span class=p>,</span> <span class=mi>80</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate Q1 and Q3 for math scores</span>
</span></span><span class=line><span class=cl><span class=n>Q1_math</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>math_scores</span><span class=p>,</span> <span class=mi>25</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>Q3_math</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>math_scores</span><span class=p>,</span> <span class=mi>75</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the Interquartile Range for math scores</span>
</span></span><span class=line><span class=cl><span class=n>IQR_math</span> <span class=o>=</span> <span class=n>Q3_math</span> <span class=o>-</span> <span class=n>Q1_math</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the lower outlier bound</span>
</span></span><span class=line><span class=cl><span class=n>lower_outlier_bound</span> <span class=o>=</span> <span class=n>Q1_math</span> <span class=o>-</span> <span class=mf>1.5</span> <span class=o>*</span> <span class=n>IQR_math</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>lower_outlier_bound</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Explanation:</p><ul><li>We first calculate the first quartile ((Q1)) and the third quartile ((Q3)) using <code>np.percentile</code>.</li><li>Then, we find the Interquartile Range ((IQR)) by subtracting (Q1) from (Q3).</li><li>Finally, we calculate the lower outlier bound by subtracting (1.5 \times \text{IQR}) from (Q1), which is the standard method to detect lower outliers.</li></ul><p>This code will output the lower outlier bound for the given math scores.</p><h2 id=practice-9>「Practice」</h2><p>Great work, Space Voyager!</p><p>Now, change the sentence in the provided code to &ldquo;Microsoft Corporation aims to reach 95% global coverage by 2025.&rdquo; and observe how the named entities identified by the <strong>Named Entity Recognition (NER)</strong> change.</p><p>Keep advancing!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>pos_tag</span><span class=p>,</span> <span class=n>word_tokenize</span><span class=p>,</span> <span class=n>ne_chunk</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Given sentence</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sample_sentence</span> <span class=o>=</span> <span class=s2>&#34;Apple Inc. planned to open a new store in San Francisco in 82</span><span class=si>% o</span><span class=s2>f time by 2020.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get tokens</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokens</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>sample_sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get POS tags</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>pos_tags</span> <span class=o>=</span> <span class=n>pos_tag</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform NER</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>named_entities</span> <span class=o>=</span> <span class=n>ne_chunk</span><span class=p>(</span><span class=n>pos_tags</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the identified named entities</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>named_entities</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>To change the sentence and observe how the named entities identified by the Named Entity Recognition (NER) change, we&rsquo;ll modify the given sentence to &ldquo;Microsoft Corporation aims to reach 95% global coverage by 2025.&rdquo; and then run the NER process.</p><p>Here&rsquo;s the updated code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>pos_tag</span><span class=p>,</span> <span class=n>word_tokenize</span><span class=p>,</span> <span class=n>ne_chunk</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Updated sentence</span>
</span></span><span class=line><span class=cl><span class=n>sample_sentence</span> <span class=o>=</span> <span class=s2>&#34;Microsoft Corporation aims to reach 95</span><span class=si>% g</span><span class=s2>lobal coverage by 2025.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get tokens</span>
</span></span><span class=line><span class=cl><span class=n>tokens</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>sample_sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get POS tags</span>
</span></span><span class=line><span class=cl><span class=n>pos_tags</span> <span class=o>=</span> <span class=n>pos_tag</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform NER</span>
</span></span><span class=line><span class=cl><span class=n>named_entities</span> <span class=o>=</span> <span class=n>ne_chunk</span><span class=p>(</span><span class=n>pos_tags</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the identified named entities</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>named_entities</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The expected output will show the named entities identified by NER. Let&rsquo;s break down the process and what changes we can expect:</p><ol><li><strong>Tokenization</strong>: The sentence will be split into individual words (tokens).</li><li><strong>POS Tagging</strong>: Each token will be tagged with its part of speech.</li><li><strong>NER</strong>: The part-of-speech tagged tokens will be analyzed to identify named entities such as organizations, locations, and dates.</li></ol><p>The initial sentence, &ldquo;Apple Inc. planned to open a new store in San Francisco in 82% of time by 2020,&rdquo; identifies &ldquo;Apple Inc.&rdquo; as an organization, &ldquo;San Francisco&rdquo; as a location, and &ldquo;2020&rdquo; as a date.</p><p>For the updated sentence, &ldquo;Microsoft Corporation aims to reach 95% global coverage by 2025,&rdquo; the expected named entities are:</p><ul><li>&ldquo;Microsoft Corporation&rdquo; as an organization.</li><li>&ldquo;2025&rdquo; as a date.</li></ul><p>Running the code will confirm the exact output. Here&rsquo;s a mock-up of what we can expect:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>(S
</span></span><span class=line><span class=cl>  (ORGANIZATION Microsoft/NNP Corporation/NNP)
</span></span><span class=line><span class=cl>  aims/VBZ
</span></span><span class=line><span class=cl>  to/TO
</span></span><span class=line><span class=cl>  reach/VB
</span></span><span class=line><span class=cl>  95/CD
</span></span><span class=line><span class=cl>  %/NN
</span></span><span class=line><span class=cl>  global/JJ
</span></span><span class=line><span class=cl>  coverage/NN
</span></span><span class=line><span class=cl>  by/IN
</span></span><span class=line><span class=cl>  2025/CD)
</span></span></code></pre></td></tr></table></div></div><p>This output indicates that &ldquo;Microsoft Corporation&rdquo; is recognized as an organization, and &ldquo;2025&rdquo; is recognized as a date, as expected. The NER process using <code>ne_chunk</code> from NLTK helps in identifying and categorizing these entities.</p><h2 id=practice-10>「Practice」</h2><p>Excellent work, Space Explorer!</p><p>Let&rsquo;s reinforce your learning by inserting the missing code. Fill in the appropriate functions to perform tokenization and POS tagging. Use nltk&rsquo;s powerful tools to achieve this. Happy learning!from nltk import ____, word_tokenize</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Given sentence</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sample_sentence</span> <span class=o>=</span> <span class=s2>&#34;The quick brown fox jumps over the lazy dog.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get tokens</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokens</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>sample_sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get POS tags</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>pos_tags</span> <span class=o>=</span> <span class=n>____</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the POS tags</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>pos_tags</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
Certainly, here is the completed code with the appropriate functions from the NLTK library to perform tokenization and POS tagging:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>pos_tag</span><span class=p>,</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Given sentence</span>
</span></span><span class=line><span class=cl><span class=n>sample_sentence</span> <span class=o>=</span> <span class=s2>&#34;The quick brown fox jumps over the lazy dog.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get tokens</span>
</span></span><span class=line><span class=cl><span class=n>tokens</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>sample_sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get POS tags</span>
</span></span><span class=line><span class=cl><span class=n>pos_tags</span> <span class=o>=</span> <span class=n>pos_tag</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the POS tags</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>pos_tags</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=explanation-2>Explanation:</h3><ol><li><p><strong>Importing the necessary functions</strong>:</p><ul><li><code>pos_tag</code>: This function is used to perform part-of-speech (POS) tagging.</li><li><code>word_tokenize</code>: This function is used to split the sentence into individual words or tokens.</li></ul></li><li><p><strong>Tokenization</strong>:</p><ul><li><code>tokens = word_tokenize(sample_sentence)</code>: This line splits the given sentence into tokens.</li></ul></li><li><p><strong>POS Tagging</strong>:</p><ul><li><code>pos_tags = pos_tag(tokens)</code>: This line assigns POS tags to each token.</li></ul></li><li><p><strong>Printing the POS tags</strong>:</p><ul><li><code>print(pos_tags)</code>: This prints out the tokens along with their corresponding POS tags.</li></ul></li></ol><p>When you run this code, you should see an output where each word in the sentence is paired with its POS tag, like this:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[(&#39;The&#39;, &#39;DT&#39;), (&#39;quick&#39;, &#39;JJ&#39;), (&#39;brown&#39;, &#39;JJ&#39;), (&#39;fox&#39;, &#39;NN&#39;), (&#39;jumps&#39;, &#39;VBZ&#39;), (&#39;over&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;lazy&#39;, &#39;JJ&#39;), (&#39;dog&#39;, &#39;NN&#39;)]
</span></span></code></pre></td></tr></table></div></div><h3 id=explanation-of-pos-tags-in-the-output>Explanation of POS tags in the output:</h3><ul><li><strong>DT</strong>: Determiner</li><li><strong>JJ</strong>: Adjective</li><li><strong>NN</strong>: Noun, singular or mass</li><li><strong>VBZ</strong>: Verb, 3rd person singular present</li><li><strong>IN</strong>: Preposition or subordinating conjunction</li></ul><p>This way, the code effectively tokenizes the sentence and performs POS tagging using NLTK&rsquo;s powerful tools.</p><h1 id=lesson-2>lesson</h1><h2 id=introduction-2>Introduction</h2><p>Hello and welcome! Today&rsquo;s lesson will introduce a crucial component of text feature engineering: <em>tokenization</em>. Used in text classification, tokenization is a pre-processing step that transforms raw text into units of meaning known as tokens. By breaking down text into these consumable pieces, we can provide feeding material for machine learning models to understand the text better. Our goal in this lesson is to apply tokenization on a raw text dataset (<em>IMDB movie review dataset</em>) and understand how it can be beneficial in the process of text classification.</p><h2 id=understanding-the-concept-and-importance-of-text-tokenization>Understanding the Concept and Importance of Text Tokenization</h2><p>Text tokenization is a type of pre-processing step where a text string is split up into individual units (tokens). In most cases, these tokens are words, digits, or punctuation marks. For instance, consider this text: &ldquo;I love Python.&rdquo; After tokenization, this sentence is split into <code>['I', 'love', 'Python', '.']</code>, with each word and punctuation mark becoming a separate token.</p><p>Text tokenization plays a foundational role in text classification and many Natural Language Processing (NLP) tasks. Consider the fact that most machine learning algorithms prefer numerical input. But when dealing with text data, we can&rsquo;t feed raw text directly into these algorithms. This is where tokenization steps in. It breaks down the text into individual tokens, which can then be transformed into some numerical form (via techniques like Bag-of-Words, TF-IDF, etc.). This transformed form can then be processed by the machine learning algorithms.</p><h2 id=applying-tokenization-on-a-text-example-using-nltk>Applying Tokenization on a Text Example Using NLTK</h2><p>Before we tackle our dataset, let&rsquo;s understand how tokenization works with a simple example. Python and the <code>NLTK</code> (Natural Language Toolkit) library, a comprehensive library built specifically for NLP tasks, make tokenization simple and efficient. For our example, suppose we have a sentence: &ldquo;The cat is on the mat.&rdquo; Let&rsquo;s tokenize it:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s2>&#34;The cat is on the mat.&#34;</span>
</span></span><span class=line><span class=cl><span class=n>tokens</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[&#39;The&#39;, &#39;cat&#39;, &#39;is&#39;, &#39;on&#39;, &#39;the&#39;, &#39;mat&#39;, &#39;.&#39;]
</span></span></code></pre></td></tr></table></div></div><h5 id=text-classification-dataset-overview>Text Classification Dataset Overview</h5><p>For the purpose of this lesson, we&rsquo;ll use the <strong>IMDB movie reviews dataset</strong> (provided in the NLTK corpus). This dataset contains movie reviews along with their associated binary sentiment polarity labels. The core dataset has 50,000 reviews split evenly into 25k for training and 25k for testing. Each set has 12.5k positive and 12.5k negative reviews. However, for the purpose of these lessons, we will focus on using the first 100 reviews.</p><p>It&rsquo;s important to note that the IMDB dataset provided in the NLTK corpus has been preprocessed. The text is already lowercased, and common punctuation is typically separated from the words. This pre-cleaning makes the dataset well-suited for the tokenization process we&rsquo;ll be exploring.</p><p>Let&rsquo;s get these reviews and print a few of them:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>nltk</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>movie_reviews</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nltk</span><span class=o>.</span><span class=n>download</span><span class=p>(</span><span class=s1>&#39;movie_reviews&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>movie_reviews_ids</span> <span class=o>=</span> <span class=n>movie_reviews</span><span class=o>.</span><span class=n>fileids</span><span class=p>()[:</span><span class=mi>100</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>review_texts</span> <span class=o>=</span> <span class=p>[</span><span class=n>movie_reviews</span><span class=o>.</span><span class=n>raw</span><span class=p>(</span><span class=n>fileid</span><span class=p>)</span> <span class=k>for</span> <span class=n>fileid</span> <span class=ow>in</span> <span class=n>movie_reviews_ids</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;First movie review:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>review_texts</span><span class=p>[</span><span class=mi>0</span><span class=p>][:</span><span class=mi>260</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>Note that we&rsquo;re only printing the first 260 characters of the first review to prevent lengthy output.</p><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>First</span> <span class=n>movie</span> <span class=n>review</span><span class=p>:</span>
</span></span><span class=line><span class=cl> <span class=n>plot</span> <span class=p>:</span> <span class=n>two</span> <span class=n>teen</span> <span class=n>couples</span> <span class=n>go</span> <span class=n>to</span> <span class=n>a</span> <span class=n>church</span> <span class=n>party</span> <span class=p>,</span> <span class=n>drink</span> <span class=ow>and</span> <span class=n>then</span> <span class=n>drive</span> <span class=o>.</span> 
</span></span><span class=line><span class=cl><span class=n>they</span> <span class=n>get</span> <span class=n>into</span> <span class=n>an</span> <span class=n>accident</span> <span class=o>.</span> 
</span></span><span class=line><span class=cl><span class=n>one</span> <span class=n>of</span> <span class=n>the</span> <span class=n>guys</span> <span class=n>dies</span> <span class=p>,</span> <span class=n>but</span> <span class=n>his</span> <span class=n>girlfriend</span> <span class=n>continues</span> <span class=n>to</span> <span class=n>see</span> <span class=n>him</span> <span class=ow>in</span> <span class=n>her</span> <span class=n>life</span> <span class=p>,</span> <span class=ow>and</span> <span class=n>has</span> <span class=n>nightmares</span> <span class=o>.</span> 
</span></span><span class=line><span class=cl><span class=n>what</span><span class=s1>&#39;s the deal ? </span>
</span></span><span class=line><span class=cl><span class=n>watch</span> <span class=n>the</span> <span class=n>movie</span> <span class=ow>and</span> <span class=s2>&#34; sorta &#34;</span> <span class=n>find</span> <span class=n>out</span> <span class=o>.</span> <span class=o>.</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=applying-tokenization-on-the-dataset>Applying Tokenization on the Dataset</h5><p>Now it&rsquo;s time to transform our data. For this, we will apply tokenization on all our 100 movie reviews.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl><span class=n>tokenized_reviews</span> <span class=o>=</span> <span class=p>[</span><span class=n>word_tokenize</span><span class=p>(</span><span class=n>review</span><span class=p>)</span> <span class=k>for</span> <span class=n>review</span> <span class=ow>in</span> <span class=n>review_texts</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>So, what changes did tokenization bring to our data? Each review, which was initially a long string of text, is now a list of individual tokens (words, punctuation, etc), which collectively represent the review. In other words, our dataset evolved from being a list of strings to being a list of lists.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>review</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>tokenized_reviews</span><span class=p>[:</span><span class=mi>3</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2> Review </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2> first 10 tokens:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>review</span><span class=p>[:</span><span class=mi>10</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl> <span class=n>Review</span> <span class=mi>1</span> <span class=n>first</span> <span class=mi>10</span> <span class=n>tokens</span><span class=p>:</span>
</span></span><span class=line><span class=cl> <span class=p>[</span><span class=s1>&#39;plot&#39;</span><span class=p>,</span> <span class=s1>&#39;:&#39;</span><span class=p>,</span> <span class=s1>&#39;two&#39;</span><span class=p>,</span> <span class=s1>&#39;teen&#39;</span><span class=p>,</span> <span class=s1>&#39;couples&#39;</span><span class=p>,</span> <span class=s1>&#39;go&#39;</span><span class=p>,</span> <span class=s1>&#39;to&#39;</span><span class=p>,</span> <span class=s1>&#39;a&#39;</span><span class=p>,</span> <span class=s1>&#39;church&#39;</span><span class=p>,</span> <span class=s1>&#39;party&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> <span class=n>Review</span> <span class=mi>2</span> <span class=n>first</span> <span class=mi>10</span> <span class=n>tokens</span><span class=p>:</span>
</span></span><span class=line><span class=cl> <span class=p>[</span><span class=s1>&#39;the&#39;</span><span class=p>,</span> <span class=s1>&#39;happy&#39;</span><span class=p>,</span> <span class=s1>&#39;bastard&#39;</span><span class=p>,</span> <span class=s2>&#34;&#39;s&#34;</span><span class=p>,</span> <span class=s1>&#39;quick&#39;</span><span class=p>,</span> <span class=s1>&#39;movie&#39;</span><span class=p>,</span> <span class=s1>&#39;review&#39;</span><span class=p>,</span> <span class=s1>&#39;damn&#39;</span><span class=p>,</span> <span class=s1>&#39;that&#39;</span><span class=p>,</span> <span class=s1>&#39;y2k&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> <span class=n>Review</span> <span class=mi>3</span> <span class=n>first</span> <span class=mi>10</span> <span class=n>tokens</span><span class=p>:</span>
</span></span><span class=line><span class=cl> <span class=p>[</span><span class=s1>&#39;it&#39;</span><span class=p>,</span> <span class=s1>&#39;is&#39;</span><span class=p>,</span> <span class=s1>&#39;movies&#39;</span><span class=p>,</span> <span class=s1>&#39;like&#39;</span><span class=p>,</span> <span class=s1>&#39;these&#39;</span><span class=p>,</span> <span class=s1>&#39;that&#39;</span><span class=p>,</span> <span class=s1>&#39;make&#39;</span><span class=p>,</span> <span class=s1>&#39;a&#39;</span><span class=p>,</span> <span class=s1>&#39;jaded&#39;</span><span class=p>,</span> <span class=s1>&#39;movie&#39;</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=lesson-summary-and-next-steps>Lesson Summary and Next Steps</h5><p>Well done! Today, you learned about the fundamental concept of text tokenization and its importance in text classification. You also applied tokenization to the IMDB movie reviews dataset using Python and NLTK. Your text data is now effectively transformed into a form that machine learning models can digest better.</p><p>As you advance in the course, you will refine this dataset further for your text classification objectives. We are laying the foundation one brick at a time, and tokenization was a sturdy one! Upcoming lessons will build upon this understanding. You&rsquo;ll harness this tokenized data to generate Bag-of-Words representations, implement TF-IDF representations, handle sparse features, and apply dimensionality reduction.</p><p>Remember, practice consolidates learning. Make sure to reinforce your knowledge by practicing the code samples and applying these concepts contextually. Don&rsquo;t forget to use your creativity to manipulate codes and see the outcomes. Happy learning!</p><h2 id=practice-11>「Practice」</h2><p>Good job, Space Voyager! The existing code is intended to tokenize a movie review and filter out punctuation, leaving only word tokens. However, there&rsquo;s a bug causing it to act incorrectly.<br>干得好，太空旅行者！现有代码旨在将电影评论标记化并过滤掉标点符号，仅保留单词标记。但是，其中存在一个错误，导致其行为不正确。</p><p>Can you locate the error and adjust the code to correctly execute the task? After your revision, the code should tokenize the first movie review from the dataset, omit any punctuation, and print the first 10 word tokens.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>nltk</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>movie_reviews</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nltk</span><span class=o>.</span><span class=n>download</span><span class=p>(</span><span class=s1>&#39;movie_reviews&#39;</span><span class=p>,</span> <span class=n>quiet</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the first movie review</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>review_text</span> <span class=o>=</span> <span class=n>movie_reviews</span><span class=o>.</span><span class=n>raw</span><span class=p>(</span><span class=n>movie_reviews</span><span class=o>.</span><span class=n>fileids</span><span class=p>()[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply tokenization on the review</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenized_review</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>review_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Should keep only word tokens</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>current_tokens</span> <span class=o>=</span> <span class=p>[</span><span class=n>token</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokenized_review</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>token</span><span class=o>.</span><span class=n>isalpha</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the first 10 tokens</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>The first 10 tokens are:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>current_tokens</span><span class=p>[:</span><span class=mi>10</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
你已经很接近正确答案了！代码中只有一个小错误需要修正。让我们仔细看看这行代码：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>current_tokens</span> <span class=o>=</span> <span class=p>[</span><span class=n>token</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokenized_review</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>token</span><span class=o>.</span><span class=n>isalpha</span><span class=p>()]</span>
</span></span></code></pre></td></tr></table></div></div><p>这行代码使用列表推导式来过滤标记，但条件 <code>if not token.isalpha()</code> 的逻辑是相反的。<code>isalpha()</code> 方法检查一个字符串是否只包含字母字符。通过使用 <code>not</code>，它实际上保留了非字母的标记（如标点符号），而丢弃了所有单词标记。</p><p>为了修复这个问题，我们需要移除 <code>not</code> 关键字，像这样：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>current_tokens</span> <span class=o>=</span> <span class=p>[</span><span class=n>token</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokenized_review</span> <span class=k>if</span> <span class=n>token</span><span class=o>.</span><span class=n>isalpha</span><span class=p>()]</span>
</span></span></code></pre></td></tr></table></div></div><p>现在，条件 <code>if token.isalpha()</code> 将只保留字母字符的标记，有效地过滤掉标点符号。</p><p>修改后的完整代码如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>nltk</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>movie_reviews</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nltk</span><span class=o>.</span><span class=n>download</span><span class=p>(</span><span class=s1>&#39;movie_reviews&#39;</span><span class=p>,</span> <span class=n>quiet</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the first movie review</span>
</span></span><span class=line><span class=cl><span class=n>review_text</span> <span class=o>=</span> <span class=n>movie_reviews</span><span class=o>.</span><span class=n>raw</span><span class=p>(</span><span class=n>movie_reviews</span><span class=o>.</span><span class=n>fileids</span><span class=p>()[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply tokenization on the review </span>
</span></span><span class=line><span class=cl><span class=n>tokenized_review</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>review_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Should keep only word tokens</span>
</span></span><span class=line><span class=cl><span class=n>current_tokens</span> <span class=o>=</span> <span class=p>[</span><span class=n>token</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokenized_review</span> <span class=k>if</span> <span class=n>token</span><span class=o>.</span><span class=n>isalpha</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the first 10 tokens</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>The first 10 tokens are:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>current_tokens</span><span class=p>[:</span><span class=mi>10</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>运行修改后的代码，你应该会看到前10个单词标记正确地打印出来，不包含任何标点符号。这样就成功地标记化了电影评论，并过滤掉了非单词标记。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The first 10 tokens are:  
</span></span><span class=line><span class=cl> [&#39;plot&#39;, &#39;two&#39;, &#39;teen&#39;, &#39;couples&#39;, &#39;go&#39;, &#39;to&#39;, &#39;a&#39;, &#39;church&#39;, &#39;party&#39;, &#39;drink&#39;]
</span></span></code></pre></td></tr></table></div></div><h2 id=practice-12>「Practice」</h2><p>Hey Space Voyager, you&rsquo;re doing great!<br>嘿，太空旅行者，你做得很好！</p><p>In the provided starter code, fill in the blanks (<code>____</code>) to convert a given sentence into individual tokens using the <code>nltk</code> library. Then, filter out the word tokens, leaving out the punctuation marks. 请提供需要翻译的完整句子，我才能帮您翻译成简体中文。目前您只提供了句子的开头 &ldquo;In the p&rdquo;，信息不足，无法进行翻译。<br>在提供的初始代码中，填写空格 ( <code>____</code> )，使用 <code>nltk</code> 库将给定的句子转换为单独的标记。然后，过滤掉单词标记，去掉标点符号。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>____</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Given text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s2>&#34;Who doesn&#39;t enjoy studying Feature Engineering for Text Classification?&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Tokenize the text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokens</span> <span class=o>=</span> <span class=n>____</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Filter out the words</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>words</span> <span class=o>=</span> <span class=p>[</span><span class=n>token</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokens</span> <span class=k>if</span> <span class=n>token</span><span class=o>.</span><span class=n>____</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2> Word Tokens:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>words</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=practice-13>「Practice」</h2><p>Hey Space Voyager, you&rsquo;re doing great!</p><p>In the provided starter code, fill in the blanks (<code>____</code>) to convert a given sentence into individual tokens using the <code>nltk</code> library. Then, filter out the word tokens, leaving out the punctuation marks.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>____</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Given text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s2>&#34;Who doesn&#39;t enjoy studying Feature Engineering for Text Classification?&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Tokenize the text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokens</span> <span class=o>=</span> <span class=n>____</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Filter out the words</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>words</span> <span class=o>=</span> <span class=p>[</span><span class=n>token</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokens</span> <span class=k>if</span> <span class=n>token</span><span class=o>.</span><span class=n>____</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2> Word Tokens:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>words</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>解释</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-mysql data-lang=mysql><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>You</span><span class=s1>&#39;re diving into natural language processing (NLP) with the NLTK library, which is a powerful tool for text analysis! To complete the provided Python code, you need to fill in the blanks to tokenize a given sentence and filter out non-word tokens such as punctuation. Here&#39;</span><span class=n>s</span><span class=w> </span><span class=n>how</span><span class=w> </span><span class=n>you</span><span class=w> </span><span class=n>can</span><span class=w> </span><span class=n>do</span><span class=w> </span><span class=n>it</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=mi>1</span><span class=p>.</span><span class=w> </span><span class=o>**</span><span class=n>Import</span><span class=w> </span><span class=n>Tokenizer</span><span class=o>**</span><span class=p>:</span><span class=w> </span><span class=n>First</span><span class=p>,</span><span class=w> </span><span class=n>you</span><span class=w> </span><span class=n>need</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>import</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>appropriate</span><span class=w> </span><span class=n>tokenizer</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>NLTK</span><span class=p>.</span><span class=w> </span><span class=n>A</span><span class=w> </span><span class=n>commonly</span><span class=w> </span><span class=n>used</span><span class=w> </span><span class=n>tokenizer</span><span class=w> </span><span class=k>is</span><span class=w> </span><span class=o>`</span><span class=n>word_tokenize</span><span class=o>`</span><span class=p>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=mi>2</span><span class=p>.</span><span class=w> </span><span class=o>**</span><span class=n>Tokenize</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=kt>Text</span><span class=o>**</span><span class=p>:</span><span class=w> </span><span class=k>Use</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=o>`</span><span class=n>word_tokenize</span><span class=o>`</span><span class=w> </span><span class=n>function</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>split</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=kt>text</span><span class=w> </span><span class=k>into</span><span class=w> </span><span class=n>tokens</span><span class=p>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=mi>3</span><span class=p>.</span><span class=w> </span><span class=o>**</span><span class=n>Filter</span><span class=w> </span><span class=n>Non</span><span class=o>-</span><span class=n>Word</span><span class=w> </span><span class=n>Tokens</span><span class=o>**</span><span class=p>:</span><span class=w> </span><span class=n>You</span><span class=s1>&#39;ll need to check if each token is alphabetic to filter out punctuation. The string method `isalpha()` is useful here, as it returns `True` if all characters in the string are alphabetic.
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>Here&#39;</span><span class=n>s</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>completed</span><span class=w> </span><span class=n>script</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>```</span><span class=n>python</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>from</span><span class=w> </span><span class=n>nltk</span><span class=w> </span><span class=n>import</span><span class=w> </span><span class=n>word_tokenize</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1># Given text
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>text</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&#34;Who doesn&#39;t enjoy studying Feature Engineering for Text Classification?&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1># Tokenize the text
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>tokens</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=nf>word_tokenize</span><span class=p>(</span><span class=kt>text</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1># Filter out the words
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>words</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>[</span><span class=n>token</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>token</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=n>tokens</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>token</span><span class=p>.</span><span class=nf>isalpha</span><span class=p>()]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nf>print</span><span class=p>(</span><span class=s2>&#34;\n Word Tokens:\n&#34;</span><span class=p>,</span><span class=w> </span><span class=n>words</span><span class=p>)</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p><strong>Explanation</strong>:</p><ul><li><strong><code>word_tokenize</code></strong>: This function from NLTK breaks the text into individual words and punctuation.</li><li><strong><code>token.isalpha()</code></strong>: This method checks if the token consists only of alphabetic characters, thus effectively filtering out punctuation and numbers.</li></ul><p>When you run this script, it will print the list of word tokens from the given text, excluding any punctuation marks.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>## 「Practice」
</span></span><span class=line><span class=cl>Great job, Voyager! Now, you&#39;re tasked with fine-tuning our weather simulation. Could you modify the initial parameters in the `np.random.normal()` function to simulate temperature values that have an average of `35` and a standard deviation of `10`?
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Observe how this alteration impacts the _skewness_ and _kurtosis_ of the weather data distribution. Keep up the good work!
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy</span> <span class=kn>import</span> <span class=n>stats</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>weather_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span> <span class=c1># A populated weather data (secured from a suitable weather database)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Compute skewness - representing the direction of skew (departure from horizontal symmetry)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>weather_skewness</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>skew</span><span class=p>(</span><span class=n>weather_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Compute kurtosis - shows the height and sharpness of the data at the center</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>weather_kurtosis</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>kurtosis</span><span class=p>(</span><span class=n>weather_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Weather Data Skewness: </span><span class=si>{</span><span class=n>weather_skewness</span><span class=si>}</span><span class=se>\n</span><span class=s2>Weather Data Kurtosis: </span><span class=si>{</span><span class=n>weather_kurtosis</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>根据你的要求，我已经修改了代码，将正态分布的参数从 <code>loc=30</code>, <code>scale=5</code> 调整到 <code>loc=35</code>, <code>scale=10</code>。下面是修正后的完整代码段：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy</span> <span class=kn>import</span> <span class=n>stats</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 更新参数以模拟平均值为35，标准差为10的温度值</span>
</span></span><span class=line><span class=cl><span class=n>weather_data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=mi>35</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 计算偏度 - 表示偏离水平对称的方向</span>
</span></span><span class=line><span class=cl><span class=n>weather_skewness</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>skew</span><span class=p>(</span><span class=n>weather_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 计算峰度 - 显示数据中心的高度和尖锐度</span>
</span></span><span class=line><span class=cl><span class=n>weather_kurtosis</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>kurtosis</span><span class=p>(</span><span class=n>weather_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Weather Data Skewness: </span><span class=si>{</span><span class=n>weather_skewness</span><span class=si>}</span><span class=se>\n</span><span class=s2>Weather Data Kurtosis: </span><span class=si>{</span><span class=n>weather_kurtosis</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>这段代码将生成新的天气数据，并计算其偏度和峰度，以分析数据的分布特性。如需进一步分析或调整，请告知！</p><h2 id=pratice>「Pratice」</h2><p>Great job so far, Space Voyager!</p><p>Your task now is to fill in the blanks with the correct code to load the IMDB movie reviews dataset. After loading the data, tokenize the first movie review, and print the first 10 tokens of the tokenized review.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>nltk</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>____</span> <span class=kn>import</span> <span class=n>____</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nltk</span><span class=o>.</span><span class=n>____</span><span class=p>(</span><span class=s1>&#39;movie_reviews&#39;</span><span class=p>,</span> <span class=n>quiet</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the first movie review</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>review_text</span> <span class=o>=</span> <span class=n>____</span><span class=o>.</span><span class=n>raw</span><span class=p>(</span><span class=n>____</span><span class=o>.</span><span class=n>fileids</span><span class=p>()[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply tokenization on the review</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenized_review</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>review_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the first 10 tokens</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>The first 10 tokens are:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>tokenized_review</span><span class=p>[:</span><span class=mi>10</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>解释</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Here</span><span class=s1>&#39;s the completed Python code snippet that correctly fills in the blanks to load the IMDB movie reviews dataset, tokenize the first movie review, and print the first 10 tokens of the tokenized review:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=err>```</span><span class=n>python</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>nltk</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>movie_reviews</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk</span> <span class=kn>import</span> <span class=n>word_tokenize</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nltk</span><span class=o>.</span><span class=n>download</span><span class=p>(</span><span class=s1>&#39;movie_reviews&#39;</span><span class=p>,</span> <span class=n>quiet</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>nltk</span><span class=o>.</span><span class=n>download</span><span class=p>(</span><span class=s1>&#39;punkt&#39;</span><span class=p>,</span> <span class=n>quiet</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>  <span class=c1># Ensure the tokenizer is available</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the first movie review</span>
</span></span><span class=line><span class=cl><span class=n>review_text</span> <span class=o>=</span> <span class=n>movie_reviews</span><span class=o>.</span><span class=n>raw</span><span class=p>(</span><span class=n>movie_reviews</span><span class=o>.</span><span class=n>fileids</span><span class=p>()[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Apply tokenization on the review</span>
</span></span><span class=line><span class=cl><span class=n>tokenized_review</span> <span class=o>=</span> <span class=n>word_tokenize</span><span class=p>(</span><span class=n>review_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the first 10 tokens</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>The first 10 tokens are:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>tokenized_review</span><span class=p>[:</span><span class=mi>10</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>This script downloads the <code>movie_reviews</code> dataset and the necessary tokenizer (<code>punkt</code>). It then loads the text of the first movie review, tokenizes it, and prints the first 10 tokens. If you have any further questions or need more assistance, feel free to ask!</p><h1 id=lesson-3>lesson</h1><h5 id=introducing-bag-of-words-representation>Introducing Bag-of-Words Representation</h5><p>In the world of text analysis, transforming raw data into a format that is both computer-friendly and preserves the essential information for further processing is crucial. One of the simplest yet versatile methods to do this is the <em>Bag-of-Words Representation</em>, or BoW for short.</p><p>BoW is essentially a method to extract features from text. Imagine you have a big bag filled with words. These words can come from anywhere: a book, a website, or, in our case, movie reviews from the IMDB dataset. For each document or sentence, the BoW representation will contain the count of how many times each word appears. Most importantly, in this &ldquo;bag,&rdquo; we don&rsquo;t care about the order of words, only their occurrence.</p><p>Consider this simple example with three sentences:</p><ol><li><code>The cat sat on the mat.</code></li><li><code>The cat sat near the mat.</code></li><li><code>The cat played with a ball.</code></li></ol><p>Using a BoW representation, our table would look like this:</p><table><thead><tr><th></th><th>the</th><th>cat</th><th>sat</th><th>on</th><th>mat</th><th>near</th><th>played</th><th>with</th><th>a</th><th>ball</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2</td><td>2</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>3</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td></tr></tbody></table><p>Each sentence (document) corresponds to a row, and each unique word is a column. The values in the cells represent the word count in the given sentence.</p><h5 id=illustrating-bag-of-words-with-a-simple-example>Illustrating Bag-of-Words with a Simple Example</h5><p>We can start practising the Bag-of-Words model by using Scikit-learn <code>CountVectorizer</code> on the exact same three sentences:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Simple example sentences</span>
</span></span><span class=line><span class=cl><span class=n>sentences</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;The cat sat on the mat.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>             <span class=s1>&#39;The cat sat near the mat.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>             <span class=s1>&#39;The cat played with a ball.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Feature names:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Bag of Words Representation:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Feature names:
</span></span><span class=line><span class=cl>[&#39;ball&#39; &#39;cat&#39; &#39;mat&#39; &#39;near&#39; &#39;on&#39; &#39;played&#39; &#39;sat&#39; &#39;the&#39; &#39;with&#39;]
</span></span><span class=line><span class=cl>Bag of Words Representation:
</span></span><span class=line><span class=cl>[[0 1 1 0 1 0 1 2 0]
</span></span><span class=line><span class=cl> [0 1 1 1 0 0 1 2 0]
</span></span><span class=line><span class=cl> [1 1 0 0 0 1 0 1 1]]
</span></span></code></pre></td></tr></table></div></div><p>From the output, you&rsquo;ll notice that Scikit-learn <code>CountVectorizer</code> has done the exact thing as our previous manual process. It&rsquo;s created a Bag-of-Words representation for our sentences where each row corresponds to a sentence and each column to a unique word.</p><h5 id=applying-bag-of-words-to-our-dataset>Applying Bag-of-Words to Our Dataset</h5><p>Now that we know what Bag-of-Words is and what it does, let&rsquo;s apply it to our dataset:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>nltk</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>nltk.corpus</span> <span class=kn>import</span> <span class=n>movie_reviews</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nltk</span><span class=o>.</span><span class=n>download</span><span class=p>(</span><span class=s1>&#39;movie_reviews&#39;</span><span class=p>)</span>  
</span></span><span class=line><span class=cl><span class=n>reviews</span> <span class=o>=</span> <span class=p>[</span><span class=n>movie_reviews</span><span class=o>.</span><span class=n>raw</span><span class=p>(</span><span class=n>fileid</span><span class=p>)</span> <span class=k>for</span> <span class=n>fileid</span> <span class=ow>in</span> <span class=n>movie_reviews</span><span class=o>.</span><span class=n>fileids</span><span class=p>()]</span>
</span></span></code></pre></td></tr></table></div></div><p>In the code snippet above, we utilize Python&rsquo;s <code>NLTK</code> module to download and import the <code>IMDB movie reviews dataset</code>.</p><p>Next, we&rsquo;ll again use Scikit-learn&rsquo;s <code>CountVectorizer</code> to apply the BoW method to our reviews:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>bag_of_words</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>reviews</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;The shape of our Bag-of-Words is: </span><span class=si>{</span><span class=n>bag_of_words</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The shape of our Bag-of-Words is: (2000, 39659)
</span></span></code></pre></td></tr></table></div></div><p>The output indicates that the result is a matrix where each row corresponds to a movie review and each column to a unique word. The entries in this matrix are word counts.</p><h5 id=understanding-the-bag-of-words-matrix-and-most-used-word>Understanding the Bag-of-Words Matrix and Most Used Word</h5><p>Let&rsquo;s decode what&rsquo;s inside the <code>bag_of_words</code> matrix:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>feature_names</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>first_review_word_counts</span> <span class=o>=</span> <span class=n>bag_of_words</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>toarray</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>Here, we retrieve the feature names (which are unique words in the reviews) from our <code>CountVectorizer</code> model. Then we get the word counts for a specific review - in our case, we chose the first one.</p><p>Subsequently, let&rsquo;s find out which word in the first review occurs the most:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>max_count_index</span> <span class=o>=</span> <span class=n>first_review_word_counts</span><span class=o>.</span><span class=n>argmax</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>most_used_word</span> <span class=o>=</span> <span class=n>feature_names</span><span class=p>[</span><span class=n>max_count_index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;The most used word is &#39;</span><span class=si>{</span><span class=n>most_used_word</span><span class=si>}</span><span class=s2>&#39; with a count of </span><span class=si>{</span><span class=n>first_review_word_counts</span><span class=p>[</span><span class=n>max_count_index</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Running the above code would output something like:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>The</span> <span class=n>most</span> <span class=n>used</span> <span class=n>word</span> <span class=ow>is</span> <span class=s1>&#39;the&#39;</span> <span class=k>with</span> <span class=n>a</span> <span class=n>count</span> <span class=n>of</span> <span class=mi>38</span>
</span></span></code></pre></td></tr></table></div></div><p>The output gives away the most used word in the first review and its count. The script finds the index of the word with the highest count in the first review. Then, it uses this index to identify the corresponding word in the <code>feature_names</code>. This demonstrates how we can identify the most used word in a specific review using the Bag-of-Words model.</p><h5 id=lesson-summary-2>Lesson Summary</h5><p>Congratulations! You&rsquo;ve successfully made it through this lesson. Today, you&rsquo;ve learned how to implement a significant concept in the world of text classification, the <code>Bag-of-Words</code> method. You&rsquo;ve not only understood the theoretical aspect of it, but you also applied it on a real-world dataset using Python. You even used it to extract insights about word frequency, a crucial aspect of many text classification problems.</p><p>As we move forward in the upcoming lessons, we&rsquo;ll take what you&rsquo;ve learned today, build on top of it, and continue our journey to understand and apply more advanced text classification techniques. Remember, practice makes perfect, so try to apply what you&rsquo;ve learned today on different text data on your own. Happy coding, and see you in the next lesson!</p><p>Start practice</p><h2 id=practice-14>「Practice」</h2><p>Great job! Now, let&rsquo;s play around with the <strong>text</strong>. Change the provided sentences to any three sentences of your choice. Then, observe how this affects the <strong>Bag-of-Words</strong> representation. Remember, the output should be a <strong>matrix</strong>, with each row representing one of your sentences and each column representing a unique word.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Custom sentences</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sentences</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;The cat sat on the mat.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;The cat sat near the mat.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;The cat played with a ball.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Feature names:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Bag of Words Representation:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>解释
Certainly! I&rsquo;ll modify the sentences and show you how it affects the Bag-of-Words representation. Here&rsquo;s the updated code with new sentences:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Simple example sentences</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sentences</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Machine learning is fascinating.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;Deep learning is a subset of machine learning.&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;We use Python for machine learning.&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Feature names:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>vectorizer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Bag of Words Representation:&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>Let&rsquo;s break down the filled-in parts:</p><ol><li><p>We import <code>CountVectorizer</code> from <code>sklearn.feature_extraction.text</code>.</p></li><li><p>We create an instance of <code>CountVectorizer</code> with <code>vectorizer = CountVectorizer()</code>.</p></li><li><p>We use <code>fit_transform(sentences)</code> to both fit the vectorizer to our sentences (learning the vocabulary) and transform the sentences into a Bag-of-Words representation in one step.</p></li></ol><p>When you run this code, you&rsquo;ll see output similar to this:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Feature names:
</span></span><span class=line><span class=cl>[&#39;deep&#39; &#39;fascinating&#39; &#39;for&#39; &#39;is&#39; &#39;learning&#39; &#39;machine&#39; &#39;of&#39; &#39;python&#39; &#39;subset&#39; &#39;use&#39; &#39;we&#39;]
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Bag of Words Representation:
</span></span><span class=line><span class=cl>[[0 1 0 1 1 1 0 0 0 0 0]
</span></span><span class=line><span class=cl> [1 0 0 1 2 1 1 0 1 0 0]
</span></span><span class=line><span class=cl> [0 0 1 0 1 1 0 1 0 1 1]]
</span></span></code></pre></td></tr></table></div></div><p>This output shows:</p><ol><li>The unique words (features) extracted from all sentences.</li><li>A matrix where each row represents a sentence, and each column represents a word. The numbers in the matrix indicate how many times each word appears in each sentence.</li></ol><p>For example, in the second sentence, &rsquo;learning&rsquo; appears twice, which is reflected in the matrix.</p><p>This Bag-of-Words representation is a fundamental technique in natural language processing and is often used as a starting point for more complex text analysis tasks. Great job on exploring this concept!</p><h1 id=introduction-to-sparse-matrices>Introduction to Sparse Matrices</h1><p>Hello and welcome to this lesson on <strong>&ldquo;Efficient Text Data Representation with Sparse Matrices&rdquo;</strong>. As you recall, in our previous lessons, we transformed raw text data into numerical features, for example, using the <em>Bag-of-Words</em> (BoW) or <em>Term Frequency-Inverse Document Frequency</em> (TF-IDF) techniques. These transformation methods often create what we call &ldquo;Sparse Matrices,&rdquo; an incredibly memory-efficient way of storing high-dimensional data.</p><p>Let&rsquo;s break this down a bit. In the context of text data, each unique word across all documents could be treated as a distinct feature. However, each document will only include a small subset of these available features or unique words. Meaning, most entries in our feature matrix end up being 0s, hence resulting in a sparse matrix.</p><p>We&rsquo;ll begin with a simple non-text matrix to illustrate sparse matrices and later connect this knowledge to our journey on text data transformation.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.sparse</span> <span class=kn>import</span> <span class=n>csr_matrix</span><span class=p>,</span> <span class=n>csc_matrix</span><span class=p>,</span> <span class=n>coo_matrix</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Simple example matrix</span>
</span></span><span class=line><span class=cl><span class=n>vectors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=sparse-matrix-formats-csr>Sparse Matrix Formats: CSR</h5><p>In this section, we&rsquo;ll investigate how we can handle sparse matrices in different formats including: <em>Compressed Sparse Row</em> (CSR), <em>Compressed Sparse Column</em> (CSC), and the <em>Coordinate</em> (COO) formats.</p><p>We&rsquo;ll start with the CSR format, a common format for sparse matrices that is excellent for quick arithmetic operations and matrix vector calculations.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># CSR format</span>
</span></span><span class=line><span class=cl><span class=n>sparse_csr</span> <span class=o>=</span> <span class=n>csr_matrix</span><span class=p>(</span><span class=n>vectors</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Compressed Sparse Row (CSR) Matrix:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>sparse_csr</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Compressed Sparse Row (CSR) Matrix:
</span></span><span class=line><span class=cl>   (0, 2)	2
</span></span><span class=line><span class=cl>  (0, 3)	3
</span></span><span class=line><span class=cl>  (1, 0)	4
</span></span><span class=line><span class=cl>  (1, 4)	6
</span></span><span class=line><span class=cl>  (4, 1)	7
</span></span><span class=line><span class=cl>  (4, 3)	8
</span></span><span class=line><span class=cl>Observe that in the output of the Compressed Sparse Row representation, it records the values in the matrix row-wise, starting from the top. Each entry (0, 2), for example, tells us that the element in the 0th row and 2nd column is 2.
</span></span></code></pre></td></tr></table></div></div><p>##Sparse Matrix Formats: CSC</p><p>Next, let&rsquo;s convert our <code>vectors</code> matrix to the CSC format. This format, like the CSR format, also forms the backbone of many operations we perform on sparse matrices. But it stores the non-zero entries column-wise, and is especially efficient for column slicing operations.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl># CSC format
</span></span><span class=line><span class=cl>sparse_csc = csc_matrix(vectors)
</span></span><span class=line><span class=cl>print(&#34;Compressed Sparse Column (CSC) Matrix:\n&#34;, sparse_csc)
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Compressed Sparse Column (CSC) Matrix:
</span></span><span class=line><span class=cl>   (1, 0)	4
</span></span><span class=line><span class=cl>  (4, 1)	7
</span></span><span class=line><span class=cl>  (0, 2)	2
</span></span><span class=line><span class=cl>  (0, 3)	3
</span></span><span class=line><span class=cl>  (4, 3)	8
</span></span><span class=line><span class=cl>  (1, 4)	6
</span></span></code></pre></td></tr></table></div></div><p>In this Compressed Sparse Column output, the non-zero entries are stored column-wise. Essentially, CSC format is a transpose of the CSR format.</p><h5 id=sparse-matrix-formats-coo>Sparse Matrix Formats: COO</h5><p>Lastly, let&rsquo;s convert our example to the COO format or Coordinate List format. The COO format is another useful way to represent a sparse matrix and is simpler compared to CSR or CSC formats.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># COO format</span>
</span></span><span class=line><span class=cl><span class=n>sparse_coo</span> <span class=o>=</span> <span class=n>coo_matrix</span><span class=p>(</span><span class=n>vectors</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Coordinate Format (COO) Matrix:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>sparse_coo</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Coordinate Format (COO) Matrix:
</span></span><span class=line><span class=cl>   (0, 2)	2
</span></span><span class=line><span class=cl>  (0, 3)	3
</span></span><span class=line><span class=cl>  (1, 0)	4
</span></span><span class=line><span class=cl>  (1, 4)	6
</span></span><span class=line><span class=cl>  (4, 1)	7
</span></span><span class=line><span class=cl>  (4, 3)	8
</span></span></code></pre></td></tr></table></div></div><p>In the COO format, or Coordinate format, the non-zero entries are represented by their own coordinates (row, column). Unlike CSC or CSR, the COO format can contain duplicate entries. This can be particularly useful when data is being accumulated in several passes and there might be instances where duplicate entries are generated. These duplicates are not immediately merged in the COO format, providing you with flexibility for subsequent processing like duplicate resolution.</p><h5 id=vectorized-operations-csr-and-csc>Vectorized Operations: CSR and CSC</h5><p>Sparse matrices are not just memory-efficient storage mechanisms, but they also allow us to conduct operations directly on them. Specifically, the CSR and CSC formats support these operations directly, whereas the COO format requires converting back to CSR or CSC first.</p><p>Let&rsquo;s see this in practice when performing a multiplication operation.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Running</span> <span class=n>operations</span> <span class=n>on</span> <span class=n>CSR</span> <span class=ow>and</span> <span class=n>CSC</span> <span class=n>matrices</span>
</span></span><span class=line><span class=cl><span class=n>weighted_csr</span> <span class=o>=</span> <span class=n>sparse_csr</span><span class=o>.</span><span class=n>multiply</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Weighted CSR:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>weighted_csr</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the code block above will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Weighted CSR:
</span></span><span class=line><span class=cl> [[0.  0.  1.  1.5 0. ]
</span></span><span class=line><span class=cl> [2.  0.  0.  0.  3. ]
</span></span><span class=line><span class=cl> [0.  3.5 0.  4.  0. ]
</span></span><span class=line><span class=cl> [0.  0.  0.  0.  0. ]
</span></span><span class=line><span class=cl> [0.  0.  0.  0.  0. ]]
</span></span></code></pre></td></tr></table></div></div><p>We can see the impressive CSR format efficiency in vectorized operations, which becomes crucial when performing calculations with large text data.</p><h5 id=vectorized-operations-coo>Vectorized Operations: COO</h5><p>And now let&rsquo;s demonstrate the process of performing the same multiplication operation on the COO format, but this time requiring conversion to CSR or CSC first.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Operation on COO requires conversion to CSR or CSC first</span>
</span></span><span class=line><span class=cl><span class=n>weighted_coo</span> <span class=o>=</span> <span class=n>sparse_coo</span><span class=o>.</span><span class=n>tocsr</span><span class=p>()</span><span class=o>.</span><span class=n>multiply</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Weighted COO:</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>weighted_coo</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Weighted COO:
</span></span><span class=line><span class=cl> [[0.  0.  1.  1.5 0. ]
</span></span><span class=line><span class=cl> [2.  0.  0.  0.  3. ]
</span></span><span class=line><span class=cl> [0.  3.5 0.  4.  0. ]
</span></span><span class=line><span class=cl> [0.  0.  0.  0.  0. ]
</span></span><span class=line><span class=cl> [0.  0.  0.  0.  0. ]]
</span></span></code></pre></td></tr></table></div></div><h5 id=the-connection-between-sparse-matrices-and-nlp>The Connection Between Sparse Matrices and NLP</h5><p>After going through the concepts and code, you might ask - what does all this have to do with NLP? Well, remember when we transformed raw text data into either a <em>Bag-of-Words</em> or a <em>TF-IDF</em> representation in the previous lessons? Each unique word across all documents was treated as a distinct feature. Given the high dimensionality and inherent sparsity of the resulting feature representation, we used sparse matrices for efficient storage.</p><p>Handling of sparse matrices becomes crucial in large NLP tasks, as they allow us to operate on large datasets while maintaining computational efficiency and optimal memory usage. Therefore, understanding these different formats of sparse matrices is an essential part of your feature engineering skills for text classification.</p><h5 id=lesson-summary-3>Lesson Summary</h5><p>Congratulations! Today, you gained an insight into sparse matrices and their different formats, how they help efficiently storing and operating on high dimensional data like that of text records in NLP. You also explored the implications of implementing vectorized operations on different sparse matrix formats. Structuring your learning and understanding these formats is paramount to efficiently handle large datasets in NLP and other machine learning tasks. In the upcoming exercises, you&rsquo;ll get hands-on experience with these concepts, reinforcing your understanding further. Keep up the momentum and dive into practice!</p><h5 id=topic-overview-and-actualization>Topic Overview and Actualization</h5><p>主题概述与现实化</p><p>Today, we target duplicates and outliers to clean our data for more accurate analysis.<br>今天，我们将针对重复数据和异常值进行清理，以便进行更准确的分析。</p><h5 id=understanding-duplicates-in-data>Understanding Duplicates in Data</h5><p>理解数据中的重复项</p><p>Let&rsquo;s consider a dataset from a school containing students&rsquo; details. If a student&rsquo;s information appears more than once, that is regarded as a duplicate. Duplicates distort data, leading to inaccurate statistics.<br>考虑一个包含学生详细信息的学校数据集。如果一个学生的资讯出现多次，则被视为重复数据。重复数据会扭曲数据，导致统计数据不准确。</p><h2 id=practice-15>「Practice」</h2><p>Greetings, Stellar Navigator! For this assignment, we&rsquo;re focusing on model initialization and training. You will find a TODO comment in the provided starter code. Fill it in to define the Naive Bayes model and train it! You&rsquo;ll be able to see the difference between your model&rsquo;s prediction and the actual results visually on a scatter plot. Let&rsquo;s dive in!
你好，星际领航员！本次作业的重点是模型初始化和训练。你会在提供的初始代码中找到一个 TODO 注释。请完成注释内容，定义朴素贝叶斯模型并对其进行训练！你将能够在散点图上直观地看到你的模型预测结果与实际结果之间的差异。让我们开始吧！</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import the necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.naive_bayes</span> <span class=kn>import</span> <span class=n>MultinomialNB</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_dataset</span><span class=p>(</span><span class=s1>&#39;codesignal/sms-spam-collection&#39;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>spam_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define X (input features) and Y (output labels)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Y</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform the train test split using stratified cross-validation</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>,</span> <span class=n>Y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>count_vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit and transform the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Transform the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_test_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Initialize the MultinomialNB model and fit it on the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>naive_bayes_model</span> <span class=o>=</span> <span class=n>MultinomialNB</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>naive_bayes_model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_count</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Make predictions on the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Y_pred</span> <span class=o>=</span> <span class=n>naive_bayes_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create a DataFrame with actual and predicted labels</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>results_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span><span class=s2>&#34;Actual&#34;</span><span class=p>:</span> <span class=n>Y_test</span><span class=p>,</span> <span class=s2>&#34;Predicted&#34;</span><span class=p>:</span> <span class=n>Y_pred</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># We now generate indices for our scatter plot for clarity</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>indices</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>51</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plotting the comparison scatter plot for the first 50 messages</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot actual labels</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>indices</span><span class=p>,</span> <span class=n>results_df</span><span class=p>[</span><span class=s2>&#34;Actual&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>[:</span><span class=mi>50</span><span class=p>],</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;b&#39;</span><span class=p>,</span> <span class=n>facecolors</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Actual&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot predicted labels</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>indices</span><span class=p>,</span> <span class=n>results_df</span><span class=p>[</span><span class=s2>&#34;Predicted&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>[:</span><span class=mi>50</span><span class=p>],</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>,</span><span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Predicted&#39;</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=s1>&#39;Ham&#39;</span><span class=p>,</span> <span class=s1>&#39;Spam&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Category&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Message Number&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Actual vs Predicted Labels for First 50 Messages&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=practice-16>「Practice」</h2><p>亲爱的太空旅行者，你的技能再次被需要！利用你所学到的关于朴素贝叶斯模型的知识，你的任务是使用混淆矩阵评估你的模型。实现朴素贝叶斯模型，进行预测，然后使用测试数据为模型生成混淆矩阵。绘制混淆矩阵的结果以进行视觉评估。Dear Space Voyager, your skills are needed once again! Using what you&rsquo;ve learned about the <strong>Naive Bayes Model</strong>, your mission is to evaluate your model using a <strong>confusion matrix</strong>. Implement the <strong>Naive Bayes model</strong>, make predictions, and then generate a confusion matrix for the model using the test data. Plot the results of the confusion matrix for visual assessment.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import the necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.naive_bayes</span> <span class=kn>import</span> <span class=n>MultinomialNB</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>metrics</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_dataset</span><span class=p>(</span><span class=s1>&#39;codesignal/sms-spam-collection&#39;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>spam_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define X (input features) and Y (output labels)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Y</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform the train test split using stratified cross-validation</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>,</span> <span class=n>Y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Initialize the CountVectorizer and fit and transform the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Transform the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Initialize the MultinomialNB model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Fit the model on the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Make predictions on the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Generate confusion matrix</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>confusion_matrix</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>confusion_matrix</span><span class=p>(</span><span class=n>Y_test</span><span class=p>,</span> <span class=n>Y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create a DataFrame with confusion matrix</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>confusion_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ham&#39;</span><span class=p>,</span> <span class=s1>&#39;spam&#39;</span><span class=p>],</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ham&#39;</span><span class=p>,</span> <span class=s1>&#39;spam&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the confusion DataFrame</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>confusion_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot the confusion matrix</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span><span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>confusion_df</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;d&#39;</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Blues&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>解释</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span><span class=lnt>91
</span><span class=lnt>92
</span><span class=lnt>93
</span><span class=lnt>94
</span><span class=lnt>95
</span><span class=lnt>96
</span><span class=lnt>97
</span><span class=lnt>98
</span><span class=lnt>99
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import the necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.naive_bayes</span> <span class=kn>import</span> <span class=n>MultinomialNB</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>metrics</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_dataset</span><span class=p>(</span><span class=s1>&#39;codesignal/sms-spam-collection&#39;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>spam_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define X (input features) and Y (output labels)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Y</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform the train test split using stratified cross-validation</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>,</span> <span class=n>Y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Initialize the CountVectorizer and fit and transform the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>count_vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Transform the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_test_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Initialize the MultinomialNB model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>naive_bayes_model</span> <span class=o>=</span> <span class=n>MultinomialNB</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Fit the model on the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>naive_bayes_model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_count</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TODO: Make predictions on the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Y_pred</span> <span class=o>=</span> <span class=n>naive_bayes_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Generate confusion matrix</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>confusion_matrix</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>confusion_matrix</span><span class=p>(</span><span class=n>Y_test</span><span class=p>,</span> <span class=n>Y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create a DataFrame with confusion matrix</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>confusion_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ham&#39;</span><span class=p>,</span> <span class=s1>&#39;spam&#39;</span><span class=p>],</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ham&#39;</span><span class=p>,</span> <span class=s1>&#39;spam&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the confusion DataFrame</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>confusion_df</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot the confusion matrix</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span><span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>confusion_df</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;d&#39;</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Blues&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>好的,让我们用更简单的方式,给5岁的小朋友解释这个有趣的游戏: 1. 想象你有一大堆信件。有些是好朋友写的,有些是坏人寄来的骗人的信。 2. 我们要教一个机器人朋友分辨哪些是好信,哪些是坏信。 3. 首先,我们给机器人一些信看,告诉它哪些是好的,哪些是坏的。这就像教你分辨苹果和橘子。 4. 然后,我们给机器人一些新的信,看它能不能猜对是好信还是坏信。 5. 最后,我们画了一个有颜色的图画: - 蓝色的格子越深,说明机器人猜对的次数越多。 - 浅色的格子说明机器人有时候会猜错。 6. 如果图画上深蓝色的格子多,浅色的格子少,就说明我们的机器人朋友学得很好! 这就像教你的玩具机器人分辨好东西和坏东西。如果它学得好,就能帮我们找出那些骗人的坏信,保护我们不受骗。是不是很神奇呀?</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-mysql data-lang=mysql><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>好的</span><span class=p>,</span><span class=err>我来尝试用简单的语言解释这段代码</span><span class=p>,</span><span class=err>让三年级的小朋友也能理解</span><span class=p>:</span><span class=w> </span><span class=mi>1</span><span class=p>.</span><span class=w> </span><span class=err>首先</span><span class=p>,</span><span class=err>我们有一堆短信。有些是正常的短信</span><span class=p>,</span><span class=err>有些是垃圾短信。我们想教电脑分辨哪些是垃圾短信。</span><span class=w> </span><span class=mi>2</span><span class=p>.</span><span class=w> </span><span class=err>我们把这些短信分成两组</span><span class=p>:</span><span class=err>一组用来教电脑</span><span class=p>,</span><span class=err>另一组用来测试电脑学得怎么样。</span><span class=w> </span><span class=mi>3</span><span class=p>.</span><span class=w> </span><span class=err>接下来</span><span class=p>,</span><span class=err>我们要把短信变成数字</span><span class=p>,</span><span class=err>因为电脑更擅长处理数字。我们数一数每个短信里有哪些词</span><span class=p>,</span><span class=err>出现了多少次。</span><span class=w> </span><span class=mi>4</span><span class=p>.</span><span class=w> </span><span class=err>然后</span><span class=p>,</span><span class=err>我们用一种叫</span><span class=s2>&#34;朴素贝叶斯&#34;</span><span class=err>的方法来教电脑。这就像教电脑玩一个猜谜游戏。</span><span class=w> </span><span class=mi>5</span><span class=p>.</span><span class=w> </span><span class=err>教完之后</span><span class=p>,</span><span class=err>我们让电脑猜测那些测试用的短信是不是垃圾短信。</span><span class=w> </span><span class=mi>6</span><span class=p>.</span><span class=w> </span><span class=err>最后</span><span class=p>,</span><span class=err>我们看看电脑猜得对不对。我们画了一个表格</span><span class=p>:</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=err>左上角的数字是电脑正确地说</span><span class=s2>&#34;这不是垃圾短信&#34;</span><span class=err>的次数。</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=err>右上角是电脑错误地说</span><span class=s2>&#34;这是垃圾短信&#34;</span><span class=err>的次数。</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=err>左下角是电脑错误地说</span><span class=s2>&#34;这不是垃圾短信&#34;</span><span class=err>的次数。</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=err>右下角是电脑正确地说</span><span class=s2>&#34;这是垃圾短信&#34;</span><span class=err>的次数。</span><span class=w> </span><span class=mi>7</span><span class=p>.</span><span class=w> </span><span class=err>我们还画了一个彩色的图</span><span class=p>,</span><span class=err>颜色越深的地方</span><span class=p>,</span><span class=err>数字越大。这样我们一眼就能看出电脑学得好不好。</span><span class=w> </span><span class=err>通过这个游戏</span><span class=p>,</span><span class=err>我们教会了电脑分辨垃圾短信</span><span class=p>,</span><span class=err>就像教小朋友分辨健康食物和垃圾食品一样</span><span class=o>!</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>##A Brief Introduction to Support Vector Machines (SVM)  
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=err>支持向量机</span><span class=w> </span><span class=p>(</span><span class=n>SVM</span><span class=p>)</span><span class=w> </span><span class=err>简介</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>In</span><span class=w> </span><span class=n>machine</span><span class=w> </span><span class=n>learning</span><span class=p>,</span><span class=w> </span><span class=o>**</span><span class=n>Support</span><span class=w> </span><span class=n>Vector</span><span class=w> </span><span class=n>Machines</span><span class=o>**</span><span class=w> </span><span class=p>(</span><span class=n>SVMs</span><span class=p>)</span><span class=w> </span><span class=n>are</span><span class=w> </span><span class=n>classification</span><span class=w> </span><span class=n>algorithms</span><span class=w> </span><span class=n>that</span><span class=w> </span><span class=n>you</span><span class=w> </span><span class=n>can</span><span class=w> </span><span class=k>use</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>label</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=k>into</span><span class=w> </span><span class=n>different</span><span class=w> </span><span class=n>classes</span><span class=p>.</span><span class=w> </span><span class=n>The</span><span class=w> </span><span class=o>`</span><span class=n>SVM</span><span class=o>`</span><span class=w> </span><span class=n>algorithm</span><span class=w> </span><span class=n>segregates</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=k>into</span><span class=w> </span><span class=n>two</span><span class=w> </span><span class=n>groups</span><span class=w> </span><span class=k>by</span><span class=w> </span><span class=n>finding</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=n>hyperplane</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=n>high</span><span class=o>-</span><span class=n>dimensional</span><span class=w> </span><span class=nf>space</span><span class=w> </span><span class=p>(</span><span class=k>or</span><span class=w> </span><span class=n>surface</span><span class=p>,</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=k>case</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>more</span><span class=w> </span><span class=n>than</span><span class=w> </span><span class=n>two</span><span class=w> </span><span class=n>features</span><span class=p>)</span><span class=w> </span><span class=n>that</span><span class=w> </span><span class=n>distinctly</span><span class=w> </span><span class=n>classifies</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=n>points</span><span class=p>.</span><span class=w> </span><span class=n>The</span><span class=w> </span><span class=n>algorithm</span><span class=w> </span><span class=n>chooses</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>hyperplane</span><span class=w> </span><span class=n>that</span><span class=w> </span><span class=n>represents</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>largest</span><span class=w> </span><span class=n>separation</span><span class=p>,</span><span class=w> </span><span class=k>or</span><span class=w> </span><span class=n>margin</span><span class=p>,</span><span class=w> </span><span class=k>between</span><span class=w> </span><span class=n>classes</span><span class=p>.</span><span class=w>  
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>在机器学习中，支持向量机</span><span class=w> </span><span class=p>(</span><span class=n>SVM</span><span class=p>)</span><span class=w> </span><span class=err>是一种分类算法，可用于将数据标记到不同的类别中。</span><span class=n>SVM</span><span class=w> </span><span class=err>算法通过在高维空间（如果特征超过两个，则为曲面）中找到一个能够清晰地区分数据点的超平面，将数据分成两组。该算法选择能够代表类别之间最大间隔（或称“边际”）的超平面。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>`</span><span class=n>SVM</span><span class=o>`</span><span class=w> </span><span class=k>is</span><span class=w> </span><span class=n>extremely</span><span class=w> </span><span class=n>useful</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>solving</span><span class=w> </span><span class=n>nonlinear</span><span class=w> </span><span class=kt>text</span><span class=w> </span><span class=n>classification</span><span class=w> </span><span class=n>problems</span><span class=p>.</span><span class=w> </span><span class=n>It</span><span class=w> </span><span class=n>can</span><span class=w> </span><span class=n>efficiently</span><span class=w> </span><span class=n>perform</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=n>non</span><span class=o>-</span><span class=n>linear</span><span class=w> </span><span class=n>classification</span><span class=w> </span><span class=k>using</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>_</span><span class=s2>&#34;kernel trick,&#34;</span><span class=n>_</span><span class=w> </span><span class=n>implicitly</span><span class=w> </span><span class=n>mapping</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>inputs</span><span class=w> </span><span class=k>into</span><span class=w> </span><span class=n>high</span><span class=o>-</span><span class=n>dimensional</span><span class=w> </span><span class=n>feature</span><span class=w> </span><span class=n>spaces</span><span class=p>.</span><span class=w>  
</span></span></span><span class=line><span class=cl><span class=w></span><span class=err>支持向量机</span><span class=w> </span><span class=p>(</span><span class=n>SVM</span><span class=p>)</span><span class=w> </span><span class=err>对于解决非线性文本分类问题非常有效。它可以通过“核技巧”有效地执行非线性分类，将输入隐式映射到高维特征空间。</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>In</span><span class=w> </span><span class=n>summary</span><span class=p>,</span><span class=w> </span><span class=o>`</span><span class=n>SVM</span><span class=o>`</span><span class=s1>&#39;s distinguishing factors are:  
</span></span></span><span class=line><span class=cl><span class=s1>综上所述，支持向量机的显著特点是：
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>- **Hyperplanes**: These are decision boundaries that help `SVM` separate data into different classes.  
</span></span></span><span class=line><span class=cl><span class=s1>    超平面：这些是帮助 SVM 将数据分成不同类别的决策边界。
</span></span></span><span class=line><span class=cl><span class=s1>- **Support Vectors**: These are the data points that lie closest to the decision surface (or hyperplane). They are critical elements of `SVM` because they help maximize the margin of the classifier.  
</span></span></span><span class=line><span class=cl><span class=s1>    支持向量：这些数据点最接近决策面（或超平面）。它们是支持向量机的关键要素，因为它们有助于最大化分类器的边界。
</span></span></span><span class=line><span class=cl><span class=s1>- **Kernel Trick**: The kernel helps `SVM` to deal with non-linear input spaces by using a higher dimension space.  
</span></span></span><span class=line><span class=cl><span class=s1>    核技巧：核函数通过将数据映射到更高维空间，帮助支持向量机处理非线性输入空间。
</span></span></span><span class=line><span class=cl><span class=s1>- **Soft Margin**: `SVM` allows some misclassifications in its model for better performance. This flexibility is introduced through a concept called Soft Margin.  
</span></span></span><span class=line><span class=cl><span class=s1>    软间隔：为了获得更好的性能，SVM 允许模型中存在一些错误分类。这种灵活性是通过称为软间隔的概念引入的。```
</span></span></span><span class=line><span class=cl><span class=s1>    ### Loading and Preprocessing the Data
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>This section is a quick revisit of the code you are already familiar with. We are just loading and preprocessing the _SMS Spam Collection_ dataset.
</span></span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import the necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>metrics</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.svm</span> <span class=kn>import</span> <span class=n>SVC</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the dataset</span>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_dataset</span><span class=p>(</span><span class=s1>&#39;codesignal/sms-spam-collection&#39;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>spam_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define X (input features) and Y (output labels)</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>Y</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform the train test split using stratified cross-validation</span>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>,</span> <span class=n>Y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=n>count_vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit and transform the training data </span>
</span></span><span class=line><span class=cl><span class=n>X_train_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Transform the test data</span>
</span></span><span class=line><span class=cl><span class=n>X_test_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=implementing-support-vector-machines-for-text-classification>Implementing Support Vector Machines for Text Classification</h5><p>Let&rsquo;s delve into the practical implementation of <code>SVM</code> for text classification using the <code>Scikit-learn</code> library. We are going to introduce a new <code>Scikit-learn</code> function, <code>SVC()</code>. This function is used to fit the <code>SVM</code> model according to the given training data.</p><p>In the following Python code, we initialize the <code>SVC</code> model, fit it with our training data, and then make predictions on the test dataset.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the SVC model</span>
</span></span><span class=line><span class=cl><span class=n>svm_model</span> <span class=o>=</span> <span class=n>SVC</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit the model on the training data</span>
</span></span><span class=line><span class=cl><span class=n>svm_model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_count</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Make predictions on the test data</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>svm_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_count</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The <code>SVC</code> function takes several parameters, with the key ones being:</p><ul><li><code>C</code>: This is the penalty parameter of the error term. It controls the trade off between smooth decision boundary and classifying training points correctly.</li><li><code>kernel</code>: Specifies the kernel type to be used in the algorithm. It can be &rsquo;linear&rsquo;, &lsquo;poly&rsquo;, &lsquo;rbf&rsquo;, &lsquo;sigmoid&rsquo;, &lsquo;precomputed&rsquo; or a callable.</li><li><code>degree</code>: Degree of the polynomial kernel function (&lsquo;poly&rsquo;). Ignored by all other kernels.</li><li><h5 id=making-predictions-and-evaluating-the-svm-model>Making Predictions and Evaluating the SVM Model</h5></li></ul><p>进行预测和评估支持向量机模型</p><p>After building the model, the next step is to use it on unseen data and evaluate its performance. The python code for this step is shown below:<br>模型构建完成后，下一步是在未见过的数据上使用该模型并评估其性能。下面展示了此步骤的 Python 代码：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Make predictions on the test data</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>svm_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the accuracy of the model</span>
</span></span><span class=line><span class=cl><span class=n>accuracy</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>accuracy_score</span><span class=p>(</span><span class=n>Y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the accuracy</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Accuracy of Support Vector Machines Classifier: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:<br>以上代码的输出结果为：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Accuracy</span> <span class=n>of</span> <span class=n>Support</span> <span class=n>Vector</span> <span class=n>Machines</span> <span class=n>Classifier</span><span class=p>:</span> <span class=mf>0.98</span>
</span></span></code></pre></td></tr></table></div></div><p>This output signifies that our <code>SVM</code> model has achieved a high accuracy, specifically 98%, in classifying messages as spam or ham, highlighting its effectiveness in text classification tasks.<br>此结果表明，我们的支持向量机 (SVM) 模型在将邮件分类为垃圾邮件或非垃圾邮件方面达到了 98% 的高准确率，凸显了其在文本分类任务中的有效性。</p><h5 id=lesson-summary-and-upcoming-practice>Lesson Summary and Upcoming Practice</h5><p>课程总结和即将进行的练习</p><p>Congratulations on making it to the end of this lesson! You have now learned the theory behind <strong>Support Vector Machines</strong> (SVMs) and how to use them to perform text classification in Python. You&rsquo;ve also learned to load and preprocess the data, build the <code>SVM</code> model, and evaluate its accuracy.<br>恭喜你完成了本课的学习！你现在已经学习了支持向量机 (SVM) 背后的理论，以及如何使用它们在 Python 中执行文本分类。你还学习了如何加载和预处理数据、构建 SVM 模型以及评估其准确性。
Remember, like any other skill, programming requires practice. The upcoming practice exercises will allow you to reinforce the knowledge you&rsquo;ve acquired in this lesson. They have been carefully designed to give you further expertise in <code>SVM</code> and text classification. Good luck! You&rsquo;re doing a great job, and I&rsquo;m excited to see you in the next lesson on Decision Trees for text classification.<br>记住，编程和其他技能一样，都需要练习。接下来的练习将帮助你巩固在本节课中学到的知识。这些练习经过精心设计，旨在让你进一步掌握支持向量机和文本分类方面的知识。祝你好运！你做得很好，我期待在下一节关于决策树文本分类的课程中见到你。</p><p>Certainly! I&rsquo;ll modify the code to use the polynomial kernel (&lsquo;poly&rsquo;) instead of the linear kernel for the SVM model. Here&rsquo;s the adjusted code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import the necessary libraries </span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span> 
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span> <span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>metrics</span> <span class=kn>from</span> <span class=nn>sklearn.svm</span> <span class=kn>import</span> <span class=n>SVC</span> <span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span> <span class=kn>import</span> <span class=nn>datasets</span> <span class=c1># Load the dataset spam_dataset = datasets.load_dataset(&#39;codesignal/sms-spam-collection&#39;, split=&#39;train&#39;) spam_dataset = pd.DataFrame(spam_dataset) # Define X (input features) and Y (output labels) X = spam_dataset[&#34;message&#34;] Y = spam_dataset[&#34;label&#34;] # Perform the train test split using stratified cross-validation X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y) # Initialize the CountVectorizer count_vectorizer = CountVectorizer() # Fit and transform the training data X_train_count = count_vectorizer.fit_transform(X_train) # Transform the test data X_test_count = count_vectorizer.transform(X_test) # Initialize the SVC model with &#39;poly&#39; kernel svm_model = SVC(kernel=&#39;poly&#39;) # Fit the model on the training data svm_model.fit(X_train_count, Y_train) # Make predictions on the test data y_pred = svm_model.predict(X_test_count) # Calculate the accuracy of the model accuracy = metrics.accuracy_score(Y_test, y_pred) # Print the accuracy print(f&#34;Accuracy of Support Vector Machines Classifier with polynomial kernel: {accuracy:.2f}&#34;)</span>
</span></span></code></pre></td></tr></table></div></div><p>好的,我会尝试用简单的语言来解释这段代码,就像是在跟6岁的小朋友讲故事一样。 想象一下,我们有一个神奇的机器人朋友,它可以帮我们分辨短信是不是垃圾短信。我们要教这个机器人怎么做到这一点。这就是这段代码要做的事情。 1. 首先,我们需要给机器人一些工具。这些工具就像是机器人的眼睛和大脑,帮它看东西和思考。 2. 然后,我们给机器人一大堆短信。有些是好短信,有些是坏短信(垃圾短信)。 3. 我们把这些短信分成两部分:一部分用来教机器人,另一部分用来测试机器人学得怎么样。 4. 接下来,我们教机器人看短信。我们告诉它要注意短信里的每个字,就像你在学习认字一样。 5. 现在,我们要教机器人一个特殊的技能,叫做"多项式核"。这个技能可以帮助机器人理解更复杂的短信内容。 6. 机器人开始学习了!它仔细看每一条教它的短信,努力记住哪些是好短信,哪些是坏短信。 7. 学习完后,我们给机器人一些新的短信,看它能不能正确分辨出哪些是垃圾短信。 8. 最后,我们要给机器人打分。如果它猜对了很多,就说明它学得很好! 9. 我们把机器人的分数打印出来,看看它学得怎么样。 这就是整个过程啦!我们教会了机器人朋友一个新技能,让它可以帮我们分辨垃圾短信。是不是很神奇呀?</p><h3 id=topic-overview-and-actualization-1>Topic Overview and Actualization</h3><p>Hello and welcome! In today&rsquo;s lesson, we dive into the world of <strong>Decision Trees</strong> in text classification. Decision Trees are simple yet powerful supervised learning algorithms used for classification and regression problems. In this lesson, our focus will be on understanding the Decision Tree algorithm and implementing it for a text classification problem. Let&rsquo;s get started!</p><h3 id=understanding-decision-trees-for-classification>Understanding Decision Trees for Classification</h3><p><strong>Decision Trees</strong> are a type of flowchart-like structure in which each internal node represents a feature, each branch represents a decision rule, and each leaf node represents an outcome or a class label. The topmost node in a Decision Tree is known as the root node, which best splits the dataset.</p><p>Splitting is a process of dividing a node into two or more sub-nodes, and a Decision Tree uses certain metrics during this training phase to find the best split. These include <strong>Entropy</strong>, <strong>Gini Index</strong>, and <strong>Information Gain</strong>.</p><p>The advantage of Decision Trees is that they require relatively little effort for data preparation yet can handle both categorical and numeric data. They are visually intuitive and easy to interpret.</p><p>Let&rsquo;s see how this interprets to our spam detection problem.</p><h5 id=loading-and-preprocessing-the-data>Loading and Preprocessing the Data</h5><p>Before we dive into implementing Decision Trees, let&rsquo;s quickly load and preprocess our text dataset. This step will transform our dataset into a format that can be input into our machine learning models. This code block is being included for completeness:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import the necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>metrics</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>tree</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the dataset</span>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_dataset</span><span class=p>(</span><span class=s1>&#39;codesignal/sms-spam-collection&#39;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>spam_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define X (input features) and Y (output labels)</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>Y</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform the train test split using stratified cross-validation</span>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>,</span> <span class=n>Y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=n>count_vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit and transform the training data </span>
</span></span><span class=line><span class=cl><span class=n>X_train_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Transform the test data</span>
</span></span><span class=line><span class=cl><span class=n>X_test_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>With our data now prepared, let&rsquo;s move on to implementing Decision Trees using the Scikit-learn library.</p><h5 id=implementing-decision-trees-for-text-classification>Implementing Decision Trees for Text Classification</h5><p>In this section, we create our Decision Trees model using the Scikit-learn library:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the DecisionTreeClassifier model</span>
</span></span><span class=line><span class=cl><span class=n>decision_tree_model</span> <span class=o>=</span> <span class=n>tree</span><span class=o>.</span><span class=n>DecisionTreeClassifier</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit the model on the training data</span>
</span></span><span class=line><span class=cl><span class=n>decision_tree_model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_count</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Here, we initialize the model using the <code>DecisionTreeClassifier()</code> class and then fit it to our training data with the <code>fit()</code> method.</p><h5 id=prediction-and-model-evaluation>Prediction and Model Evaluation</h5><p>After our model has been trained, it&rsquo;s time to make predictions on the test data and evaluate the model&rsquo;s performance:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Make predictions on the test data</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>decision_tree_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_count</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Lastly, we calculate the accuracy score, which is the ratio of the number of correct predictions to the total number of predictions. The closer this number is to 1, the better our model:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the accuracy of the model</span>
</span></span><span class=line><span class=cl><span class=n>accuracy</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>accuracy_score</span><span class=p>(</span><span class=n>Y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the accuracy</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Accuracy of Decision Tree Classifier: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Accuracy</span> <span class=n>of</span> <span class=n>Decision</span> <span class=n>Tree</span> <span class=n>Classifier</span><span class=p>:</span> <span class=mf>0.97</span>
</span></span></code></pre></td></tr></table></div></div><p>This high accuracy score indicates that our Decision Tree model is performing exceptionally well in classifying messages as spam or not spam.</p><h5 id=lesson-summary-and-practice-1>Lesson Summary and Practice</h5><p>Great job! You&rsquo;ve learned the theory of Decision Trees, successfully applied it to a text classification problem, and evaluated the performance of your model. Understanding and mastering Decision Trees is an essential step in your journey to becoming skilled in <strong>Natural Language Processing and Machine Learning</strong>.
To reinforce what we&rsquo;ve learned, the next step is to tackle some exercises that will give you hands-on experience with Decision Trees. This practical experience will reinforce your learning and deepen your understanding.</p><p>Looking forward to delving even deeper into natural language processing? Let&rsquo;s proceed to our next lesson: <strong>Random Forest for Text Classification</strong>. Happy Learning!</p><h2 id=practice1-3>「Practice1」</h2><p>Great work! Now, let&rsquo;s adjust the <code>max_depth</code> of our Decision Tree model and observe any potential changes in accuracy. Change the value of the <code>max_depth</code> parameter in <code>DecisionTreeClassifier</code> from <code>5</code> to <code>10</code>. After adjusting your code, run it and compare the accuracy score to that of the original model. Good luck, Stellar Navigator!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>tree</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>metrics</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_dataset</span><span class=p>(</span><span class=s1>&#39;codesignal/sms-spam-collection&#39;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>spam_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define X (input features) and Y (output labels)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Y</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform the train test split using stratified cross-validation</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>,</span> <span class=n>Y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>count_vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit and transform the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Transform the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_test_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the DecisionTreeClassifier model with a max_depth parameter</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>decision_tree_model_v2</span> <span class=o>=</span> <span class=n>tree</span><span class=o>.</span><span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit the model on the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>decision_tree_model_v2</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_count</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Make predictions on the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>y_pred_v2</span> <span class=o>=</span> <span class=n>decision_tree_model_v2</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the accuracy of the model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>accuracy_v2</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>accuracy_score</span><span class=p>(</span><span class=n>Y_test</span><span class=p>,</span> <span class=n>y_pred_v2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the accuracy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Accuracy of Decision Tree Classifier with max_depth=5: </span><span class=si>{</span><span class=n>accuracy_v2</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Certainly! I&rsquo;ll adjust the <code>max_depth</code> parameter of the DecisionTreeClassifier from 5 to 10 and run the code to compare the accuracy scores. Here&rsquo;s the modified code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import necessary libraries</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>tree</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>metrics</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_dataset</span><span class=p>(</span><span class=s1>&#39;codesignal/sms-spam-collection&#39;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>spam_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define X (input features) and Y (output labels)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Y</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform the train test split using stratified cross-validation</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>,</span> <span class=n>Y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the CountVectorizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>count_vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit and transform the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_train_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Transform the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X_test_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the DecisionTreeClassifier model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>decision_tree_model</span> <span class=o>=</span> <span class=n>____</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit the model on the training data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>____</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>____</span><span class=p>,</span> <span class=n>____</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Make predictions on the test data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>decision_tree_model</span><span class=o>.</span><span class=n>___</span><span class=p>(</span><span class=n>____</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the accuracy of the model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>accuracy</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>accuracy_score</span><span class=p>(</span><span class=n>Y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the accuracy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Accuracy of Decision Tree Classifier: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Now, let&rsquo;s run this code and compare the accuracy to the original model with <code>max_depth=5</code>. After running the code, we should see the accuracy score for the Decision Tree Classifier with <code>max_depth=10</code>. Let&rsquo;s compare this to the previous accuracy score: 1. Original model (max_depth=5): 0.96 (from the previous output) 2. New model (max_depth=10): [The new accuracy score will be displayed here] By increasing the <code>max_depth</code> from 5 to 10, we&rsquo;ve allowed the decision tree to create more complex decision boundaries. This can potentially lead to better accuracy on the training data, but it may also increase the risk of overfitting. If the new accuracy is higher, it suggests that the model benefited from the increased complexity and was able to capture more nuanced patterns in the data. However, if the accuracy is similar or lower, it might indicate that the additional depth didn&rsquo;t provide significant improvements or possibly led to overfitting. To further analyze the impact of changing the <code>max_depth</code>, you could consider: 1. Comparing the training accuracy to the test accuracy to check for overfitting. 2. Trying different <code>max_depth</code> values to find the optimal depth for this dataset. 3. Implementing cross-validation to get a more robust estimate of the model&rsquo;s performance. Remember, the goal is to find the right balance between model complexity and generalization ability. The optimal <code>max_depth</code> will depend on the specific characteristics of your dataset. Execution Error: ModuleNotFoundError Traceback (most recent call last) Cell In[3], line 6 4 from sklearn.feature_extraction.text import CountVectorizer 5 from sklearn.model_selection import train_test_split &mdash;-> 6 import datasets 7 import pandas as pd 9 # Load the dataset ModuleNotFoundError: No module named &lsquo;datasets&rsquo;</p><p>哦,我明白了。让我们试着用更简单的方式来解释这个情况: 想象你有一个很酷的玩具机器人。这个机器人可以学习做不同的事情,比如分辨苹果和橘子。 有时候,我们想让机器人变得更聪明。所以我们给它一个新的"大脑"。这个新"大脑"可以让机器人思考得更多。 但是,有趣的是,让机器人思考更多并不总是让它变得更聪明。有时候,它可能会变得有点糊涂,因为它想得太多了! 就像你玩游戏一样,有时候简单的规则反而更容易赢。机器人也是这样,有时候简单一点反而能做得更好。 所以,我们总是要试试看,到底是让机器人思考多一点好,还是思考少一点好。这就是大人们在做的事情 - 他们在帮助机器人找到最好的"思考方式",让它变得既聪明又不会糊涂。 你觉得怎么样?这样解释是不是更容易理解了呢?</p><h1 id=lesson-4>lesson</h1><h5 id=introduction-to-the-random-forest-for-text-classification-lesson>Introduction to the Random Forest for Text Classification Lesson</h5><p>Welcome to the lesson on <strong>Random Forest for Text Classification</strong>. As we continue our journey into the world of text classification techniques in Natural Language Processing (NLP), this lesson brings us to the powerful ensemble learning method - the Random Forest algorithm.</p><p>In this lesson, we will:</p><ul><li>Broaden our understanding of the Random Forest algorithm.</li><li>Apply it using Python&rsquo;s scikit-learn package, on the SMS Spam Collection dataset.</li><li>Evaluate our model&rsquo;s accuracy in classifying whether a text message is spam or not.</li></ul><p>By the end of this lesson, you will have gained hands-on experience in implementing a Random Forest classifier, equipping you with another versatile tool in your NLP modeling toolkit.</p><p>Let the learning begin!</p><h5 id=introduction-to-the-random-forest-for-text-classification-lesson-1>Introduction to the Random Forest for Text Classification Lesson</h5><p>Welcome to the lesson on <strong>Random Forest for Text Classification</strong>. As we continue our journey into the world of text classification techniques in Natural Language Processing (NLP), this lesson brings us to the powerful ensemble learning method - the Random Forest algorithm.</p><p>In this lesson, we will:</p><ul><li>Broaden our understanding of the Random Forest algorithm.</li><li>Apply it using Python&rsquo;s scikit-learn package, on the SMS Spam Collection dataset.</li><li>Evaluate our model&rsquo;s accuracy in classifying whether a text message is spam or not.</li></ul><p>By the end of this lesson, you will have gained hands-on experience in implementing a Random Forest classifier, equipping you with another versatile tool in your NLP modeling toolkit.</p><p>Let the learning begin!</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Import the necessary libraries</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.feature_extraction.text</span> <span class=kn>import</span> <span class=n>CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn</span> <span class=kn>import</span> <span class=n>metrics</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.ensemble</span> <span class=kn>import</span> <span class=n>RandomForestClassifier</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Load the dataset</span>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_dataset</span><span class=p>(</span><span class=s1>&#39;codesignal/sms-spam-collection&#39;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>spam_dataset</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>spam_dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define X (input features) and Y (output labels)</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>Y</span> <span class=o>=</span> <span class=n>spam_dataset</span><span class=p>[</span><span class=s2>&#34;label&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Perform the train test split using stratified cross-validation</span>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>,</span> <span class=n>Y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>Y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the CountVectorizer</span>
</span></span><span class=line><span class=cl><span class=n>count_vectorizer</span> <span class=o>=</span> <span class=n>CountVectorizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit and transform the training data </span>
</span></span><span class=line><span class=cl><span class=n>X_train_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Transform the test data</span>
</span></span><span class=line><span class=cl><span class=n>X_test_count</span> <span class=o>=</span> <span class=n>count_vectorizer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Remember, the <code>CountVectorizer</code> transforms the text data into vectors of token occurrence counts (also known as bag of words), which is required for processing by machine learning models. We also use a stratified train-test split to ensure a balanced representation of different classes within both our training and test data.</p><h5 id=random-forest-classification-overview>Random Forest Classification: Overview</h5><p><strong>Random Forest</strong> is a type of ensemble learning method, where a group of weak models work together to form a stronger predictive model. A Random Forest operates by constructing numerous decision trees during training time and outputting the class that is the mode of the classes (classification) of the individual trees.</p><p>Random Forest has several advantages over a single decision tree. Most significant among these is that by building and averaging multiple deep decision trees trained on different parts of the same training data, the Random Forest algorithm reduces the problem of overfitting.</p><p>Random Forests also handle imbalanced data well, making them a good option for our text classification task.</p><h5 id=implementing-random-forest-classifier-with-scikit-learn>Implementing Random Forest Classifier with Scikit-learn</h5><p>Now that we have a basic understanding of the Random Forest algorithm, let&rsquo;s train our model.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize the RandomForestClassifier model</span>
</span></span><span class=line><span class=cl><span class=n>random_forest_model</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>n_estimators</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fit the model on the training data</span>
</span></span><span class=line><span class=cl><span class=n>random_forest_model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_count</span><span class=p>,</span> <span class=n>Y_train</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Here, the parameter <code>n_estimators</code> defines the number of trees in the forest of the model while <code>random_state</code> sets a seed to the random generator, ensuring that the split you generate is replicable. The random forest model inherently handles multi-class tasks, hence we don&rsquo;t have to use the &lsquo;one-vs-all&rsquo; method to extend it to multi-class.
这里，参数 n_estimators 定义了模型森林中树的数量，而 random_state 为随机生成器设置了一个种子，确保生成的划分是可复制的。随机森林模型本身就能处理多分类任务，因此我们不必使用“一对多”方法将其扩展到多分类。</p><h5 id=evaluating-the-model模型评估>Evaluating the Model 模型评估</h5><p>Once our model is trained, we can use it to make predictions on our test data. By comparing these predictions against the actual labels in the test set, we can evaluate how well our model is performing. One of the most straightforward metrics we can use to achieve this is accuracy, calculated as the proportion of true results among the total number of cases examined.<br>模型训练完成后，我们可以用它对测试数据进行预测。通过将这些预测结果与测试集中实际标签进行比较，我们可以评估模型的性能。准确率是最直观的评估指标之一，它指的是在所有样本中预测正确的比例。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Make predictions on the test data</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>random_forest_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_count</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the accuracy of the model</span>
</span></span><span class=line><span class=cl><span class=n>accuracy</span> <span class=o>=</span> <span class=n>metrics</span><span class=o>.</span><span class=n>accuracy_score</span><span class=p>(</span><span class=n>Y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the accuracy</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Accuracy of Random Forest Classifier: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The output of the above code will be:<br>以上代码的输出结果为：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Accuracy</span> <span class=n>of</span> <span class=n>Random</span> <span class=n>Forest</span> <span class=n>Classifier</span><span class=p>:</span> <span class=mf>0.97</span>
</span></span></code></pre></td></tr></table></div></div><p>This indicates that our Random Forest model was able to accurately classify 97% of the messages in the test set as spam or ham, showcasing a high level of performance.<br>这表明我们的随机森林模型能够准确地将测试集中 97% 的消息分类为垃圾邮件或非垃圾邮件，展现出很高的性能水平。</p><h5 id=lesson-summary-and-next-steps-1>Lesson Summary and Next Steps</h5><p>课程总结和后续步骤</p><p>We successfully explored the Random Forest algorithm, learned how it works, and implemented it in Python to classify messages as spam or ham. Remember, choosing and training a model is just part of the machine learning pipeline. Evaluating your model&rsquo;s performance, and selecting the best one, is also integral to any successful <strong>Machine Learning project</strong>.<br>我们成功探索了随机森林算法，学习了它的工作原理，并在 Python 中实现了它，以将消息分类为垃圾邮件或非垃圾邮件。请记住，选择和训练模型只是机器学习流程的一部分。评估模型的性能并选择最佳模型也是任何成功的机器学习项目的组成部分。
In our upcoming exercises, you will get the opportunity to apply the concepts you&rsquo;ve learned and further familiarize yourself with the Random Forest algorithm. These tasks will help you solidify your understanding and ensure you are able to apply these techniques to your future data science projects. Happy learning!<br>在接下来的练习中，您将有机会运用所学概念，并进一步熟悉随机森林算法。这些任务将帮助您巩固理解，确保您能够将这些技术应用到未来的数据科学项目中。祝学习愉快！</p></div></article></main><footer class="u-container u-py-xl u-text-center"><div class=u-mb-md><span class=u-text-2xl>🌱</span></div><p class=u-text-light>© 2025 Mengxi's Blog. Cultivated with intention.</p></footer><script src=/%20js/copy-code.js></script><script src=/%20js/hn-interactions.js></script><script src=/%20js/ux-booster.js></script></body></html>