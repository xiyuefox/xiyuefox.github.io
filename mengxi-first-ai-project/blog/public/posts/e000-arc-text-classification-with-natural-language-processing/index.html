<!DOCTYPE html>
<html lang="zh-cn">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>e000ï¼ˆä»Arcæ‰“å¼€ï¼‰-Text Classification with Natural Language Processing | Mengxi&#39;s Blog</title>


<link href="https://fonts.googleapis.com" rel="preconnect" />
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
<link
    href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;600;700&family=Noto+Sans+SC:wght@300;400;500;600;700&display=swap"
    rel="stylesheet" />


<link rel="stylesheet" href="/css/unified-styles.css">
</head>

<body class="theme-knowledge">
    <nav class="u-nav">
    <div class="u-container u-nav__container">
        <a href="http://localhost:1313/" class="u-nav__brand">
            <span class="u-nav__logo-emoji">ğŸŒ¿</span> Mengxi&#39;s Blog
        </a>
        <ul class="u-nav__links">
            
            <li><a href="/" class="u-nav__link ">Home</a></li>
            
            <li><a href="/posts" class="u-nav__link ">Posts</a></li>
            
            <li><a href="/search" class="u-nav__link ">Search</a></li>
            
            <li><a href="/timeline/" class="u-nav__link ">Timeline</a></li>
            
            <li><a href="/guide/" class="u-nav__link ">Guide</a></li>
            
            <li><a href="/upload/" class="u-nav__link ">Upload</a></li>
            
        </ul>
    </div>
</nav>

    <main class="u-container u-py-xl">
        
<header class="u-text-center u-mb-xl">
    <h1>e000ï¼ˆä»Arcæ‰“å¼€ï¼‰-Text Classification with Natural Language Processing</h1>
    <div class="u-flex u-justify-center u-gap-md u-text-light">
        <span>Dec 14, 2025</span>
        <span>â€¢</span>
        <span>108 min read</span>
    </div>
</header>

<article class="u-card" style="max-width: 800px; margin: 0 auto;">
    <div class="content">
        <h2 id="introduction-and-text-data-collection">Introduction and Text Data Collection</h2>
<p>Welcome to today&rsquo;s lesson! As data science and machine learning professionals, particularly in the Natural Language Processing (NLP) field, we often deal with textual data. Today, we dive into the &lsquo;Introduction to Textual Data Collection&rsquo;. Specifically, we&rsquo;ll explore how to collect, understand and analyze text data usingÂ <code>Python</code>.</p>
<p>Textual data is usually unstructured, being much harder to analyze than structured data. It can take many forms, such as emails, social media posts, books, or transcripts of conversations. Understanding how to handle such data is a critical part of building effective machine learning models, especially for text classification tasks where we &lsquo;classify&rsquo; or categorize texts. The quality of the data we use for these tasks is of utmost importance. Better, well-structured data leads to models that perform better.</p>
<h5 id="the-20-newsgroups-dataset">The 20 Newsgroups Dataset</h5>
<p>The dataset we&rsquo;ll be working with in today&rsquo;s lesson is theÂ <strong>20 Newsgroups dataset</strong>. For some historical background, newsgroups were the precursors to modern internet forums, where people gathered to discuss specific topics. In our case, the dataset consists of approximately 20,000 documents from newsgroup discussions. These texts were originally exchanged through Usenet, a global discussion system that predates many modern Internet forums.</p>
<p>The dataset is divided nearly evenly across 20 different newsgroups, each corresponding to a separate topic - this segmentation is one of the main reasons why it is especially useful for text classification tasks. The separation of data makes it excellent for training models to distinguish between different classes, or in our case, newsgroup topics.</p>
<p>From science and religion to politics and sports, the topics covered provide a diversified range of discussions. This diversity adds another layer of complexity and richness, similar to what we might experience with real-world data.</p>
<h5 id="fetching-and-understanding-the-data-structure">Fetching and Understanding the Data Structure</h5>
<p>To load this dataset, we use theÂ <code>fetch_20newsgroups()</code>Â function from theÂ <code>sklearn.datasets</code>Â module in Python. This function retrieves the 20 newsgroup dataset in a format that&rsquo;s useful for machine learning purposes. Let&rsquo;s fetch and examine the dataset.</p>
<p>First, let&rsquo;s import the necessary libraries and fetch the data:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">`</span><span style="color:#ae81ff">1</span><span style="color:#75715e"># Importing necessary libraries 2from sklearn.datasets import fetch_20newsgroups 3 4# Fetch data 5newsgroups = fetch_20newsgroups(subset=&#39;all&#39;)`</span>
</span></span></code></pre></div><p>The datasets fetched from sklearn typically have three attributesâ€”<code>data</code>,Â <code>target</code>, andÂ <code>target_names</code>.Â <code>data</code>Â refers to the actual content,Â <code>target</code>Â refers to the labels for the texts, andÂ <code>target_names</code>Â provides names for the target labels.</p>
<p>Next, let&rsquo;s understand the structure of the fetched data:</p>
<p>Python</p>
<p>CopyPlay</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">`</span><span style="color:#ae81ff">1</span><span style="color:#75715e"># Understanding the structure of the data 2print(&#34;\n\nData Structure\n-------------&#34;) 3print(f&#39;Type of data: {type(newsgroups.data)}&#39;) 4print(f&#39;Type of target: {type(newsgroups.target)}&#39;)`</span>
</span></span></code></pre></div><p>We are fetching the data and observing the type of theÂ <code>data</code>Â andÂ <code>target</code>. TheÂ <code>type of data</code>Â tells us what kind of data structure is used to store the text data while theÂ <code>type of target</code>Â shouts what type of structure is used to store the labels. Here is what the output looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">`</span><span style="color:#ae81ff">1</span>Data Structure <span style="color:#ae81ff">2</span><span style="color:#f92672">-------------</span> <span style="color:#ae81ff">3</span>Type of data: <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">list</span><span style="color:#e6db74">&#39;&gt; 4Type of target: &lt;class &#39;</span>numpy<span style="color:#f92672">.</span>ndarray<span style="color:#e6db74">&#39;&gt;`</span>
</span></span></code></pre></div><p>As printed out, theÂ <code>data</code>Â is stored as a list, andÂ <code>target</code>Â as a numpy array.</p>
<h5 id="diving-into-data-exploration">Diving Into Data Exploration</h5>
<p>Now, let&rsquo;s explore the data points, target variables and the potential classes in the dataset:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">`</span><span style="color:#ae81ff">1</span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Data Exploration</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">----------------&#34;</span>) <span style="color:#ae81ff">2</span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Number of datapoints: </span><span style="color:#e6db74">{</span>len(newsgroups<span style="color:#f92672">.</span>data)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>) <span style="color:#ae81ff">3</span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Number of target variables: </span><span style="color:#e6db74">{</span>len(newsgroups<span style="color:#f92672">.</span>target)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>) <span style="color:#ae81ff">4</span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Possible classes: </span><span style="color:#e6db74">{</span>newsgroups<span style="color:#f92672">.</span>target_names<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)<span style="color:#960050;background-color:#1e0010">`</span>
</span></span></code></pre></div><p>We get the length of theÂ <code>data</code>Â list to fetch the number of data points. Also, we get the length of theÂ <code>target</code>Â array. Lastly, we fetch the possible classes or newsgroups in the dataset. Here is what we get:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">`</span><span style="color:#ae81ff">1</span>Data Exploration <span style="color:#ae81ff">2</span><span style="color:#f92672">----------------</span> <span style="color:#ae81ff">3</span>Number of datapoints: <span style="color:#ae81ff">18846</span> <span style="color:#ae81ff">4</span>Number of target variables: <span style="color:#ae81ff">18846</span> <span style="color:#ae81ff">5</span>Possible classes: [<span style="color:#e6db74">&#39;alt.atheism&#39;</span>, <span style="color:#e6db74">&#39;comp.graphics&#39;</span>, <span style="color:#e6db74">&#39;comp.os.ms-windows.misc&#39;</span>, <span style="color:#e6db74">&#39;comp.sys.ibm.pc.hardware&#39;</span>, <span style="color:#e6db74">&#39;comp.sys.mac.hardware&#39;</span>, <span style="color:#e6db74">&#39;comp.windows.x&#39;</span>, <span style="color:#e6db74">&#39;misc.forsale&#39;</span>, <span style="color:#e6db74">&#39;rec.autos&#39;</span>, <span style="color:#e6db74">&#39;rec.motorcycles&#39;</span>, <span style="color:#e6db74">&#39;rec.sport.baseball&#39;</span>, <span style="color:#e6db74">&#39;rec.sport.hockey&#39;</span>, <span style="color:#e6db74">&#39;sci.crypt&#39;</span>, <span style="color:#e6db74">&#39;sci.electronics&#39;</span>, <span style="color:#e6db74">&#39;sci.med&#39;</span>, <span style="color:#e6db74">&#39;sci.space&#39;</span>, <span style="color:#e6db74">&#39;soc.religion.christian&#39;</span>, <span style="color:#e6db74">&#39;talk.politics.guns&#39;</span>, <span style="color:#e6db74">&#39;talk.politics.mideast&#39;</span>, <span style="color:#e6db74">&#39;talk.politics.misc&#39;</span>, <span style="color:#e6db74">&#39;talk.religion.misc&#39;</span>]<span style="color:#960050;background-color:#1e0010">`</span>
</span></span></code></pre></div><h5 id="sample-data-preview">Sample Data Preview</h5>
<p>Lastly, let&rsquo;s fetch and understand what a sample data point and its corresponding label looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">`</span><span style="color:#ae81ff">1</span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Sample datapoint</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">----------------&#34;</span>) <span style="color:#ae81ff">2</span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Article:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">-------</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>newsgroups<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">10</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>) <span style="color:#ae81ff">3</span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Corresponding Topic:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">------------------</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>newsgroups<span style="color:#f92672">.</span>target_names[newsgroups<span style="color:#f92672">.</span>target[<span style="color:#ae81ff">10</span>]]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)<span style="color:#960050;background-color:#1e0010">`</span>
</span></span></code></pre></div><p>TheÂ <code>Article</code>Â fetched is the 10th article in the dataset andÂ <code>Corresponding Topic</code>Â is the actual topic that the article belongs to. Here&rsquo;s the output:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">`</span><span style="color:#ae81ff">1</span>Sample datapoint <span style="color:#ae81ff">2</span><span style="color:#f92672">----------------</span> <span style="color:#ae81ff">3</span> <span style="color:#ae81ff">4</span>Article: <span style="color:#ae81ff">5</span><span style="color:#f92672">-------</span> <span style="color:#ae81ff">6</span>From: sandvik<span style="color:#a6e22e">@newton.apple.com</span> (Kent Sandvik) <span style="color:#ae81ff">7</span>Subject: Re: <span style="color:#ae81ff">14</span> Apr <span style="color:#ae81ff">93</span>   God<span style="color:#e6db74">&#39;s Promise in 1 John 1: 7 8Organization: Cookamunga Tourist Bureau 9Lines: 17 10 11In article &lt;1qknu0INNbhv@shelley.u.washington.edu&gt;, &gt; Christian:  washed in 12the blood of the lamb. 13&gt; Mithraist:  washed in the blood of the bull. 14&gt;  15&gt; If anyone in .netland is in the process of devising a new religion, 16&gt; do not use the lamb or the bull, because they have already been 17&gt; reserved.  Please choose another animal, preferably one not 18&gt; on the Endangered Species List.   19 20This will be a hard task, because most cultures used most animals 21for blood sacrifices. It has to be something related to our current 22post-modernism state. Hmm, what about used computers? 23 24Cheers, 25Kent 26--- 27sandvik@newton.apple.com. ALink: KSAND -- Private activities on the net. 28 29 30Corresponding Topic: 31------------------ 32talk.religion.misc`</span>
</span></span></code></pre></div><h5 id="lesson-summary">Lesson Summary</h5>
<p>Nice work! Through today&rsquo;s lesson, you&rsquo;ve learned to fetch and analyze text data for text classification. If you&rsquo;ve followed along, you should now understand the structure of text data and how to fetch and analyze it using Python.</p>
<p>But our journey to text classification is just starting. In upcoming lessons, we&rsquo;ll dive deeper into related topics such as cleaning textual data, handling missing values, and restructuring textual data for analysis. Each step forward improves your expertise in text classification. Keep going!</p>
<h2 id="practice1explore-more-of-the-20-newsgroups-dataset">ã€ŒPractice1ã€Explore More of the 20 Newsgroups Dataset</h2>
<h2 id="practice2uncover-the-end-of-20-newsgroups-dataset">ã€ŒPractice2ã€Uncover the End of 20 Newsgroups Dataset</h2>
<p>Celestial Traveler, your journey continues! Fill in the blanks (<code>____</code>) to import and explore our dataset. We aim to extract and display theÂ <strong>last three articles</strong>Â and their correspondingÂ <strong>topics</strong>. Can you reveal what&rsquo;s at the end of our dataset?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>newsgroups <span style="color:#f92672">=</span> ____(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch last three articles</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>last_three_articles <span style="color:#f92672">=</span> newsgroups<span style="color:#f92672">.</span>____[<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>:]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the corresponding topics</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>corresponding_topics <span style="color:#f92672">=</span> [newsgroups<span style="color:#f92672">.</span>target_names[i] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> newsgroups<span style="color:#f92672">.</span>____[<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>:]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display Last three articles and their corresponding topics</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Last article </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">:&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>last_three_articles[i]<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Corresponding Topic </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">:&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>corresponding_topics[i]<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><p>&ldquo;Here is the completed code to import and explore the dataset, extracting and displaying the last three articles and their corresponding topics.&rdquo;</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>newsgroups <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch last three articles</span>
</span></span><span style="display:flex;"><span>last_three_articles <span style="color:#f92672">=</span> newsgroups<span style="color:#f92672">.</span>data[<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>:]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the corresponding topics</span>
</span></span><span style="display:flex;"><span>corresponding_topics <span style="color:#f92672">=</span> [newsgroups<span style="color:#f92672">.</span>target_names[i] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> newsgroups<span style="color:#f92672">.</span>target[<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>:]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display last three articles and their corresponding topics</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>):
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Last article </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">:&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>last_three_articles[i]<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Corresponding Topic </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">:&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>corresponding_topics[i]<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><h2 id="practice3fetch-specific-categories-from-dataset">ã€ŒPractice3ã€Fetch Specific Categories from Dataset</h2>
<p>Celestial Traveler, let&rsquo;s narrow down our data collection. Modify the provided code to fetch only theÂ <code>'alt.atheism'</code>Â andÂ <code>'talk.religion.misc'</code>Â categories from ourÂ <strong>dataset</strong>. Then, display the first two articles from these categories along with their corresponding labels.<br>
å¤©ä½“æ—…è¡Œè€…ï¼Œè®©æˆ‘ä»¬ç¼©å°æ•°æ®æ”¶é›†èŒƒå›´ã€‚ä¿®æ”¹æä¾›çš„ä»£ç ï¼Œä½¿å…¶ä»…ä»æˆ‘ä»¬çš„æ•°æ®é›†ä¸­è·å–Â <code>'alt.atheism'</code>Â å’ŒÂ <code>'talk.religion.misc'</code>Â ç±»åˆ«ã€‚ç„¶åï¼Œæ˜¾ç¤ºæ¥è‡ªè¿™äº›ç±»åˆ«çš„å‰ä¸¤ç¯‡æ–‡ç« </p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch a subset of the dataset containing selected categories. Update the categories as needed.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>newsgroups_subset <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>, categories<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;comp.graphics&#39;</span>, <span style="color:#e6db74">&#39;sci.space&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the first two articles and their corresponding topics from this subset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Article </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">:&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>newsgroups_subset<span style="color:#f92672">.</span>data[i]<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Corresponding Topic </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">:&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>newsgroups_subset<span style="color:#f92672">.</span>target_names[newsgroups_subset<span style="color:#f92672">.</span>target[i]]<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><p>&ldquo;Here is the modified code to fetch only the <code>'alt.atheism'</code> and <code>'talk.religion.misc'</code> categories from the dataset, and to display the first two articles along with their corresponding labels.&rdquo;</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch a subset of the dataset containing selected categories</span>
</span></span><span style="display:flex;"><span>newsgroups_subset <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>, categories<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;alt.atheism&#39;</span>, <span style="color:#e6db74">&#39;talk.religion.misc&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the first two articles and their corresponding topics from this subset</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>):
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Article </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">:&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>newsgroups_subset<span style="color:#f92672">.</span>data[i]<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Corresponding Topic </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">:&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>newsgroups_subset<span style="color:#f92672">.</span>target_names[newsgroups_subset<span style="color:#f92672">.</span>target[i]]<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><p>è¾“å‡º</p>
<pre tabindex="0"><code>Article 1:  
From: agr00@ccc.amdahl.com (Anthony G Rose)  
Subject: Re: Who&#39;s next?  Mormons and Jews?  
Reply-To: agr00@JUTS.ccc.amdahl.com (Anthony G Rose)  
Organization: Amdahl Corporation, Sunnyvale CA  
Lines: 18  
  
In article &lt;1993Apr20.142356.456@ra.royalroads.ca&gt; mlee@post.RoyalRoads.ca (Malcolm Lee) writes:  
&gt;  
&gt;In article &lt;C5rLps.Fr5@world.std.com&gt;, jhallen@world.std.com (Joseph H Allen) writes:  
&gt;|&gt; In article &lt;1qvk8sINN9vo@clem.handheld.com&gt; jmd@cube.handheld.com (Jim De Arras) writes:  
&gt;|&gt;   
&gt;|&gt; It was interesting to watch the 700 club today.  Pat Robertson said that the  
&gt;|&gt; &#34;Branch Dividians had met the firey end for worshipping their false god.&#34; He  
&gt;|&gt; also said that this was a terrible tragedy and that the FBI really blew it.  
&gt;  
&gt;I don&#39;t necessarily agree with Pat Robertson.  Every one will be placed before  
&gt;the judgement seat eventually and judged on what we have done or failed to do  
&gt;on this earth.  God allows people to choose who and what they want to worship.  
  
I&#39;m sorry, but He does not!  Ever read the FIRST commandment?  
  
&gt;Worship of money is one of the greatest religions in this country.  
  
You mean, false religion!  
  
  
Corresponding Topic 1:  
talk.religion.misc  
  
  
Article 2:  
From: frank@D012S658.uucp (Frank O&#39;Dwyer)  
Subject: Re: Tieing Abortion to Health Reform -- Is Clinton Nuts?  
Organization: Siemens-Nixdorf AG  
Lines: 21  
NNTP-Posting-Host: d012s658.ap.mchp.sni.de  
  
In article &lt;1993Apr26.163627.11364@csrd.uiuc.edu&gt; g-skinner@uiuc.edu writes:  
#I find myself unable to put these two statements together in a  
#sensible way:  
#  
#&gt;Abortion is done because the mother can not afford the *pregnancy*.  
#  
#[...]  
#  
#&gt;If we refused to pay for the more expensive choice of birth, *then*  
#&gt;your statement would make sense.  But that is not the case, so it doesn&#39;t.  
#  
#Are we paying for the birth or not, Mr. Parker?  If so, why can&#39;t the  
#mother afford the pregnancy?  If not, what is the meaning of the  
#latter objection?  You can&#39;t have it both ways.  
  
Birth != pregnancy.  If they were the same, the topic of abortion would   
hardly arise, would it, Mr. Skinner?  
  
--   
Frank O&#39;Dwyer                                  &#39;I&#39;m not hatching That&#39;  
odwyer@sse.ie                                  from &#34;Hens&#34;,  by Evelyn Conlon  
  
  
Corresponding Topic 2:  
talk.religion.misc
</code></pre><h2 id="practicefetching-the-third-article-from-dataset">ã€ŒPracticeã€Fetching the Third Article from Dataset</h2>
<p>Well done, Stellar Navigator! Next, fill in the missing line in the code below to fetch and display the third article from theÂ <strong>20 Newsgroups dataset</strong>Â with its corresponding topic. Prepare your spacecraft for another adventure in data exploration!<br>
å¹²å¾—å¥½ï¼Œæ˜Ÿé™…å¯¼èˆªå‘˜ï¼æ¥ä¸‹æ¥ï¼Œå¡«å†™ä»¥ä¸‹ä»£ç ä¸­ç¼ºå°‘çš„è¡Œï¼Œä»¥è·å–å¹¶æ˜¾ç¤º 20 Newsgroups æ•°æ®é›†ä¸­ç¬¬ä¸‰ç¯‡æ–‡ç« åŠå…¶å¯¹åº”ä¸»é¢˜ã€‚å‡†å¤‡å¥½ä½ çš„å®‡å®™é£èˆ¹ï¼Œå¼€å§‹å¦ä¸€åœºæ•°æ®æ¢ç´¢å†’é™©ä¹‹æ—…å§ï¼</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>newsgroups <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Fetch the third article and its corresponding topic</span>
</span></span></code></pre></div><p>&ldquo;Here is the completed code to fetch and display the third article from the 20 Newsgroups dataset along with its corresponding topic.&rdquo;</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>newsgroups <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the third article and its corresponding topic</span>
</span></span><span style="display:flex;"><span>third_article <span style="color:#f92672">=</span> newsgroups<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">2</span>]
</span></span><span style="display:flex;"><span>third_topic <span style="color:#f92672">=</span> newsgroups<span style="color:#f92672">.</span>target_names[newsgroups<span style="color:#f92672">.</span>target[<span style="color:#ae81ff">2</span>]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the third article and its corresponding topic</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Article 3:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>third_article<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Corresponding Topic 3: </span><span style="color:#e6db74">{</span>third_topic<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><p>è¾“å‡º</p>
<pre tabindex="0"><code>Article 3:  
From: hilmi-er@dsv.su.se (Hilmi Eren)  
Subject: Re: ARMENIA SAYS IT COULD SHOOT DOWN TURKISH PLANES (Henrik)  
Lines: 95  
Nntp-Posting-Host: viktoria.dsv.su.se  
Reply-To: hilmi-er@dsv.su.se (Hilmi Eren)  
Organization: Dept. of Computer and Systems Sciences, Stockholm University  
  
  
  
  
|&gt;The student of &#34;regional killings&#34; alias Davidian (not the Davidian religios sect) writes:  
  
  
|&gt;Greater Armenia would stretch from Karabakh, to the Black Sea, to the  
|&gt;Mediterranean, so if you use the term &#34;Greater Armenia&#34; use it with care.  
  
  
	Finally you said what you dream about. Mediterranean???? That was new....  
	The area will be &#34;greater&#34; after some years, like your &#34;holocaust&#34; numbers......  
  
  
  
  
|&gt;It has always been up to the Azeris to end their announced winning of Karabakh   
|&gt;by removing the Armenians! When the president of Azerbaijan, Elchibey, came to   
|&gt;power last year, he announced he would be be &#34;swimming in Lake Sevan [in   
|&gt;Armeniaxn] by July&#34;.  
		*****  
	Is&#39;t July in USA now????? Here in Sweden it&#39;s April and still cold.  
	Or have you changed your calendar???  
  
  
|&gt;Well, he was wrong! If Elchibey is going to shell the   
|&gt;Armenians of Karabakh from Aghdam, his people will pay the price! If Elchibey   
						    ****************  
|&gt;is going to shell Karabakh from Fizuli his people will pay the price! If   
						    ******************  
|&gt;Elchibey thinks he can get away with bombing Armenia from the hills of   
|&gt;Kelbajar, his people will pay the price.   
			    ***************  
  
  
	NOTHING OF THE MENTIONED IS TRUE, BUT LET SAY IT&#39;s TRUE.  
	  
	SHALL THE AZERI WOMEN AND CHILDREN GOING TO PAY THE PRICE WITH  
						    **************  
	BEING RAPED, KILLED AND TORTURED BY THE ARMENIANS??????????  
	  
	HAVE YOU HEARDED SOMETHING CALLED: &#34;GENEVA CONVENTION&#34;???????  
	YOU FACIST!!!!!  
  
  
  
	Ohhh i forgot, this is how Armenians fight, nobody has forgot  
	you killings, rapings and torture against the Kurds and Turks once  
	upon a time!
</code></pre><h2 id="practiceexploring-text-length-in-newsgroups-dataset">ã€ŒPracticeã€Exploring Text Length in Newsgroups Dataset</h2>
<p>Great job, Space Voyager! Now, as a final task, write a Python script that calculates and displays the lengths of the first five articles (in terms of the number of characters) from theÂ <em>20 Newsgroups</em>Â dataset.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries and modules</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Fetch the 20 Newsgroups dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Iterate over the first five articles,</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Calculate their length in terms of the number of characters and display it</span>
</span></span></code></pre></div><p>&ldquo;Here is the completed Python script to calculate and display the lengths of the first five articles in terms of the number of characters from the 20 Newsgroups dataset.&rdquo;</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries and modules</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the 20 Newsgroups dataset</span>
</span></span><span style="display:flex;"><span>newsgroups <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Iterate over the first five articles</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">5</span>):
</span></span><span style="display:flex;"><span>    article_length <span style="color:#f92672">=</span> len(newsgroups<span style="color:#f92672">.</span>data[i])
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Length of Article </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{</span>article_length<span style="color:#e6db74">}</span><span style="color:#e6db74"> characters&#39;</span>)
</span></span></code></pre></div><h2 id="lesson2mastering-text-cleaning-for-nlp-techniques-and-applications">LessonÂ 2ï¼šMastering Text Cleaning for NLP: Techniques and Applications</h2>
<h3 id="introductionå¼•è¨€">IntroductionÂ å¼•è¨€</h3>
<p>Welcome to today&rsquo;s lesson onÂ <strong>Text Cleaning Techniques</strong>! In any Natural Language Processing (NLP) project, the quality of your results depends heavily on the quality of your input. Hence, cleaning our textual data becomes critical for the accuracy of our project. Our main objective for today is to delve into how to clean textual data using Python. By the end of this session, you will be comfortable with creating and applying a simple text cleaning pipeline in Python.<br>
æ¬¢è¿æ¥åˆ°ä»Šå¤©å…³äºæ–‡æœ¬æ¸…ç†æŠ€æœ¯çš„è¯¾ç¨‹ï¼åœ¨ä»»ä½•è‡ªç„¶è¯­è¨€å¤„ç† (NLP) é¡¹ç›®ä¸­ï¼Œç»“æœçš„è´¨é‡åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºè¾“å…¥çš„è´¨é‡ã€‚å› æ­¤ï¼Œæ¸…ç†æ–‡æœ¬æ•°æ®å¯¹äºé¡¹ç›®çš„å‡†ç¡®æ€§è‡³å…³é‡è¦ã€‚æˆ‘ä»¬ä»Šå¤©çš„ä¸»è¦ç›®æ ‡æ˜¯æ·±å…¥ç ”ç©¶å¦‚ä½•ä½¿ç”¨ Python æ¸…ç†æ–‡æœ¬æ•°æ®ã€‚åœ¨æœ¬è¯¾ç¨‹ç»“æŸæ—¶ï¼Œæ‚¨å°†èƒ½å¤Ÿè½»æ¾åœ°ä½¿ç”¨ Python åˆ›å»ºå’Œåº”ç”¨ç®€å•çš„æ–‡æœ¬æ¸…ç†ç®¡é“ã€‚</p>
<h5 id="understanding-text-cleaning">Understanding Text Cleaning</h5>
<p>ç†è§£æ–‡æœ¬æ¸…æ´—</p>
<p><strong>Text cleaning</strong>Â is essential in NLP, involving the preparation of text data for analysis. Why is it necessary? Imagine trying to perform text classification on social media posts; people often use colloquial language, abbreviations, and emojis. In many cases, posts might also be in different languages. These variations make it challenging for machines to understand context without undergoing preprocessing.<br>
æ–‡æœ¬æ¸…æ´—åœ¨è‡ªç„¶è¯­è¨€å¤„ç† (NLP) ä¸­è‡³å…³é‡è¦ï¼Œæ¶‰åŠä¸ºåˆ†æå‡†å¤‡æ–‡æœ¬æ•°æ®ã€‚ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿæƒ³è±¡ä¸€ä¸‹å°è¯•å¯¹ç¤¾äº¤åª’ä½“å¸–å­è¿›è¡Œæ–‡æœ¬åˆ†ç±»ï¼›äººä»¬ç»å¸¸ä½¿ç”¨å£è¯­ã€ç¼©å†™å’Œè¡¨æƒ…ç¬¦å·ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œå¸–å­ä¹Ÿå¯èƒ½ä½¿ç”¨ä¸åŒçš„è¯­è¨€ã€‚è¿™äº›å·®å¼‚ä½¿å¾—æœºå™¨åœ¨æœªç»é¢„å¤„ç†çš„æƒ…å†µä¸‹éš¾ä»¥ç†è§£ä¸Šä¸‹æ–‡ã€‚</p>
<p>We get rid of superfluous variations and distractions to make the text understandable for algorithms, thereby increasing accuracy. These distractions could range from punctuation, special symbols, numbers, to even common words that do not carry significant meaning (commonly referred to as &ldquo;stop words&rdquo;).<br>
æˆ‘ä»¬å»é™¤å¤šä½™çš„å˜åŒ–å’Œå¹²æ‰°å› ç´ ï¼Œä½¿æ–‡æœ¬æ˜“äºç®—æ³•ç†è§£ï¼Œä»è€Œæé«˜å‡†ç¡®æ€§ã€‚è¿™äº›å¹²æ‰°å› ç´ åŒ…æ‹¬æ ‡ç‚¹ç¬¦å·ã€ç‰¹æ®Šç¬¦å·ã€æ•°å­—ï¼Œç”šè‡³æ˜¯ä¸å…·æœ‰é‡è¦æ„ä¹‰çš„å¸¸è§è¯ï¼ˆé€šå¸¸ç§°ä¸ºâ€œåœç”¨è¯â€ï¼‰ã€‚</p>
<p>Python&rsquo;sÂ <strong>Regex</strong>Â (Regular Expression) library,Â <code>re</code>, is an ideal tool for such text cleaning tasks, as it is specifically designed to work with string patterns. Within this library, we will be usingÂ <code>re.sub</code>, a method employed to replace parts of a string. This method operates by accepting three arguments:Â <code>re.sub(pattern, repl, string)</code>. Here,Â <code>pattern</code>Â is the character pattern we&rsquo;re looking to replace,Â <code>repl</code>Â is the replacement string, andÂ <code>string</code>Â is the text being processed. In essence, any part of theÂ <code>string</code>Â argument that matches theÂ <code>pattern</code>Â argument gets replaced by theÂ <code>repl</code>Â argument.<br>
Python çš„æ­£åˆ™è¡¨è¾¾å¼ (Regex) åº“ <code>Â </code>re<code>Â </code> æ˜¯æ­¤ç±»æ–‡æœ¬æ¸…ç†ä»»åŠ¡çš„ç†æƒ³å·¥å…·ï¼Œå› ä¸ºå®ƒä¸“é—¨ç”¨äºå¤„ç†å­—ç¬¦ä¸²æ¨¡å¼ã€‚åœ¨è¿™ä¸ªåº“ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ <code>Â </code>re.sub<code>Â </code> æ–¹æ³•æ¥æ›¿æ¢å­—ç¬¦ä¸²çš„æŸäº›éƒ¨åˆ†ã€‚æ­¤æ–¹æ³•æ¥å—ä¸‰ä¸ªå‚æ•°ï¼š<code>Â </code>re.sub(pattern, repl, string)<code>Â </code>ã€‚å…¶ä¸­ï¼Œ<code>Â </code>pattern<code>Â </code> æ˜¯æˆ‘ä»¬è¦æ›¿æ¢çš„å­—ç¬¦æ¨¡å¼ï¼Œ<code>Â </code>repl<code>Â </code> æ˜¯æ›¿æ¢å­—ç¬¦ä¸²ï¼Œ<code>Â </code>string<code>Â </code> æ˜¯æ­£åœ¨å¤„ç†çš„æ–‡æœ¬ã€‚æœ¬è´¨ä¸Šï¼Œ<code>Â </code>string<code>Â </code> å‚æ•°ä¸­ä¸ <code>Â </code>pattern<code>Â </code> å‚æ•°åŒ¹é…çš„ä»»ä½•éƒ¨åˆ†éƒ½å°†è¢« <code>Â </code>repl<code>Â </code> å‚æ•°æ›¿æ¢ã€‚</p>
<p>As we proceed, a clearer understanding of the functionality and application ofÂ <code>re.sub</code>Â will be provided. Now, let&rsquo;s delve into it!<br>
éšç€æˆ‘ä»¬çš„æ·±å…¥ï¼Œæˆ‘ä»¬å°†å¯¹Â <code>re.sub</code>Â çš„åŠŸèƒ½å’Œåº”ç”¨æœ‰æ›´æ¸…æ™°çš„äº†è§£ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼</p>
<h3 id="text-cleaning-processæ–‡æœ¬æ¸…ç†æµç¨‹">Text Cleaning ProcessÂ æ–‡æœ¬æ¸…ç†æµç¨‹</h3>
<p>The text cleaning process comprises multiple steps where each step aims to reduce the complexity of the text. Let&rsquo;s take you through the process using a Python function,Â <code>clean_text</code>.<br>
æ–‡æœ¬æ¸…ç†è¿‡ç¨‹åŒ…å«å¤šä¸ªæ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½æ—¨åœ¨é™ä½æ–‡æœ¬çš„å¤æ‚æ€§ã€‚è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ª Python å‡½æ•°Â <code>clean_text</code>Â æ¥å¸¦æ‚¨äº†è§£æ•´ä¸ªè¿‡ç¨‹ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()  <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text
</span></span></code></pre></div><p>In the function above we can see how each line corresponds to a step in the cleaning process:<br>
åœ¨ä¸Šé¢çš„å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯ä¸€è¡Œæ˜¯å¦‚ä½•å¯¹åº”äºæ¸…æ´è¿‡ç¨‹ä¸­çš„ä¸€ä¸ªæ­¥éª¤çš„ï¼š</p>
<ol>
<li><strong>Lowercase:</strong>Â We convert all text to lower case, so every word looks the same unless it carries a different meaning. This way, words like &lsquo;The&rsquo; and &rsquo;the&rsquo; are no longer seen as different.<br>
å°å†™ï¼šæˆ‘ä»¬å°†æ‰€æœ‰æ–‡æœ¬è½¬æ¢ä¸ºå°å†™ï¼Œå› æ­¤æ¯ä¸ªå•è¯çœ‹èµ·æ¥éƒ½ä¸€æ ·ï¼Œé™¤éå®ƒå…·æœ‰ä¸åŒçš„å«ä¹‰ã€‚è¿™æ ·ï¼Œâ€œTheâ€å’Œâ€œtheâ€å°±ä¸å†è¢«è§†ä¸ºä¸åŒçš„è¯ã€‚</li>
<li><strong>Email addresses:</strong>Â Email addresses don&rsquo;t usually provide useful information unless we&rsquo;re specifically looking for them. This line of code removes any email addresses found.<br>
ç”µå­é‚®ä»¶åœ°å€ï¼šç”µå­é‚®ä»¶åœ°å€é€šå¸¸ä¸ä¼šæä¾›æœ‰ç”¨ä¿¡æ¯ï¼Œé™¤éæˆ‘ä»¬ä¸“é—¨æŸ¥æ‰¾å®ƒä»¬ã€‚è¿™è¡Œä»£ç ä¼šåˆ é™¤æ‰¾åˆ°çš„ä»»ä½•ç”µå­é‚®ä»¶åœ°å€ã€‚</li>
<li><strong>URLs:</strong>Â Similarly, URLs are removed as they are typically not useful in text classification tasks.<br>
URLï¼šç±»ä¼¼åœ°ï¼ŒURL é€šå¸¸åœ¨æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­æ²¡æœ‰ç”¨å¤„ï¼Œå› æ­¤ä¼šè¢«åˆ é™¤ã€‚</li>
<li><strong>Special Characters:</strong>Â We remove any non-word characters (<code>\W</code>) and replace it with space using regex. This includes special characters and punctuation.<br>
ç‰¹æ®Šå­—ç¬¦ï¼šæˆ‘ä»¬ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ é™¤ä»»ä½•éå•è¯å­—ç¬¦ï¼ˆÂ <code>\W</code>Â ï¼‰å¹¶å°†å…¶æ›¿æ¢ä¸ºç©ºæ ¼ã€‚è¿™åŒ…æ‹¬ç‰¹æ®Šå­—ç¬¦å’Œæ ‡ç‚¹ç¬¦å·ã€‚</li>
<li><strong>Numbers:</strong>Â We&rsquo;re dealing with text data, so numbers are also considered distractions unless they carry significant meaning.<br>
æ•°å­—ï¼šæˆ‘ä»¬å¤„ç†çš„æ˜¯æ–‡æœ¬æ•°æ®ï¼Œå› æ­¤é™¤éæ•°å­—å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå¦åˆ™å®ƒä»¬ä¹Ÿè¢«è§†ä¸ºå¹²æ‰°å› ç´ ã€‚</li>
<li><strong>Extra spaces:</strong>Â Any resulting extra spaces from the previous steps are removed.<br>
ä»å…ˆå‰æ­¥éª¤äº§ç”Ÿçš„ä»»ä½•é¢å¤–ç©ºæ ¼éƒ½å°†è¢«åˆ é™¤ã€‚</li>
</ol>
<p>Let&rsquo;s go ahead and run this function on some demo input to see it in action!<br>
è®©æˆ‘ä»¬ç»§ç»­ï¼Œåœ¨ä¸€äº›æ¼”ç¤ºè¾“å…¥ä¸Šè¿è¡Œæ­¤å‡½æ•°ï¼Œçœ‹çœ‹å®ƒçš„å®é™…æ•ˆæœï¼</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(clean_text(<span style="color:#e6db74">&#39;Check out the course at www.codesignal.com/course123&#39;</span>))
</span></span></code></pre></div><p>The output of the above code will be:<br>
ä»¥ä¸Šä»£ç çš„è¾“å‡ºå°†æ˜¯ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>check out the course at www codesignal com course 
</span></span></code></pre></div><h5 id="implementing-text-cleaning-function">Implementing Text Cleaning Function</h5>
<p>å®ç°æ–‡æœ¬æ¸…æ´—åŠŸèƒ½</p>
<p>Now that you are familiar with the workings of the function let&rsquo;s implement it in theÂ <strong>20 Newsgroups</strong>Â dataset.<br>
ç°åœ¨ä½ å·²ç»ç†Ÿæ‚‰äº†å‡½æ•°çš„å·¥ä½œåŸç†ï¼Œè®©æˆ‘ä»¬åœ¨ 20 Newsgroups æ•°æ®é›†ä¸­å®ç°å®ƒã€‚</p>
<p>To apply our cleaning function on the dataset, we will make use of the DataFrame data structure fromÂ <code>Pandas</code>, another powerful data manipulation tool in Python.<br>
ä¸ºäº†åœ¨æ•°æ®é›†ä¸Šåº”ç”¨æˆ‘ä»¬çš„æ¸…æ´—å‡½æ•°ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨Â <code>Pandas</code>Â ä¸­çš„ DataFrame æ•°æ®ç»“æ„ï¼Œå®ƒæ˜¯ Python ä¸­å¦ä¸€ä¸ªå¼ºå¤§çš„æ•°æ®æ“ä½œå·¥å…·ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetching the 20 Newsgroups Dataset</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>nlp_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(newsgroups_data<span style="color:#f92672">.</span>data, columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;text&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Applied the cleaning function to the text data</span>
</span></span><span style="display:flex;"><span>nlp_df[<span style="color:#e6db74">&#39;text&#39;</span>] <span style="color:#f92672">=</span> nlp_df[<span style="color:#e6db74">&#39;text&#39;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: clean_text(x))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Checking the cleaned text</span>
</span></span><span style="display:flex;"><span>print(nlp_df<span style="color:#f92672">.</span>head())
</span></span></code></pre></div><p>The output of the above code will be:<br>
ä»¥ä¸Šä»£ç çš„è¾“å‡ºå°†æ˜¯ï¼š</p>
<pre tabindex="0"><code>  
0  from where s my thing subject what car is this...
1  from guy kuo subject si clock poll final call ...
2  from thomas e willis subject pb questions orga...
3  from joe green subject re weitek p organizatio...
4  from jonathan mcdowell subject re shuttle laun...
</code></pre><p>In this code, we&rsquo;re applying theÂ <code>clean_text</code>Â function to each &rsquo;text&rsquo; in our DataFrame using theÂ <code>apply</code>Â function. TheÂ <code>apply</code>Â function passes every value of the DataFrame column to theÂ <code>clean_text</code>Â function one by one.<br>
åœ¨è¿™æ®µä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨Â <code>apply</code>Â å‡½æ•°å°†Â <code>clean_text</code>Â å‡½æ•°åº”ç”¨äº DataFrame ä¸­çš„æ¯ä¸ªâ€œæ–‡æœ¬â€ã€‚Â <code>apply</code>Â å‡½æ•°å°† DataFrame åˆ—çš„æ¯ä¸ªå€¼é€ä¸ªä¼ é€’ç»™Â <code>clean_text</code>Â å‡½æ•°ã€‚</p>
<h3 id="understanding-effectiveness-of-text-cleaning-function">Understanding Effectiveness of Text Cleaning Function</h3>
<p>ç†è§£æ–‡æœ¬æ¸…æ´—åŠŸèƒ½çš„æœ‰æ•ˆæ€§</p>
<p>We want to understand the impact of our text cleaning function. We can achieve this by looking at our text before and after cleaning. Let&rsquo;s use some new examples:<br>
æˆ‘ä»¬æƒ³è¦ç†è§£æ–‡æœ¬æ¸…æ´—å‡½æ•°çš„å½±å“ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æŸ¥çœ‹æ¸…æ´—å‰åçš„æ–‡æœ¬å†…å®¹æ¥å®ç°è¿™ä¸€ç‚¹ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ä¸€äº›æ–°çš„ä¾‹å­ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>test_texts <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;This is an EXAMPLE!&#39;</span>, <span style="color:#e6db74">&#39;Another ex:ample123 with special characters $#@!&#39;</span>, <span style="color:#e6db74">&#39;example@mail.com is an email address.&#39;</span>]
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> test_texts:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Original: </span><span style="color:#e6db74">{</span>text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cleaned: </span><span style="color:#e6db74">{</span>clean_text(text)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;--&#39;</span>)
</span></span></code></pre></div><p>The output of the above code will be:<br>
ä»¥ä¸Šä»£ç çš„è¾“å‡ºå°†æ˜¯ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Original: This <span style="color:#f92672">is</span> an EXAMPLE<span style="color:#960050;background-color:#1e0010">!</span>
</span></span><span style="display:flex;"><span>Cleaned: this <span style="color:#f92672">is</span> an example 
</span></span><span style="display:flex;"><span><span style="color:#f92672">--</span>
</span></span><span style="display:flex;"><span>Original: Another ex:ample123 <span style="color:#66d9ef">with</span> special characters <span style="color:#960050;background-color:#1e0010">$</span><span style="color:#75715e">#@!</span>
</span></span><span style="display:flex;"><span>Cleaned: another ex ample <span style="color:#66d9ef">with</span> special characters 
</span></span><span style="display:flex;"><span><span style="color:#f92672">--</span>
</span></span><span style="display:flex;"><span>Original: example<span style="color:#a6e22e">@mail.com</span> <span style="color:#f92672">is</span> an email address<span style="color:#f92672">.</span>
</span></span><span style="display:flex;"><span>Cleaned: <span style="color:#f92672">is</span> an email address 
</span></span><span style="display:flex;"><span><span style="color:#f92672">--</span>
</span></span></code></pre></div><p>In the example above, you will see that our function successfully transforms all text to lower case and removes punctuation, digits, and email addresses!<br>
åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œä½ ä¼šçœ‹åˆ°æˆ‘ä»¬çš„å‡½æ•°æˆåŠŸåœ°å°†æ‰€æœ‰æ–‡æœ¬è½¬æ¢ä¸ºå°å†™ï¼Œå¹¶åˆ é™¤äº†æ ‡ç‚¹ç¬¦å·ã€æ•°å­—å’Œç”µå­é‚®ä»¶åœ°å€ï¼</p>
<h5 id="lesson-summary-and-practice-exercises">Lesson Summary and Practice Exercises</h5>
<p>è¯¾æ–‡æ€»ç»“å’Œç»ƒä¹ é¢˜</p>
<p>Today we delved into the text cleaning process in Natural Language Processing. We shared why it is necessary and how to implement it in Python. We then applied our text cleaning function on a textual dataset.<br>
ä»Šå¤©æˆ‘ä»¬æ·±å…¥æ¢è®¨äº†è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„æ–‡æœ¬æ¸…æ´—è¿‡ç¨‹ã€‚æˆ‘ä»¬åˆ†äº«äº†ä¸ºä»€ä¹ˆéœ€è¦æ–‡æœ¬æ¸…æ´—ä»¥åŠå¦‚ä½•åœ¨ Python ä¸­å®ç°å®ƒã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æ–‡æœ¬æ¸…æ´—å‡½æ•°åº”ç”¨äºä¸€ä¸ªæ–‡æœ¬æ•°æ®é›†ã€‚</p>
<p>We have a few exercises lined up based on what we learned today. Keep swimming ahead, and remember, you learn the most by doing. Happy cleaning!<br>
æˆ‘ä»¬å‡†å¤‡äº†ä¸€äº›ç»ƒä¹ ï¼Œéƒ½æ˜¯åŸºäºä»Šå¤©æ‰€å­¦çš„å†…å®¹ã€‚ç»§ç»­åŠ æ²¹ç»ƒä¹ ï¼Œè®°ä½ï¼Œå®è·µå‡ºçœŸçŸ¥ã€‚ç¥ä½ é¡ºåˆ©å®Œæˆï¼</p>
<h2 id="practice1">ã€ŒPractice1ã€</h2>
<p>Well done, Space Voyager! Now, to further explore the workings of our text cleaning function, let&rsquo;s use a different sentence. Replace the first sentence in theÂ <code>test_texts</code>Â list with the phrase &ldquo;I love learning at CodeSignal; it&rsquo;s so interactive and fun!&rdquo;. Then run theÂ <code>clean_text</code>Â function with the updated list.<br>
å¹²å¾—å¥½ï¼Œå¤ªç©ºæ—…è¡Œè€…ï¼ç°åœ¨ï¼Œä¸ºäº†è¿›ä¸€æ­¥æ¢ç´¢æˆ‘ä»¬æ–‡æœ¬æ¸…ç†åŠŸèƒ½çš„å·¥ä½œåŸç†ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„å¥å­ã€‚å°†Â <code>test_texts</code>Â åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å¥è¯æ›¿æ¢ä¸ºâ€œæˆ‘å–œæ¬¢åœ¨ Co å­¦ä¹ <br>
å¹²å¾—å¥½ï¼Œå¤ªç©ºæ—…è¡Œå®¶ï¼ç°åœ¨ï¼Œä¸ºäº†è¿›ä¸€æ­¥æ¢ç´¢æ–‡æœ¬æ¸…ç†å‡½æ•°çš„å·¥ä½œåŸç†ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„å¥å­ã€‚å°†Â <code>test_texts</code>Â åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å¥è¯æ›¿æ¢ä¸ºâ€œæˆ‘å–œæ¬¢åœ¨ä»£ç å­¦ä¹ </p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;[^\w\s]&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters but leave spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Normalize whitespace to single spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip() <span style="color:#75715e"># Strip leading and trailing spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_texts <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;This is an EXAMPLE!&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;Another ex:ample123 with special characters $#@!&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;example@mail.com is an email address.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> test_texts:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Original: </span><span style="color:#e6db74">{</span>text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cleaned: </span><span style="color:#e6db74">{</span>clean_text(text)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;--&#39;</span>)
</span></span></code></pre></div><p>è¾“å‡º</p>
<pre tabindex="0"><code>Original: I love learning at CodeSignal; it&#39;s so interactive and fun!  
Cleaned: i love learning at codesignal its so interactive and fun  
--  
Original: Another ex:ample123 with special characters $#@!  
Cleaned: another example with special characters  
--  
Original: example@mail.com is an email address.  
Cleaned: is an email address  
--
</code></pre><h2 id="practice2filling-in-python-functions-and-regex-patterns">ã€ŒPractice2ã€Filling in Python Functions and Regex Patterns</h2>
<p>Superb job! Now, let&rsquo;s ensure you have grasped the coreÂ <strong>Python functions</strong>Â andÂ <strong>regex patterns</strong>Â used in text cleaning.<br>
å¹²å¾—å¥½ï¼ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¥ç¡®ä¿ä½ å·²ç»æŒæ¡äº†æ–‡æœ¬æ¸…ç†ä¸­ä½¿ç”¨çš„æ ¸å¿ƒ Python å‡½æ•°å’Œæ­£åˆ™è¡¨è¾¾å¼ã€‚</p>
<p>Fill in the blanks (<code>____</code>) to transform all text to lowercase and remove extra spaces.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>____() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\____\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_texts <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;Another ex:ample123 with special characters $#@!&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;example@mail.com is an email address.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> test_texts:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Original: </span><span style="color:#e6db74">{</span>text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cleaned: </span><span style="color:#e6db74">{</span>clean_text(text)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;--&#39;</span>)
</span></span></code></pre></div><p>è§£é‡Š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()  <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_texts <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#e6db74">&#39;Another ex:ample123 with special characters $#@!&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#e6db74">&#39;example@mail.com is an email address.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> test_texts:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Original: </span><span style="color:#e6db74">{</span>text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cleaned: </span><span style="color:#e6db74">{</span>clean_text(text)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;--&#39;</span>)
</span></span></code></pre></div><p>è¾“å‡º</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Original: Fill me In<span style="color:#960050;background-color:#1e0010">!</span> I enjoy problem<span style="color:#f92672">-</span>solving tasks like these; they are quite engaging<span style="color:#f92672">.</span>  
</span></span><span style="display:flex;"><span>Cleaned: fill me <span style="color:#f92672">in</span> i enjoy problem solving tasks like these they are quite engaging  
</span></span><span style="display:flex;"><span><span style="color:#f92672">--</span>  
</span></span><span style="display:flex;"><span>Original: Another ex:ample123 <span style="color:#66d9ef">with</span> special characters <span style="color:#960050;background-color:#1e0010">$</span><span style="color:#75715e">#@!  </span>
</span></span><span style="display:flex;"><span>Cleaned: another ex ample <span style="color:#66d9ef">with</span> special characters  
</span></span><span style="display:flex;"><span><span style="color:#f92672">--</span>  
</span></span><span style="display:flex;"><span>Original: example<span style="color:#a6e22e">@mail.com</span> <span style="color:#f92672">is</span> an email address<span style="color:#f92672">.</span>  
</span></span><span style="display:flex;"><span>Cleaned: <span style="color:#f92672">is</span> an email address  
</span></span><span style="display:flex;"><span><span style="color:#f92672">--</span>
</span></span></code></pre></div><h2 id="practice2filling-in-python-functions-and-regex-patterns-1">ã€ŒPractice2ã€Filling in Python Functions and Regex Patterns</h2>
<p>Superb job! Now, let&rsquo;s ensure you have grasped the coreÂ <strong>Python functions</strong>Â andÂ <strong>regex patterns</strong>Â used in text cleaning.</p>
<p>Fill in the blanks (<code>____</code>) to transform all text to lowercase and remove extra spaces.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>____() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\____\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_texts <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;Another ex:ample123 with special characters $#@!&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;example@mail.com is an email address.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> test_texts:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Original: </span><span style="color:#e6db74">{</span>text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cleaned: </span><span style="color:#e6db74">{</span>clean_text(text)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;--&#39;</span>)
</span></span></code></pre></div><p>è§£é‡Š
Certainly! Here&rsquo;s the completed Python code with the blanks filled:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()  <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_texts <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#e6db74">&#39;Another ex:ample123 with special characters $#@!&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#e6db74">&#39;example@mail.com is an email address.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> test_texts:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Original: </span><span style="color:#e6db74">{</span>text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cleaned: </span><span style="color:#e6db74">{</span>clean_text(text)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;--&#39;</span>)
</span></span></code></pre></div><p>Explanation:</p>
<ul>
<li>The <code>lower()</code> method converts all text to lowercase.</li>
<li>The regex pattern <code>r'\s+'</code> matches one or more whitespace characters, which are then replaced by a single space to remove extra spaces.</li>
</ul>
<h3 id="è¾“å‡º">è¾“å‡º</h3>
<pre tabindex="0"><code>Original: Fill me In! I enjoy problem-solving tasks like these; they are quite engaging.  
Cleaned: fill me in i enjoy problem solving tasks like these they are quite engaging  
--  
Original: Another ex:ample123 with special characters $#@!  
Cleaned: another ex ample with special characters  
--  
Original: example@mail.com is an email address.  
Cleaned: is an email address  
--
</code></pre><h2 id="practice3mastering-text-cleaning-with-python-regex">PracticeÂ 3ï¼šMastering Text Cleaning with Python Regex</h2>
<p>Charming maneuvering, Stellar Navigator!</p>
<p>Now, I want to see more of your Python prowess. Replace the missing parts (<code>____</code>), ensuring that they perform the right operations. We aim toÂ <strong>transform all text to lowercase</strong>Â andÂ <strong>eliminate email addresses</strong>,Â <strong>URLs</strong>,Â <strong>special characters</strong>,Â <strong>digits</strong>, andÂ <strong>extra spaces</strong>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>____() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;____&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;____&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;____&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;____&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;____&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_texts <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Sample Text with EMAIL! mailsample@mail.com&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;URL example: https://www.codesignal.com&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;Special characters #formed.&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;Digits included: 1234!!&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;Extra spaces included.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> test_texts:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Original: </span><span style="color:#e6db74">{</span>text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cleaned: </span><span style="color:#e6db74">{</span>clean_text(text)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;--&#39;</span>)
</span></span></code></pre></div><p>è§£é‡Š
To clean the text by transforming it to lowercase and removing email addresses, URLs, special characters, digits, and extra spaces, you can fill in the missing parts of the provided Python code as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\b[\w\.-]+?@\w+?\.\w+?\b&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+|www\.\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;[^\w\s]&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>test_texts <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;Sample Text with EMAIL! mailsample@mail.com&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;URL example: https://www.codesignal.com&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;Special characters #formed.&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;Digits included: 1234!!&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;Extra spaces included.  &#39;</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> test_texts:
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Original: </span><span style="color:#e6db74">{</span>text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cleaned: </span><span style="color:#e6db74">{</span>clean_text(text)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;--&#39;</span>)
</span></span></code></pre></div><p>Explanation of the substitutions:</p>
<ol>
<li><code>text.lower()</code>: Converts the text to lowercase.</li>
<li><code>re.sub(r'\b[\w\.-]+?@\w+?\.\w+?\b', '', text)</code>: Removes email addresses by matching common email patterns.</li>
<li><code>re.sub(r'http\S+|www\.\S+', '', text)</code>: Removes URLs by matching patterns that start with &ldquo;http&rdquo; or &ldquo;www&rdquo;.</li>
<li><code>re.sub(r'[^\w\s]', ' ', text)</code>: Removes special characters by replacing anything that is not a word character or whitespace with a space.</li>
<li><code>re.sub(r'\d+', '', text)</code>: Removes digits by matching one or more digits.</li>
<li><code>re.sub(r'\s+', ' ', text)</code>: Replaces multiple spaces with a single space.</li>
</ol>
<p>This code will transform the given text according to the specified requirements.</p>
<h2 id="practice">ã€ŒPracticeã€</h2>
<p>Off to a flying start, Celestial Traveler! Your new task requires you to insert missing code into two sections. First,Â <strong>write code</strong>Â that transforms the collected dataset into aÂ <code>DataFrame</code>. Then, ensure that you apply theÂ <code>clean_text</code>Â function to theÂ <code>DataFrame</code>Â to clean up the textual data. Bon Voyage!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Normalize whitespace to single spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip() <span style="color:#75715e"># Strip leading and trailing spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create DataFrame from the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Write the required code to create a dataframe from the dataset. Name the dataframe as nlp_df and the column as &#39;text&#39;.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply the clean_text function to the text data in the DataFrame</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Write the code to apply the clean_text function to the &#39;text&#39; column in the dataframe.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check the cleaned text</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(nlp_df<span style="color:#f92672">.</span>head())
</span></span></code></pre></div><p>è§£é‡Š
Certainly! Let&rsquo;s expand on your query to ensure comprehensive coverage. You are asking for the code needed to transform a dataset collected from the <code>fetch_20newsgroups</code> function into a pandas <code>DataFrame</code>. The task also involves applying a <code>clean_text</code> function to the text data within this <code>DataFrame</code> to clean it up by removing email addresses, URLs, punctuation, digits, and normalizing whitespace. Below is the complete code to achieve this:</p>
<ol>
<li>Transform the fetched dataset into a <code>DataFrame</code>.</li>
<li>Apply the <code>clean_text</code> function to the text column in this <code>DataFrame</code>.</li>
</ol>
<p>Here&rsquo;s the completed code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Normalize whitespace to single spaces</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip() <span style="color:#75715e"># Strip leading and trailing spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create DataFrame from the dataset</span>
</span></span><span style="display:flex;"><span>nlp_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;text&#39;</span>: newsgroups_data<span style="color:#f92672">.</span>data})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply the clean_text function to the text data in the DataFrame</span>
</span></span><span style="display:flex;"><span>nlp_df[<span style="color:#e6db74">&#39;text&#39;</span>] <span style="color:#f92672">=</span> nlp_df[<span style="color:#e6db74">&#39;text&#39;</span>]<span style="color:#f92672">.</span>apply(clean_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check the cleaned text</span>
</span></span><span style="display:flex;"><span>print(nlp_df<span style="color:#f92672">.</span>head())
</span></span></code></pre></div><h3 id="explanation">Explanation:</h3>
<ol>
<li><strong>Fetching Data</strong>: The <code>fetch_20newsgroups</code> function from <code>sklearn.datasets</code> is used to fetch the dataset.</li>
<li><strong>Creating DataFrame</strong>: A pandas <code>DataFrame</code> is created from the dataset, with a single column named <code>text</code>.</li>
<li><strong>Cleaning Text</strong>: The <code>clean_text</code> function is applied to each entry in the <code>text</code> column of the DataFrame to clean the text.</li>
<li><strong>Display Cleaned Data</strong>: The first few rows of the cleaned DataFrame are printed to verify the cleaning process.</li>
</ol>
<p>This code ensures that the dataset is not only structured properly but also cleaned efficiently, ready for any further text processing or analysis tasks.
è¾“å‡º</p>
<pre tabindex="0"><code>0  from where s my thing subject what car is this...  
1  from guy kuo subject si clock poll final call ...  
2  from thomas e willis subject pb questions orga...  
3  from joe green subject re weitek p organizatio...  
4  from jonathan mcdowell subject re shuttle laun...
</code></pre><h2 id="practice-1">ã€ŒPracticeã€</h2>
<p>Excellent work so far, Stellar Navigator! This time, you&rsquo;ll masterÂ <strong>how to clean textual data</strong>. We aim to transform pieces of text into cleaner versions, making them more suitable for further analysis. Let&rsquo;s put the focus on the cleaning functions you&rsquo;ve built previously. Implement a combined function that runs all these cleaning operations in sequence: converting text to lowercase letters, removing email addresses,Â <strong>URLs</strong>,Â <strong>special characters</strong>,Â <strong>digits</strong>, andÂ <strong>extra spaces</strong>. Finally,<strong>apply this unified cleaning function to a dataset</strong>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">lower_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>lower()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_email</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_url</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_special_chars</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_digits</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_extra_spaces</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Implement a function clean_text that runs all the functions above in a sequence</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Create a DataFrame from the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Apply the cleaning functions to the DataFrame</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Check the cleaned text</span>
</span></span></code></pre></div><h2 id="practice5mastering-text-cleaning-with-python-regex-on-a-dataset">ã€ŒPracticeÂ 5ã€ï¼šMastering Text Cleaning with Python Regex on a Dataset</h2>
<p>Excellent work so far, Stellar Navigator! This time, you&rsquo;ll masterÂ <strong>how to clean textual data</strong>. We aim to transform pieces of text into cleaner versions, making them more suitable for further analysis. Let&rsquo;s put the focus on the cleaning functions you&rsquo;ve built previously. Implement a combined function that runs all these cleaning operations in sequence: converting text to lowercase letters, removing email addresses,Â <strong>URLs</strong>,Â <strong>special characters</strong>,Â <strong>digits</strong>, andÂ <strong>extra spaces</strong>. Finally,<strong>apply this unified cleaning function to a dataset</strong>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">lower_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>lower()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_email</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_url</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_special_chars</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_digits</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_extra_spaces</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Implement a function clean_text that runs all the functions above in a sequence</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Create a DataFrame from the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Apply the cleaning functions to the DataFrame</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Check the cleaned text</span>
</span></span></code></pre></div><p>Certainly! Let&rsquo;s rephrase and expand your request to ensure a comprehensive solution.</p>
<p>You want to implement a combined function that performs a series of text cleaning operations, which include converting text to lowercase, removing email addresses, URLs, special characters, digits, and extra spaces. After defining this unified cleaning function, you will apply it to a dataset and inspect the cleaned text.</p>
<p>Here&rsquo;s the step-by-step process to achieve this:</p>
<ol>
<li><strong>Implement a function <code>clean_text</code> that sequentially applies all the cleaning operations.</strong></li>
<li><strong>Fetch a dataset (in this case, the 20 Newsgroups dataset).</strong></li>
<li><strong>Create a DataFrame from the fetched dataset.</strong></li>
<li><strong>Apply the <code>clean_text</code> function to the text data in the DataFrame.</strong></li>
<li><strong>Inspect the cleaned text.</strong></li>
</ol>
<p>Let&rsquo;s start by defining the <code>clean_text</code> function:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Individual cleaning functions</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">lower_text</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>lower()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_email</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_url</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_special_chars</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_digits</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_extra_spaces</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Combined cleaning function</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> lower_text(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_email(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_url(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_special_chars(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_digits(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_extra_spaces(text)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a DataFrame from the dataset</span>
</span></span><span style="display:flex;"><span>df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;text&#39;</span>: newsgroups_data<span style="color:#f92672">.</span>data})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply the cleaning functions to the DataFrame</span>
</span></span><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;cleaned_text&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;text&#39;</span>]<span style="color:#f92672">.</span>apply(clean_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check the cleaned text</span>
</span></span><span style="display:flex;"><span>print(df[<span style="color:#e6db74">&#39;cleaned_text&#39;</span>]<span style="color:#f92672">.</span>head())
</span></span></code></pre></div><p>This script does the following:</p>
<ul>
<li>Defines each individual cleaning function.</li>
<li>Creates a <code>clean_text</code> function that applies all the cleaning steps in sequence.</li>
<li>Fetches the 20 Newsgroups dataset.</li>
<li>Creates a DataFrame from the dataset, with the text data in a column named &rsquo;text&rsquo;.</li>
<li>Applies the <code>clean_text</code> function to each text entry in the DataFrame.</li>
<li>Prints the first few cleaned text entries to verify the results.</li>
</ul>
<p>By running this code, you will transform the text data into a cleaner version suitable for further analysis, ensuring it is free from unwanted characters and formatted consistently.
Certainly! Let&rsquo;s rephrase and expand your request to ensure a comprehensive solution.</p>
<p>You want to implement a combined function that performs a series of text cleaning operations, which include converting text to lowercase, removing email addresses, URLs, special characters, digits, and extra spaces. After defining this unified cleaning function, you will apply it to a dataset and inspect the cleaned text.</p>
<p>Here&rsquo;s the step-by-step process to achieve this:</p>
<ol>
<li><strong>Implement a function <code>clean_text</code> that sequentially applies all the cleaning operations.</strong></li>
<li><strong>Fetch a dataset (in this case, the 20 Newsgroups dataset).</strong></li>
<li><strong>Create a DataFrame from the fetched dataset.</strong></li>
<li><strong>Apply the <code>clean_text</code> function to the text data in the DataFrame.</strong></li>
<li><strong>Inspect the cleaned text.</strong></li>
</ol>
<p>Let&rsquo;s start by defining the <code>clean_text</code> function:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Individual cleaning functions</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">lower_text</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>lower()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_email</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_url</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_special_chars</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_digits</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_extra_spaces</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Combined cleaning function</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> lower_text(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_email(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_url(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_special_chars(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_digits(text)
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_extra_spaces(text)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetch the dataset</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a DataFrame from the dataset</span>
</span></span><span style="display:flex;"><span>df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;text&#39;</span>: newsgroups_data<span style="color:#f92672">.</span>data})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply the cleaning functions to the DataFrame</span>
</span></span><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;cleaned_text&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;text&#39;</span>]<span style="color:#f92672">.</span>apply(clean_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check the cleaned text</span>
</span></span><span style="display:flex;"><span>print(df[<span style="color:#e6db74">&#39;cleaned_text&#39;</span>]<span style="color:#f92672">.</span>head())
</span></span></code></pre></div><p>This script does the following:</p>
<ul>
<li>Defines each individual cleaning function.</li>
<li>Creates a <code>clean_text</code> function that applies all the cleaning steps in sequence.</li>
<li>Fetches the 20 Newsgroups dataset.</li>
<li>Creates a DataFrame from the dataset, with the text data in a column named &rsquo;text&rsquo;.</li>
<li>Applies the <code>clean_text</code> function to each text entry in the DataFrame.</li>
<li>Prints the first few cleaned text entries to verify the results.</li>
</ul>
<p>By running this code, you will transform the text data into a cleaner version suitable for further analysis, ensuring it is free from unwanted characters and formatted consistently.</p>
<h1 id="lesson">lesson</h1>
<p>Blast through text preprocessing with ease! ğŸš€ Keep up the great work - you&rsquo;re doing stellar!</p>
<h5 id="introduction">Introduction</h5>
<p>Hello and welcome to this lesson onÂ <strong>Removing Stop Words and Stemming</strong>! In this lesson, we will dive deep into two essential steps to prepare text data for machine learning models: removing stop words and stemming. These techniques will help us improve the efficiency and accuracy of our models. Let&rsquo;s get started!</p>
<h5 id="understanding-stop-words">Understanding Stop Words</h5>
<p>Stop words in Natural Language Processing (NLP) refer to the most common words in a language. Examples include &ldquo;and&rdquo;, &ldquo;the&rdquo;, &ldquo;is&rdquo;, and others that do not provide significant meaning and are often removed to speed up processing without losing crucial information. For this purpose, Python&rsquo;s Natural Language Tool Kit (NLTK) provides a pre-defined list of stop words. Let&rsquo;s have a look:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Defining the stop words</span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print 5 stop words</span>
</span></span><span style="display:flex;"><span>examples_of_stopwords <span style="color:#f92672">=</span> list(stop_words)[:<span style="color:#ae81ff">5</span>]
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Examples of stop words: </span><span style="color:#e6db74">{</span>examples_of_stopwords<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>The output of the above code will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Examples of stop words: [<span style="color:#e6db74">&#39;or&#39;</span>, <span style="color:#e6db74">&#39;some&#39;</span>, <span style="color:#e6db74">&#39;couldn&#39;</span>, <span style="color:#e6db74">&#39;hasn&#39;</span>, <span style="color:#e6db74">&#39;after&#39;</span>]
</span></span></code></pre></div><p>Here, theÂ <code>stopwords.words('english')</code>Â function returns a list of English stop words. You might sometimes need to add domain-specific stop words to this list based on the nature of your text data.</p>
<h5 id="introduction-to-stemming">Introduction to Stemming</h5>
<p>Stemming is a technique that reduces a word to its root form. Although the stemmed word may not always be a real or grammatically correct word in English, it does help to consolidate different forms of the same word to a common base form, reducing the complexity of text data. This simplification leads to quicker computation and potentially better performance when implementing Natural Language Processing (NLP) algorithms, as there are fewer unique words to consider.</p>
<p>For example, the words &ldquo;run&rdquo;, &ldquo;runs&rdquo;, &ldquo;running&rdquo; might all be stemmed to the common root &ldquo;run&rdquo;. This helps our algorithm understand that these words are related and they carry a similar semantic meaning.</p>
<p>Let&rsquo;s illustrate this with Porter Stemmer, a well-known stemming algorithm from the NLTK library:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Stemming with NLTK Porter Stemmer</span>
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stemmed_word <span style="color:#f92672">=</span> stemmer<span style="color:#f92672">.</span>stem(<span style="color:#e6db74">&#39;running&#39;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Stemmed word: </span><span style="color:#e6db74">{</span>stemmed_word<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>The output of the above code will be:</p>
<pre tabindex="0"><code>Stemmed word: run
</code></pre><p>TheÂ <code>PorterStemmer</code>Â class comes with theÂ <code>stem</code>Â method that takes in a word and returns its root form. In this case, &ldquo;running&rdquo; is correctly stemmed to its root word &ldquo;run&rdquo;. This form of preprocessing, although it may lead to words that are not recognizable, is a standard practice in text preprocessing for NLP tasks.</p>
<h5 id="stop-words-removal-and-stemming-in-action">Stop Words Removal and Stemming in Action</h5>
<p>Having understood stop words and stemming, let&rsquo;s develop a function that removes stop words and applies stemming to a given text. We will tokenize the text (split it into individual words) and apply these transformations word by word.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_stopwords_and_stem</span>(text):
</span></span><span style="display:flex;"><span>    tokenized_text <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    filtered_text <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized_text <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>example_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;This is a example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original Text: </span><span style="color:#e6db74">{</span>example_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Processed Text: </span><span style="color:#e6db74">{</span>remove_stopwords_and_stem(example_text)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>The output of the above code will be:</p>
<pre tabindex="0"><code>Original Text: This is a example text to demonstrate the removal of stop words and stemming.
Processed Text: thi exampl text demonstr remov stop word stem .
</code></pre><p>TheÂ <code>remove_stopwords_and_stem</code>Â function does the required processing and provides the cleaned-up text.</p>
<h5 id="stop-words-removal-and-stemming-on-a-dataset">Stop Words Removal and Stemming on a Dataset</h5>
<p>Let&rsquo;s implement the above concepts on a real-world text dataset â€“ theÂ <strong>20 Newsgroups Dataset</strong>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetching 20 newsgroups dataset</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Limit to first 100 data points for efficient code execution</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> newsgroups_data[<span style="color:#e6db74">&#39;data&#39;</span>][:<span style="color:#ae81ff">100</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>processed_newsgroups_data <span style="color:#f92672">=</span> [remove_stopwords_and_stem(text) <span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> newsgroups_data[:<span style="color:#ae81ff">100</span>]]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print first 100 characters of first document</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;First 100 characters of first processed document:&#34;</span>)
</span></span><span style="display:flex;"><span>print(processed_newsgroups_data[<span style="color:#ae81ff">0</span>][:<span style="color:#ae81ff">100</span>])
</span></span></code></pre></div><p>The output of the above code will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>First <span style="color:#ae81ff">100</span> characters of first processed document:
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> : mamatha devineni ratnam <span style="color:#f92672">&lt;</span> mr47<span style="color:#f92672">+</span> <span style="color:#f92672">@</span> andrew<span style="color:#f92672">.</span>cmu<span style="color:#f92672">.</span>edu <span style="color:#f92672">&gt;</span> subject : pen fan reaction organ : post of
</span></span></code></pre></div><p>This process can take a while for large datasets, but the output will be much cleaner and easier for a machine learning model to work with.</p>
<h5 id="summary-and-conclusion">Summary and Conclusion</h5>
<p>And that&rsquo;s a wrap! In today&rsquo;s lesson, we&rsquo;ve learned about stop words and stemming as crucial steps in text preprocessing for machine learning models. We&rsquo;ve used Python&rsquo;s NLTK library to work with stop words and perform stemming. We have processed some example sentences and a real-world dataset to practice these concepts.</p>
<p>As we proceed to more advanced NLP tasks, pre-processing techniques like removing stop words and stemming would serve as a solid foundation. In the upcoming lessons, we will delve deeper into handling missing text data and learn about reshaping textual data for analysis. Let&rsquo;s keep going!</p>
<p>Start practice</p>
<h2 id="practice1-1">ã€Œpractice1ã€</h2>
<p>Excellent work so far, Stellar Navigator! Now it&rsquo;s time toÂ <strong>tweak the implemented text preprocessing method</strong>. Replace the use ofÂ <code>LancasterStemmer</code>Â withÂ <code>PorterStemmer</code>. Remember to importÂ <code>PorterStemmer</code>Â fromÂ <code>nltk.stem</code>. After adjusting your code, run it and observe the differences in your processed text.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> LancasterStemmer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Defining the stop words</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Creating an instance of LancasterStemmer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> LancasterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_stopwords_and_stem</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenized_text <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>filtered_text <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized_text <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>example_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;This is a example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>processed_text <span style="color:#f92672">=</span> remove_stopwords_and_stem(example_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original Text: </span><span style="color:#e6db74">{</span>example_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Processed Text: </span><span style="color:#e6db74">{</span>processed_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><h3 id="è§£é‡Š">è§£é‡Š</h3>
<p>å¥½çš„ï¼Œæˆ‘ä»¬éœ€è¦å°†æ–‡æœ¬é¢„å¤„ç†æ–¹æ³•ä¸­çš„ <code>LancasterStemmer</code> æ›¿æ¢ä¸º <code>PorterStemmer</code>ã€‚è®©æˆ‘ä»¬å¯¼å…¥ <code>PorterStemmer</code> å¹¶ä¿®æ”¹ä»£ç ä»¥ä½¿ç”¨æ–°çš„è¯å¹²æå–å™¨ã€‚è¿™é‡Œæ˜¯è°ƒæ•´åçš„ä»£ç ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Defining the stop words</span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Creating an instance of PorterStemmer</span>
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_stopwords_and_stem</span>(text):
</span></span><span style="display:flex;"><span>    tokenized_text <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    filtered_text <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized_text <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>example_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;This is an example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span style="display:flex;"><span>processed_text <span style="color:#f92672">=</span> remove_stopwords_and_stem(example_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original Text: </span><span style="color:#e6db74">{</span>example_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Processed Text: </span><span style="color:#e6db74">{</span>processed_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><h5 id="å…·ä½“è§£é‡Š">å…·ä½“è§£é‡Š</h5>
<ol>
<li>
<p><strong>å¯¼å…¥åº“å’Œæ¨¡å—</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span></code></pre></div><p>æˆ‘ä»¬ä» <code>nltk.corpus</code> å¯¼å…¥ <code>stopwords</code>ï¼Œä» <code>nltk.stem</code> å¯¼å…¥ <code>PorterStemmer</code>ï¼Œå¹¶ä» <code>nltk.tokenize</code> å¯¼å…¥ <code>word_tokenize</code>ã€‚</p>
</li>
<li>
<p><strong>å®šä¹‰åœæ­¢è¯</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span></code></pre></div><p>æˆ‘ä»¬å®šä¹‰äº†ä¸€ç»„åœæ­¢è¯ï¼Œè¿™äº›æ˜¯å¸¸è§çš„ã€åœ¨åˆ†æä¸­é€šå¸¸ä¼šè¢«ç§»é™¤çš„è¯ï¼ˆå¦‚ &ldquo;is&rdquo;, &ldquo;and&rdquo;, &ldquo;the&rdquo; ç­‰ï¼‰ã€‚</p>
</li>
<li>
<p><strong>åˆ›å»º PorterStemmer å®ä¾‹</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span></code></pre></div><p>æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª <code>PorterStemmer</code> çš„å®ä¾‹ï¼Œç”¨äºè¯å¹²æå–ã€‚</p>
</li>
<li>
<p><strong>å®šä¹‰å»é™¤åœæ­¢è¯å’Œè¯å¹²æå–çš„å‡½æ•°</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_stopwords_and_stem</span>(text):
</span></span><span style="display:flex;"><span>    tokenized_text <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    filtered_text <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized_text <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span></code></pre></div><p>è¿™ä¸ªå‡½æ•°é¦–å…ˆå°†è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œç„¶åç§»é™¤åœæ­¢è¯å¹¶è¿›è¡Œè¯å¹²æå–ï¼Œæœ€åå°†å¤„ç†åçš„è¯é‡æ–°ç»„åˆæˆå­—ç¬¦ä¸²ã€‚</p>
</li>
<li>
<p><strong>ç¤ºä¾‹æ–‡æœ¬å’Œå¤„ç†ç»“æœ</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>example_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;This is an example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span style="display:flex;"><span>processed_text <span style="color:#f92672">=</span> remove_stopwords_and_stem(example_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original Text: </span><span style="color:#e6db74">{</span>example_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Processed Text: </span><span style="color:#e6db74">{</span>processed_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>æˆ‘ä»¬ä½¿ç”¨ç¤ºä¾‹æ–‡æœ¬æ¥å±•ç¤ºå¤„ç†å‰åçš„æ•ˆæœã€‚</p>
</li>
</ol>
<h5 id="è¿è¡Œç»“æœ">è¿è¡Œç»“æœ</h5>
<p>è¿è¡Œä»£ç åï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å¤„ç†å‰åçš„æ–‡æœ¬ï¼š</p>
<ul>
<li><strong>Original Text</strong>: This is an example text to demonstrate the removal of stop words and stemming.</li>
<li><strong>Processed Text</strong>: thi exampl text demonstr remov stop word stem</li>
</ul>
<p>å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œä½¿ç”¨ <code>PorterStemmer</code> åï¼Œæ–‡æœ¬ä¸­çš„è¯è¢«ç®€åŒ–ä¸ºå®ƒä»¬çš„è¯å¹²å½¢å¼ï¼Œä¾‹å¦‚ &ldquo;demonstrate&rdquo; è¢«ç®€åŒ–ä¸º &ldquo;demonstr&rdquo;ã€‚ä¸ <code>LancasterStemmer</code> ç›¸æ¯”ï¼Œ<code>PorterStemmer</code> æ›´ä¸ºå¸¸ç”¨ä¸”æ›´ä¸ºæ¸©å’Œï¼Œåœ¨å®é™…åº”ç”¨ä¸­æ›´ä¸ºå¸¸è§ã€‚</p>
<h2 id="practice-2">ã€ŒPracticeã€</h2>
<p>Well done on completing the first practice, stellar navigator! Now it&rsquo;s time to put your skills further to the test.</p>
<p>The skeleton code for this task is already written for you. You just need to fill in the blank spots (<code>____</code>) to make the code run without errors.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> casual_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> string
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(____<span style="color:#f92672">.</span>____(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Adding string punctuation to stop words to filter them out</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stop_words<span style="color:#f92672">.</span>update(string<span style="color:#f92672">.</span>punctuation)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ex_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Here&#39;s a sample sentence to remove stop words from. It has generic and specific words.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Tokenize the sample sentence with casual_tokenize</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ex_words <span style="color:#f92672">=</span> _____(ex_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Remove stop words and punctuation from the list of tokenized words</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>filtered_words <span style="color:#f92672">=</span> [word <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> ex_words <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word<span style="color:#f92672">.</span>lower() <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Filtered words:&#34;</span>, filtered_words)
</span></span></code></pre></div><p>å½“ç„¶ï¼Œè®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥åœ°å¡«è¡¥ä»£ç ä¸­çš„ç©ºç™½ï¼Œå¹¶è§£é‡Šå…¶ä¸­çš„ä¸»è¦çŸ¥è¯†ç‚¹ã€‚</p>
<h4 id="å¡«è¡¥ç©ºç™½">å¡«è¡¥ç©ºç™½</h4>
<p>æˆ‘ä»¬éœ€è¦å¡«è¡¥ä»¥ä¸‹ç©ºç™½ï¼š</p>
<ol>
<li>ä» <code>nltk.corpus</code> å¯¼å…¥ <code>stopwords</code>ã€‚</li>
<li>ä½¿ç”¨ <code>casual_tokenize</code> å‡½æ•°æ¥åˆ†è¯ã€‚</li>
<li>ä½¿ç”¨ <code>stopwords.words('english')</code> è·å–è‹±æ–‡åœæ­¢è¯ã€‚</li>
</ol>
<p>å¡«è¡¥åçš„ä»£ç å¦‚ä¸‹ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> casual_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> string
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># è·å–è‹±è¯­åœæ­¢è¯</span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># å°†æ ‡ç‚¹ç¬¦å·æ·»åŠ åˆ°åœæ­¢è¯ä¸­</span>
</span></span><span style="display:flex;"><span>stop_words<span style="color:#f92672">.</span>update(string<span style="color:#f92672">.</span>punctuation)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ex_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Here&#39;s a sample sentence to remove stop words from. It has generic and specific words.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ä½¿ç”¨ casual_tokenize åˆ†è¯</span>
</span></span><span style="display:flex;"><span>ex_words <span style="color:#f92672">=</span> casual_tokenize(ex_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ä»åˆ†è¯åçš„å•è¯åˆ—è¡¨ä¸­ç§»é™¤åœæ­¢è¯å’Œæ ‡ç‚¹ç¬¦å·</span>
</span></span><span style="display:flex;"><span>filtered_words <span style="color:#f92672">=</span> [word <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> ex_words <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word<span style="color:#f92672">.</span>lower() <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Filtered words:&#34;</span>, filtered_words)
</span></span></code></pre></div><h4 id="ä¸»è¦çŸ¥è¯†ç‚¹è§£é‡Š">ä¸»è¦çŸ¥è¯†ç‚¹è§£é‡Š</h4>
<ol>
<li>
<p><strong>å¯¼å…¥å¿…è¦æ¨¡å—</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> casual_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> string
</span></span></code></pre></div><p>æˆ‘ä»¬ä» <code>nltk.tokenize</code> å¯¼å…¥ <code>casual_tokenize</code> å‡½æ•°ç”¨äºåˆ†è¯ï¼Œä» <code>nltk.corpus</code> å¯¼å…¥ <code>stopwords</code> ç”¨äºè·å–åœæ­¢è¯ï¼Œå¹¶å¯¼å…¥ <code>string</code> æ¨¡å—æ¥å¤„ç†æ ‡ç‚¹ç¬¦å·ã€‚</p>
</li>
<li>
<p><strong>è·å–åœæ­¢è¯å¹¶æ›´æ–°</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>stop_words<span style="color:#f92672">.</span>update(string<span style="color:#f92672">.</span>punctuation)
</span></span></code></pre></div><p>è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ <code>stopwords.words('english')</code> è·å–ä¸€ç»„è‹±è¯­åœæ­¢è¯ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºé›†åˆä»¥ä¾¿é«˜æ•ˆæŸ¥æ‰¾ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ <code>stop_words.update(string.punctuation)</code> å°†æ‰€æœ‰æ ‡ç‚¹ç¬¦å·æ·»åŠ åˆ°åœæ­¢è¯é›†åˆä¸­ï¼Œä»¥ç¡®ä¿å®ƒä»¬åœ¨åç»­å¤„ç†ä¸­è¢«ç§»é™¤ã€‚</p>
</li>
<li>
<p><strong>ç¤ºä¾‹æ–‡æœ¬</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>ex_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Here&#39;s a sample sentence to remove stop words from. It has generic and specific words.&#34;</span>
</span></span></code></pre></div><p>æˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªç¤ºä¾‹æ–‡æœ¬ï¼Œå…¶ä¸­åŒ…å«äº†éœ€è¦å¤„ç†çš„å•è¯å’Œæ ‡ç‚¹ç¬¦å·ã€‚</p>
</li>
<li>
<p><strong>åˆ†è¯</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>ex_words <span style="color:#f92672">=</span> casual_tokenize(ex_text)
</span></span></code></pre></div><p>ä½¿ç”¨ <code>casual_tokenize</code> å‡½æ•°å°†ç¤ºä¾‹æ–‡æœ¬åˆ†è¯ï¼Œè¿™ä¸ªå‡½æ•°ç‰¹åˆ«é€‚ç”¨äºå¤„ç†ç¤¾äº¤åª’ä½“æ–‡æœ¬ï¼Œå› ä¸ºå®ƒèƒ½å¤„ç†ç¼©ç•¥è¯ã€è¡¨æƒ…ç¬¦å·ç­‰ã€‚</p>
</li>
<li>
<p><strong>ç§»é™¤åœæ­¢è¯å’Œæ ‡ç‚¹ç¬¦å·</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>filtered_words <span style="color:#f92672">=</span> [word <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> ex_words <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word<span style="color:#f92672">.</span>lower() <span style="color:#f92672">in</span> stop_words]
</span></span></code></pre></div><p>è¿™ä¸ªåˆ—è¡¨æ¨å¯¼å¼éå†äº†æ‰€æœ‰åˆ†è¯åçš„å•è¯ï¼Œç§»é™¤äº†æ‰€æœ‰åœ¨ <code>stop_words</code> é›†åˆä¸­çš„å•è¯ã€‚æˆ‘ä»¬ä½¿ç”¨ <code>word.lower()</code> ç¡®ä¿æ¯”è¾ƒæ—¶ä¸åŒºåˆ†å¤§å°å†™ã€‚</p>
</li>
<li>
<p><strong>è¾“å‡ºç»“æœ</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Filtered words:&#34;</span>, filtered_words)
</span></span></code></pre></div><p>æœ€åï¼Œæˆ‘ä»¬è¾“å‡ºå¤„ç†åçš„å•è¯åˆ—è¡¨ï¼Œè¿™ä¸ªåˆ—è¡¨ä¸åŒ…å«ä»»ä½•åœæ­¢è¯æˆ–æ ‡ç‚¹ç¬¦å·ã€‚</p>
</li>
</ol>
<h4 id="è¿è¡Œç»“æœ-1">è¿è¡Œç»“æœ</h4>
<p>å‡è®¾ä»£ç æˆåŠŸè¿è¡Œï¼Œè¾“å‡ºå°†æ˜¯ï¼š</p>
<pre tabindex="0"><code>Filtered words: [&#39;sample&#39;, &#39;sentence&#39;, &#39;remove&#39;, &#39;stop&#39;, &#39;words&#39;, &#39;generic&#39;, &#39;specific&#39;, &#39;words&#39;]
</code></pre><p>åœ¨è¿™ä¸ªç»“æœä¸­ï¼Œæ‰€æœ‰çš„åœæ­¢è¯ï¼ˆå¦‚ &ldquo;Here&rsquo;s&rdquo;, &ldquo;a&rdquo;, &ldquo;to&rdquo;, &ldquo;from&rdquo;, &ldquo;it&rdquo;, &ldquo;has&rdquo;ï¼‰å’Œæ ‡ç‚¹ç¬¦å·éƒ½è¢«ç§»é™¤äº†ï¼Œåªå‰©ä¸‹æœ‰æ„ä¹‰çš„å•è¯ã€‚è¿™ç§å¤„ç†åœ¨æ–‡æœ¬åˆ†æå’Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­éå¸¸é‡è¦ï¼Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ€§èƒ½å’Œåˆ†æçš„å‡†ç¡®æ€§ã€‚</p>
<h2 id="practice-3">ã€ŒPracticeã€</h2>
<p>Stellar work so far, Space Voyager! Now it&rsquo;s time to hone your skills inÂ <em>stemming</em>. Fill in the blank spots (<code>____</code>) to make the code functional. Stem the provided words, and print the stemmed versions. Let&rsquo;s get processing!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> ____
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># List of sample words</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>example_words <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;connection&#34;</span>, <span style="color:#e6db74">&#34;connections&#34;</span>, <span style="color:#e6db74">&#34;connective&#34;</span>, <span style="color:#e6db74">&#34;connected&#34;</span>, <span style="color:#e6db74">&#34;connecting&#34;</span>, <span style="color:#e6db74">&#34;connection&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create object of the Porter Stemmer Class</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> ____
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Stem each word in the list of words</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stemmed_words <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>____(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> example_words]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Stemmed words: &#34;</span>, stemmed_words)
</span></span></code></pre></div><p>è§£é‡Š
To fill in the blanks for this code using the NLTK library, let&rsquo;s detail the process of stemming words using the Porter Stemmer from NLTK. The code aims to create an instance of the Porter Stemmer class and use it to stem a list of example words.</p>
<p>Here&rsquo;s the expanded code with the blanks filled in:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># List of sample words</span>
</span></span><span style="display:flex;"><span>example_words <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;connection&#34;</span>, <span style="color:#e6db74">&#34;connections&#34;</span>, <span style="color:#e6db74">&#34;connective&#34;</span>, <span style="color:#e6db74">&#34;connected&#34;</span>, <span style="color:#e6db74">&#34;connecting&#34;</span>, <span style="color:#e6db74">&#34;connection&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create object of the Porter Stemmer Class</span>
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Stem each word in the list of words</span>
</span></span><span style="display:flex;"><span>stemmed_words <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> example_words]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Stemmed words: &#34;</span>, stemmed_words)
</span></span></code></pre></div><p>Explanation:</p>
<ol>
<li>The <code>from nltk.stem import PorterStemmer</code> line imports the Porter Stemmer class from the NLTK library.</li>
<li>The <code>example_words</code> list contains words that need to be stemmed.</li>
<li>The <code>stemmer = PorterStemmer()</code> line creates an instance of the Porter Stemmer class.</li>
<li>The list comprehension <code>[stemmer.stem(word) for word in example_words]</code> stems each word in the <code>example_words</code> list using the <code>stem</code> method of the Porter Stemmer instance.</li>
<li>The <code>print</code> statement outputs the stemmed words.</li>
</ol>
<h2 id="practice-4">ã€ŒPracticeã€</h2>
<p>Celestial Traveler, letâ€™s put our text preprocessing skills to the test. Can you add the missing line inside the functionÂ <code>remove_stopwords_and_stem</code>Â to tokenize the given text, remove stop words, stem the remaining words, and return the processed text? Give it a shot!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Defining the stop words</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Creating an instance of PorterStemmer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_stopwords_and_stem</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Add the code to tokenize the text, remove stopwords and apply stemming</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>example_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;This is a example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>processed_text <span style="color:#f92672">=</span> remove_stopwords_and_stem(example_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original Text: </span><span style="color:#e6db74">{</span>example_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Processed Text: </span><span style="color:#e6db74">{</span>processed_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>è§£é‡Š
Celestial Traveler, letâ€™s put our text preprocessing skills to the test. Can you add the missing line inside the functionÂ <code>remove_stopwords_and_stem</code>Â to tokenize the given text, remove stop words, stem the remaining words, and return the processed text? Give it a shot!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Defining the stop words</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Creating an instance of PorterStemmer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_stopwords_and_stem</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Add the code to tokenize the text, remove stopwords and apply stemming</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>example_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;This is a example text to demonstrate the removal of stop words and stemming.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>processed_text <span style="color:#f92672">=</span> remove_stopwords_and_stem(example_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Original Text: </span><span style="color:#e6db74">{</span>example_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Processed Text: </span><span style="color:#e6db74">{</span>processed_text<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>è¾“å‡º</p>
<pre tabindex="0"><code>Original Text: This is an example text to demonstrate the removal of stop words and stemming.  
Processed Text: exampl text demonstr remov stop word stem .
</code></pre><h2 id="practice-5">ã€ŒPracticeã€</h2>
<p>Good job, Stellar Navigator! Could you now define theÂ <strong>stop words</strong>Â and instantiate theÂ <code>PorterStemmer</code>Â using NLTK&rsquo;s predefined English stop words andÂ <code>PorterStemmer</code>? Additionally, could you implement the tokenization of the text, remove stop words, apply stemming, and return the processed text in the functionÂ <code>remove_stopwords_and_stem</code>? After doing so, you will preprocess the first newsgroup article and display it. The stars are in your favor!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Define the stop words and instantiate the PorterStemmer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> remove_stopwords_and_stem(text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_stopwords_and_stem</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Implement the process to tokenize the text, remove stopwords and apply stemming</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetching 20 newsgroups dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>)[<span style="color:#e6db74">&#39;data&#39;</span>][:<span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Process and display the first newsgroup article</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cleaned_data <span style="color:#f92672">=</span> clean_text(newsgroups_data[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;First newsgroup article after cleaning and textual preprocessing:&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(cleaned_data)
</span></span></code></pre></div><p>è§£é‡Š
Certainly, letâ€™s complete the <code>clean_text</code> and <code>remove_stopwords_and_stem</code> functions by defining stop words, instantiating the Porter Stemmer, and implementing the text preprocessing steps.</p>
<p>Here is the complete code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define the stop words and instantiate the PorterStemmer</span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>))
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()  <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> remove_stopwords_and_stem(text)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">remove_stopwords_and_stem</span>(text):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Tokenize the text</span>
</span></span><span style="display:flex;"><span>    tokens <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Remove stop words and apply stemming</span>
</span></span><span style="display:flex;"><span>    filtered_text <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokens <span style="color:#66d9ef">if</span> word<span style="color:#f92672">.</span>lower() <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fetching 20 newsgroups dataset</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>)[<span style="color:#e6db74">&#39;data&#39;</span>][:<span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Process and display the first newsgroup article</span>
</span></span><span style="display:flex;"><span>cleaned_data <span style="color:#f92672">=</span> clean_text(newsgroups_data[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;First newsgroup article after cleaning and textual preprocessing:&#34;</span>)
</span></span><span style="display:flex;"><span>print(cleaned_data)
</span></span></code></pre></div><p>Explanation:</p>
<ol>
<li><code>stop_words</code> is defined using NLTK&rsquo;s predefined English stop words.</li>
<li><code>stemmer</code> is instantiated using NLTK&rsquo;s <code>PorterStemmer</code>.</li>
<li>In the <code>clean_text</code> function:
<ul>
<li>The text is converted to lowercase.</li>
<li>Email addresses are removed.</li>
<li>URLs are removed.</li>
<li>Punctuation and special characters are removed.</li>
<li>Digits are removed.</li>
<li>Extra spaces are removed.</li>
<li>The text is processed by the <code>remove_stopwords_and_stem</code> function.</li>
</ul>
</li>
<li>In the <code>remove_stopwords_and_stem</code> function:
<ul>
<li>The text is tokenized using <code>word_tokenize</code>.</li>
<li>Stop words are removed, and the remaining words are stemmed using a list comprehension.</li>
</ul>
</li>
<li>The first article from the 20 newsgroups dataset is processed and displayed.</li>
</ol>
<h3 id="output">output</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>First newsgroup article after cleaning <span style="color:#f92672">and</span> textual preprocessing:  
</span></span><span style="display:flex;"><span>mamatha devineni ratnam subject pen fan reaction organ post offic carnegi mellon pittsburgh pa line nntp post host po andrew cmu edu sure basher pen fan pretti confus lack kind post recent pen massacr devil actual bit puzzl bit reliev howev go put end non pittsburgh relief bit prais pen man kill devil wors thought jagr show much better regular season stat also lot fo fun watch playoff bowman let jagr lot fun next coupl game sinc pen go beat pulp jersey anyway disappoint see island lose final regular season game pen rule
</span></span></code></pre></div><h1 id="lesson4">lesson4</h1>
<p>Brace yourself for an out-of-this-world journey through text classification using n-grams! ğŸš€ We&rsquo;re getting closer to mastering this skill, and I&rsquo;m right here to navigate this adventure with you. Keep going, space explorer!</p>
<h5 id="topic-overview-and-goal">Topic Overview and Goal</h5>
<p>Hello, and welcome to today&rsquo;s lesson onÂ <strong>n-grams</strong>! If you&rsquo;ve ever wondered how language models or text classifiers can understand the context or sequence in text, it&rsquo;s usually courtesy of our today&rsquo;s hero â€” n-grams. In this lesson, we&rsquo;ll delve into the magic of n-grams and how essential they prove in processing textual data. Specifically, we&rsquo;ll learn how to create n-grams from text data using Python, covering unigrams and bigrams.</p>
<h5 id="topic-overview-and-goal-1">Topic Overview and Goal</h5>
<p>Hello, and welcome to today&rsquo;s lesson onÂ <strong>n-grams</strong>! If you&rsquo;ve ever wondered how language models or text classifiers can understand the context or sequence in text, it&rsquo;s usually courtesy of our today&rsquo;s hero â€” n-grams. In this lesson, we&rsquo;ll delve into the magic of n-grams and how essential they prove in processing textual data. Specifically, we&rsquo;ll learn how to create n-grams from text data using Python, covering unigrams and bigrams.</p>
<h4 id="what-are-n-grams">What are n-grams?</h4>
<p>In Natural Language Processing, when we analyze text, it&rsquo;s often beneficial to consider not only individual words but sequences of words. This approach helps to grasp the context better. Here is where n-grams come in handy.</p>
<p>An n-gram is a contiguous sequence of n items from a given sample of text or speech. The &rsquo;n&rsquo; stands for the number of words in the sequence. For instance, in &ldquo;I love dogs,&rdquo; a 1-gram (or unigram) is just one word, like &ldquo;love.&rdquo; A 2-gram (or bigram) would be a sequence of 2 words, like &ldquo;I love&rdquo; or &ldquo;love dogs&rdquo;.</p>
<p>N-grams help preserve the sequential information or context in text data, contributing significantly to many language models or text classifiers.</p>
<h4 id="preparing-data-for-n-grams-creation">Preparing Data for n-Grams Creation</h4>
<p>Before we can create n-grams, we need clean, structured text data. The text needs to be cleaned and preprocessed into a desirable format, after which it can be used for feature extraction or modeling.</p>
<p>Here&rsquo;s an already familiar code where we apply cleaning on our text, removing stop words and stemming the remaining words. These steps include lower-casing words, removing punctuations, useless words (stopwords), and reducing all words to their base or stemmed form.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Function to clean text and perform stemming</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()  <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    tokenized_text <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    filtered_text <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized_text <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span></code></pre></div><h3 id="creating-n-grams-with-python-setting-up-the-vectorizer">Creating n-grams with Python: Setting up the Vectorizer</h3>
<p>Python&rsquo;sÂ <code>sklearn</code>Â library provides an accessible way to generate n-grams. TheÂ <code>CountVectorizer</code>Â class in theÂ <code>sklearn.feature_extraction.text</code>Â module can convert a given text into its matrix representation and allows us to specify the type of n-grams we want.</p>
<p>Let&rsquo;s set up our vectorizer as a preliminary step towards creating n-grams:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer(ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>)) <span style="color:#75715e"># Generate unigram and bigram</span>
</span></span></code></pre></div><p>TheÂ <code>ngram_range=(1, 2)</code>Â parameter instructs our vectorizer to generate n-grams where n ranges from 1 to 2. So, the CountVectorizer will generate both unigrams and bigrams. If we wanted unigrams, bigrams, and trigrams, we could useÂ `ngram_range=(1, 3</p>
<h5 id="creating-n-grams-with-python-applying-the-vectorizer">Creating n-grams with Python: Applying the Vectorizer</h5>
<p>Now that we&rsquo;ve set up our n-gram generating machine let&rsquo;s use it on some real-world data.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Fetching 20 newsgroups dataset and restricting to first 100 records for performance</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;all&#39;</span>)[<span style="color:#e6db74">&#39;data&#39;</span>][:<span style="color:#ae81ff">100</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Clean and preprocess the newsgroup data</span>
</span></span><span style="display:flex;"><span>cleaned_data <span style="color:#f92672">=</span> [clean_text(data) <span style="color:#66d9ef">for</span> data <span style="color:#f92672">in</span> newsgroups_data]
</span></span></code></pre></div><p>Applying the vectorizer to our cleaned text data will create the n-grams:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Apply the CountVectorizer on the cleaned data to create n-grams</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(cleaned_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the shape of X</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Shape of X with n-grams: &#34;</span>, X<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the total number of features</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Total number of features: &#34;</span>, len(features))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print features from index 100 to 110</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Features from index 100 to 110: &#34;</span>, features[<span style="color:#ae81ff">100</span>:<span style="color:#ae81ff">111</span>])
</span></span></code></pre></div><p>The output of the above code will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Shape of X <span style="color:#66d9ef">with</span> n<span style="color:#f92672">-</span>grams:  (<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">16246</span>)
</span></span><span style="display:flex;"><span>Total number of features:  <span style="color:#ae81ff">16246</span>
</span></span><span style="display:flex;"><span>Features <span style="color:#f92672">from</span> index <span style="color:#ae81ff">100</span> to <span style="color:#ae81ff">110</span>:  [<span style="color:#e6db74">&#39;accid figur&#39;</span> <span style="color:#e6db74">&#39;accid worri&#39;</span> <span style="color:#e6db74">&#39;accomod&#39;</span> <span style="color:#e6db74">&#39;accomod like&#39;</span> <span style="color:#e6db74">&#39;accord&#39;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#39;accord document&#39;</span> <span style="color:#e6db74">&#39;accord lynn&#39;</span> <span style="color:#e6db74">&#39;accord mujanov&#39;</span> <span style="color:#e6db74">&#39;accord previou&#39;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#39;account&#39;</span> <span style="color:#e6db74">&#39;account curiou&#39;</span>]
</span></span></code></pre></div><p>The shape ofÂ <code>X</code>Â isÂ <code>(100, 16246)</code>, indicating we have a high-dimensional feature space. The first number,Â <code>100</code>, represents the number of documents or records in your dataset (here, it&rsquo;s 100 as we limited our fetching to the first 100 records of the dataset), whereasÂ <code>16246</code>Â represents the unique n-grams or features created from all the 100 documents.</p>
<p>By printingÂ <code>features[100:111]</code>Â we get a glance into our features where each string represents an n-gram from our cleaned text data. The returned n-gramsÂ <code>['accid figur', 'accid worri', 'accomod', ...]</code>Â include both unigrams (single words likeÂ <code>accomod</code>,Â <code>account</code>) and bigrams (two-word phrases likeÂ <code>accid figur</code>,Â <code>accid worri</code>).</p>
<p>As you can see, generating n-grams adds a new level of complexity to our analysis, as we now have multiple types of features or tokens - unigrams and bigrams. You can experiment with theÂ <code>ngram_range</code>Â parameter inÂ <code>CountVectorizer</code>Â to include trigrams or higher-level n-grams, depending on your specific context and requirements. Remember, each choice will have implications for the complexity and interpretability of your models, and it&rsquo;s always a balance between the two.</p>
<h5 id="lesson-summary-1">Lesson Summary</h5>
<p>Congratulations, you&rsquo;ve finished today&rsquo;s lesson on n-grams! We&rsquo;ve explored what n-grams are and their importance in text classification. We then moved on to preparing data for creating n-grams before we dived into generating them using Python&rsquo;sÂ <code>CountVectorizer</code>Â class in theÂ <code>sklearn</code>Â library.</p>
<p>Now, it&rsquo;s time to get hands-on. Try generating trigrams or 4-grams from the same cleaned newsgroups data and notice the differences. Practicing these skills will not only reinforce the concepts learned in this lesson but also enable you to understand when and how much context is needed for certain tasks.</p>
<p>As always, happy learning!</p>
<h3 id="practice1-2">ã€ŒPractice1ã€</h3>
<p>Excellent work, Space Voyager! Now, let&rsquo;s deepen our understanding ofÂ <strong>n-grams</strong>Â in Python. Modify theÂ <code>ngram_range</code>Â parameter inÂ <code>CountVectorizer</code>Â in the starter code to generate onlyÂ <strong>bigrams</strong>Â andÂ <strong>trigrams</strong>, instead of unigrams, bigrams, and trigrams. ChangeÂ <code>ngram_range</code>Â fromÂ <code>(1, 3)</code>Â toÂ <code>(2, 3)</code>. Display the output and observe the differences.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#34;english&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define function for text cleaning and stemming</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove extra spaces</span>
</span></span></code></pre></div><p>Here is the modified code to generate only bigrams and trigrams using CountVectorizer:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#34;english&#34;</span>)) 
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define function for text cleaning and stemming</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses </span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Tokenize text and remove stop words</span>
</span></span><span style="display:flex;"><span>    tokens <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    tokens <span style="color:#f92672">=</span> [token <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokens <span style="color:#66d9ef">if</span> token <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Stem tokens</span>
</span></span><span style="display:flex;"><span>    stemmed_tokens <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(token) <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokens]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(stemmed_tokens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load 20 newsgroups dataset</span>
</span></span><span style="display:flex;"><span>newsgroups_train <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>, remove<span style="color:#f92672">=</span>(<span style="color:#e6db74">&#39;headers&#39;</span>, <span style="color:#e6db74">&#39;footers&#39;</span>, <span style="color:#e6db74">&#39;quotes&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Clean and preprocess text </span>
</span></span><span style="display:flex;"><span>cleaned_text <span style="color:#f92672">=</span> [clean_text(text) <span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> newsgroups_train<span style="color:#f92672">.</span>data]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize CountVectorizer with bigrams and trigrams only</span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer(ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit and transform cleaned text</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(cleaned_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get feature names</span>
</span></span><span style="display:flex;"><span>feature_names <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print some bigrams and trigrams</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Some bigrams and trigrams:&#34;</span>)
</span></span><span style="display:flex;"><span>print(feature_names[:<span style="color:#ae81ff">20</span>])
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>Some bigrams and trigrams:
[&#39;aa aa&#39; &#39;aa ab&#39; &#39;aa ac&#39; &#39;aa ag&#39; &#39;aa al&#39; &#39;aa am&#39; &#39;aa ap&#39; &#39;aa ar&#39; &#39;aa at&#39; &#39;aa au&#39;
 &#39;aa av&#39; &#39;aa aw&#39; &#39;aa ax&#39; &#39;aa ba&#39; &#39;aa be&#39; &#39;aa bi&#39; &#39;aa bl&#39; &#39;aa bo&#39; &#39;aa br&#39; &#39;aa bu&#39;]
</code></pre><p>Key changes made:</p>
<ul>
<li>Modified <code>ngram_range</code> from <code>(1, 3)</code> to <code>(2, 3)</code> in the CountVectorizer initialization to generate only bigrams and trigrams</li>
<li>Printed out the first 20 features from <code>feature_names</code> to show some example bigrams and trigrams</li>
</ul>
<p>By changing the <code>ngram_range</code> to <code>(2, 3)</code>, the output now contains only bigram and trigram features, without any unigrams. This allows capturing more context by considering pairs and triplets of words together[1][2].</p>
<p>The bigrams and trigrams can provide additional insights compared to just unigrams. For example, &ldquo;new york&rdquo; as a bigram has a different meaning than the individual unigrams &ldquo;new&rdquo; and &ldquo;york&rdquo;[4]. Trigrams extend this to three word phrases.</p>
<p>However, using higher-order n-grams also increases the dimensionality of the feature space substantially[3]. So there is a tradeoff between capturing more context with longer n-grams versus the resulting size of the vocabulary.</p>
<p>Citations:
[1] <a href="https://stackoverflow.com/questions/24005762/understanding-the-ngram-range-argument-in-a-countvectorizer-in-sklearn">https://stackoverflow.com/questions/24005762/understanding-the-ngram-range-argument-in-a-countvectorizer-in-sklearn</a>
[2] <a href="https://www.ibm.com/reference/python/countvectorizer">https://www.ibm.com/reference/python/countvectorizer</a>
[3] <a href="https://maartengr.github.io/BERTopic/getting_started/vectorizers/vectorizers.html">https://maartengr.github.io/BERTopic/getting_started/vectorizers/vectorizers.html</a>
[4] <a href="https://pages.github.rpi.edu/kuruzj/website_introml_rpi/notebooks/08-intro-nlp/03-scikit-learn-text.html">https://pages.github.rpi.edu/kuruzj/website_introml_rpi/notebooks/08-intro-nlp/03-scikit-learn-text.html</a>
[5] <a href="https://kavita-ganesan.com/how-to-use-countvectorizer/">https://kavita-ganesan.com/how-to-use-countvectorizer/</a></p>
<p>Let&rsquo;s deepen our understanding of n-grams in Python by modifying the <code>ngram_range</code> parameter in <code>CountVectorizer</code>. We&rsquo;ll change it to generate only bigrams and trigrams, instead of unigrams, bigrams, and trigrams. Hereâ€™s the complete code including the necessary modifications and output display:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#34;english&#34;</span>))
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define function for text cleaning and stemming</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()  <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>    words <span style="color:#f92672">=</span> word_tokenize(text)  <span style="color:#75715e"># Tokenize the text</span>
</span></span><span style="display:flex;"><span>    words <span style="color:#f92672">=</span> [word <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> words <span style="color:#66d9ef">if</span> word <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> stop_words]  <span style="color:#75715e"># Remove stop words</span>
</span></span><span style="display:flex;"><span>    words <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> words]  <span style="color:#75715e"># Apply stemming</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(words)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>corpus <span style="color:#f92672">=</span> newsgroups_data<span style="color:#f92672">.</span>data
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Clean the text data</span>
</span></span><span style="display:flex;"><span>cleaned_corpus <span style="color:#f92672">=</span> [clean_text(text) <span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> corpus]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize CountVectorizer with ngram_range set to (2, 3)</span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer(ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>))
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(cleaned_corpus)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Convert the output to a DataFrame for better readability</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get feature names and create DataFrame</span>
</span></span><span style="display:flex;"><span>features <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(X<span style="color:#f92672">.</span>toarray(), columns<span style="color:#f92672">=</span>features)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the DataFrame</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> ace_tools <span style="color:#66d9ef">as</span> tools; tools<span style="color:#f92672">.</span>display_dataframe_to_user(name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;N-gram Feature Matrix&#34;</span>, dataframe<span style="color:#f92672">=</span>df)
</span></span></code></pre></div><p>In this script:</p>
<ol>
<li><strong>Data Cleaning</strong>: We clean and preprocess the text data by removing email addresses, URLs, punctuation, special characters, and digits. We also remove stop words and apply stemming.</li>
<li><strong>CountVectorizer</strong>: We set the <code>ngram_range</code> to <code>(2, 3)</code> in the <code>CountVectorizer</code>, which will generate only bigrams and trigrams.</li>
<li><strong>Output Display</strong>: The transformed data is converted into a DataFrame to display the bigrams and trigrams.</li>
</ol>
<p>Running this code will generate a feature matrix where the features are bigrams and trigrams extracted from the text data. You will be able to see the differences compared to when unigrams are included in the feature set.</p>
<h3 id="practice-6">ã€ŒPracticeã€</h3>
<p>For the next task, we will simplify our data input and use a simple short string. Through this, we will generate bigrams and trigrams from it. This will give us a more immediate understanding of generating n-grams. Can you fill in the blanks (<code>____</code>) to get the code up and running? Remember, we need to useÂ <code>CountVectorizer</code>Â to generate bigrams and trigrams. After that, display the features created.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simple short text</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;I love studying data science&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Setup the CountVectorizer to generate bigrams and trigrams</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> ____(ngram_range<span style="color:#f92672">=</span>____)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply the CountVectorizer on the text to create n-grams</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform([text])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the shape of X and some features</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Shape of X with n-grams: &#34;</span>, X<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>features <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Features: &#34;</span>, features)
</span></span></code></pre></div><p>Here&rsquo;s the completed code with the necessary blanks filled in to generate bigrams and trigrams using <code>CountVectorizer</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simple short text</span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;I love studying data science&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Setup the CountVectorizer to generate bigrams and trigrams</span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer(ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply the CountVectorizer on the text to create n-grams</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform([text])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the shape of X and some features</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Shape of X with n-grams: &#34;</span>, X<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>features <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Features: &#34;</span>, features)
</span></span></code></pre></div><p>In this code:</p>
<ul>
<li><code>CountVectorizer(ngram_range=(2, 3))</code> sets up the vectorizer to create bigrams (2-grams) and trigrams (3-grams).</li>
<li>The <code>fit_transform</code> method is applied to the input text to create the n-grams.</li>
<li>The shape of the resulting matrix <code>X</code> is printed, as well as the feature names, which represent the bigrams and trigrams generated from the text.</li>
</ul>
<blockquote>
<p>[!tip]</p>
</blockquote>
<h3 id="practice3generating-bigrams-and-trigrams-from-two-texts">PracticeÂ 3ï¼šGenerating Bigrams and Trigrams from Two Texts</h3>
<p>Bravo, Space Voyager! Now let&rsquo;s try generating n-grams again, but with slightly different text. However, this time, theÂ <code>fit_transform</code>Â function and its invoker have been removed. You need to fill in the blanks (<code>____</code>) to get the code running successfully.</p>
<p>TheÂ <code>fit_transform</code>Â function takes input as a list of texts. It will transform the texts into a matrix of token counts and return a sparse representation of this matrix, which we are storing asÂ <code>X</code>. TheÂ <code>fit_transform</code>Â function is convenient when we want to learn a vocabulary dictionary and return document-term matrix at the same time.</p>
<p>For this exercise, we&rsquo;ve made it a bit easier and more meaningful. We&rsquo;re only generating unigrams (individual words) this time, meaning n is equal to 1.</p>
<p>The text we&rsquo;re using this time is not a proper English sentence but a list of stemmed words to better illustrate how n-grams work on a finer level.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define two simple short texts</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;data love data science passion&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;science love algorithm data passion&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Setup the CountVectorizer to generate unigrams only</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer(ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply the CountVectorizer on the text to create n-grams</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> ____<span style="color:#f92672">.</span>____([text1, text2])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the shape of X and some features</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Shape of X with n-grams: &#34;</span>, X<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>features <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Features: &#34;</span>, features)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Matrix X: &#34;</span>, X<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><p>è§£é‡Š
Sure, let&rsquo;s complete the code snippet to use <code>CountVectorizer</code> to generate unigrams and transform the input texts into a matrix of token counts.</p>
<p>Here&rsquo;s the completed code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define two simple short texts</span>
</span></span><span style="display:flex;"><span>text1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;data love data science passion&#34;</span>
</span></span><span style="display:flex;"><span>text2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;science love algorithm data passion&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Setup the CountVectorizer to generate unigrams only</span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer(ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply the CountVectorizer on the text to create n-grams</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform([text1, text2])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the shape of X and some features</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Shape of X with n-grams: &#34;</span>, X<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>features <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Features: &#34;</span>, features)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Matrix X: &#34;</span>, X<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><p>In this snippet:</p>
<ul>
<li>The <code>CountVectorizer</code> is set up to generate unigrams (n-gram range of 1, 1).</li>
<li>The <code>fit_transform</code> method of <code>vectorizer</code> is applied to the list of texts <code>[text1, text2]</code> to create the document-term matrix <code>X</code>.</li>
<li>The shape of <code>X</code>, the feature names (unigrams), and the dense representation of the matrix <code>X</code> are printed out.</li>
</ul>
<p>This will output the shape of the matrix, the features (unique unigrams), and the matrix itself, showing the counts of each unigram in the given texts.</p>
<h1 id="practice-7">ã€ŒPracticeã€</h1>
<p>You are doing an excellent job, Galactic Pioneer!</p>
<p>Now, let&rsquo;s dive a bit deeper into creatingÂ <strong>bigrams</strong>. Set up theÂ <code>CountVectorizer</code>Â to generate bigrams, then apply it to the cleaned data. Once you accomplish this, you&rsquo;ll need to display theÂ <code>shape</code>Â ofÂ <code>X</code>, theÂ <code>feature names</code>, and the matrixÂ <code>X</code>. You can do it!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#34;english&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define function for text cleaning and stemming</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower() <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text) <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text) <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenized_text <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>filtered_text <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized_text <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simple short sentences</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;I love studying data science&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Science is a field I am passionate about&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text3 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Algorithms fascinate me&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text4 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;It is a joy to work on data algorithms&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Clean and preprocess the text</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cleaned_text_1 <span style="color:#f92672">=</span> clean_text(text1)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cleaned_text_2 <span style="color:#f92672">=</span> clean_text(text2)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cleaned_text_3 <span style="color:#f92672">=</span> clean_text(text3)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cleaned_text_4 <span style="color:#f92672">=</span> clean_text(text4)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Setup the CountVectorizer to generate bigrams only</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Apply the CountVectorizer on the cleaned data to create n-grams</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the shape of X and some features</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Shape of X with n-grams: &#34;</span>, X<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>features <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Features: &#34;</span>, features)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Matrix X: &#34;</span>, X<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><p>è§£é‡Š
To generate bigrams from the given cleaned data, we need to use <code>CountVectorizer</code> from the <code>sklearn.feature_extraction.text</code> module with the parameter <code>ngram_range</code> set to <code>(2, 2)</code>. This will configure the <code>CountVectorizer</code> to create bigrams.</p>
<p>Here&rsquo;s the complete code, including the setup of <code>CountVectorizer</code> to generate bigrams, applying it to the cleaned data, and then displaying the shape of <code>X</code>, the feature names, and the matrix <code>X</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load stop words from NLTK and initialize a stemmer</span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#34;english&#34;</span>))
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define function for text cleaning and stemming</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()  <span style="color:#75715e"># Convert text to lower case</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove email addresses</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># Remove URLs</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove punctuation and special characters</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove digits</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># Remove extra spaces</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    tokenized_text <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    filtered_text <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized_text <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simple short sentences</span>
</span></span><span style="display:flex;"><span>text1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;I love studying data science&#34;</span>
</span></span><span style="display:flex;"><span>text2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Science is a field I am passionate about&#34;</span>
</span></span><span style="display:flex;"><span>text3 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Algorithms fascinate me&#34;</span>
</span></span><span style="display:flex;"><span>text4 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;It is a joy to work on data algorithms&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Clean and preprocess the text</span>
</span></span><span style="display:flex;"><span>cleaned_text_1 <span style="color:#f92672">=</span> clean_text(text1)
</span></span><span style="display:flex;"><span>cleaned_text_2 <span style="color:#f92672">=</span> clean_text(text2)
</span></span><span style="display:flex;"><span>cleaned_text_3 <span style="color:#f92672">=</span> clean_text(text3)
</span></span><span style="display:flex;"><span>cleaned_text_4 <span style="color:#f92672">=</span> clean_text(text4)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cleaned_data <span style="color:#f92672">=</span> [cleaned_text_1, cleaned_text_2, cleaned_text_3, cleaned_text_4]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Setup the CountVectorizer to generate bigrams only</span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer(ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply the CountVectorizer on the cleaned data to create bigrams</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(cleaned_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Display the shape of X and some features</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Shape of X with n-grams: &#34;</span>, X<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>features <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Features: &#34;</span>, features)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Matrix X: &#34;</span>, X<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><h3 id="explanation-1">Explanation</h3>
<ol>
<li><strong>Import Libraries</strong>: Necessary libraries are imported, including <code>CountVectorizer</code>, <code>stopwords</code>, <code>word_tokenize</code>, and <code>PorterStemmer</code>.</li>
<li><strong>Clean Text Function</strong>: A function <code>clean_text</code> is defined to preprocess and clean the input text by removing email addresses, URLs, punctuation, digits, and extra spaces. It also converts text to lowercase and stems the words, removing stopwords.</li>
<li><strong>Clean and Preprocess</strong>: Four short sentences are defined, cleaned, and preprocessed using the <code>clean_text</code> function.</li>
<li><strong>CountVectorizer for Bigrams</strong>: A <code>CountVectorizer</code> is set up with <code>ngram_range=(2, 2)</code> to generate bigrams only.</li>
<li><strong>Apply CountVectorizer</strong>: The vectorizer is applied to the cleaned data to create a bigram frequency matrix <code>X</code>.</li>
<li><strong>Display Results</strong>: The shape of <code>X</code>, the feature names (bigrams), and the matrix <code>X</code> itself are printed.</li>
</ol>
<p>This code effectively preprocesses the text, generates bigrams, and displays the results as required.
å¥½çš„ï¼Œæˆ‘æ¥ç”¨ä¸‰å¹´çº§å„¿ç«¥èƒ½ç†è§£çš„æ–¹å¼è§£é‡Šè¿™ä¸ªè¿‡ç¨‹ï¼</p>
<h3 id="1-æ¸…ç†å’Œå¤„ç†æ–‡æœ¬">1. æ¸…ç†å’Œå¤„ç†æ–‡æœ¬</h3>
<p>æˆ‘ä»¬å…ˆè¦æ¸…ç†å’Œå¤„ç†è¿™äº›å¥å­ï¼Œå°±åƒæ•´ç†ä¹¦æ¡Œä¸€æ ·ï¼ŒæŠŠä¸éœ€è¦çš„ä¸œè¥¿æ¸…ç†æ‰ã€‚æˆ‘ä»¬æœ‰ä¸€äº›å¥å­ï¼š</p>
<ul>
<li>æˆ‘çˆ±å­¦ä¹ æ•°æ®ç§‘å­¦</li>
<li>ç§‘å­¦æ˜¯æˆ‘çƒ­çˆ±çš„é¢†åŸŸ</li>
<li>ç®—æ³•è®©æˆ‘ç€è¿·</li>
<li>å·¥ä½œåœ¨æ•°æ®ç®—æ³•ä¸Šæ˜¯ä¸€ç§å¿«ä¹</li>
</ul>
<p>æˆ‘ä»¬åšè¿™äº›æ¸…ç†å·¥ä½œï¼š</p>
<ol>
<li><strong>å˜æˆå°å†™å­—æ¯</strong>ï¼šæŠŠæ‰€æœ‰å¤§å†™å­—æ¯å˜æˆå°å†™ã€‚</li>
<li><strong>å»æ‰å¤šä½™çš„ä¸œè¥¿</strong>ï¼šæ¯”å¦‚å»æ‰é‚®ä»¶åœ°å€ã€ç½‘å€ã€æ ‡ç‚¹ç¬¦å·ã€æ•°å­—å’Œå¤šä½™çš„ç©ºæ ¼ã€‚</li>
<li><strong>å»æ‰ä¸éœ€è¦çš„è¯</strong>ï¼šæ¯”å¦‚â€œçš„â€ã€â€œæ˜¯â€ç­‰è¿™äº›å¸¸ç”¨è¯ã€‚</li>
<li><strong>è¯æ ¹åŒ–</strong>ï¼šæŠŠä¸åŒå½¢å¼çš„è¯å˜æˆå®ƒä»¬çš„åŸºæœ¬å½¢å¼ï¼Œæ¯”å¦‚â€œå­¦ä¹ â€å’Œâ€œå­¦â€å°±å˜æˆä¸€æ ·çš„ã€‚</li>
</ol>
<h3 id="2-åˆ›å»ºäºŒå…ƒç»„bigrams">2. åˆ›å»ºäºŒå…ƒç»„ï¼ˆbigramsï¼‰</h3>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¦æŠŠå¥å­å˜æˆä¸€å¯¹ä¸€å¯¹çš„è¯ï¼Œæ¯”å¦‚â€œæ•°æ®ç§‘å­¦â€å°±å˜æˆäº†ä¸€ä¸ªäºŒå…ƒç»„ã€‚å°±åƒæˆ‘ä»¬æŠŠç³–æœé…å¯¹æˆç³–æœå¯¹ä¸€æ ·ã€‚</p>
<p>æˆ‘ä»¬ç”¨ä¸€ä¸ªå·¥å…·å«<code>CountVectorizer</code>æ¥åšè¿™ä¸ªå·¥ä½œã€‚è¿™ä¸ªå·¥å…·ä¼šå¸®åŠ©æˆ‘ä»¬æ‰¾åˆ°æ‰€æœ‰å¥å­é‡Œçš„è¯å¯¹ï¼Œå¹¶æ•°ä¸€æ•°æ¯ä¸ªè¯å¯¹å‡ºç°äº†å¤šå°‘æ¬¡ã€‚</p>
<h3 id="3-ç»“æœ">3. ç»“æœ</h3>
<p>æˆ‘ä»¬æŠŠè¿™äº›æ¸…ç†åçš„å¥å­ç”¨<code>CountVectorizer</code>å·¥å…·å¤„ç†ï¼Œå¾—åˆ°è¿™äº›ç»“æœï¼š</p>
<ol>
<li><strong>å½¢çŠ¶</strong>ï¼šå°±åƒæˆ‘ä»¬æŠŠæ‰€æœ‰çš„ç³–æœå¯¹æ”¾åœ¨ä¸€ä¸ªå¤§ç›’å­é‡Œï¼Œçœ‹ä¸€çœ‹è¿™ä¸ªç›’å­æœ‰å¤šå¤§ã€‚</li>
<li><strong>ç‰¹å¾ï¼ˆè¯å¯¹ï¼‰</strong>ï¼šæˆ‘ä»¬åˆ—å‡ºæ‰€æœ‰çš„è¯å¯¹ï¼Œçœ‹çœ‹æœ‰å“ªäº›è¯å¯¹ï¼Œæ¯”å¦‚â€œæ•°æ® ç§‘å­¦â€ã€â€œç§‘å­¦ çƒ­çˆ±â€ç­‰ã€‚</li>
<li><strong>çŸ©é˜µ</strong>ï¼šæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªè¡¨æ ¼ï¼Œå‘Šè¯‰æˆ‘ä»¬æ¯ä¸ªå¥å­é‡Œæœ‰å¤šå°‘æ¬¡å‡ºç°äº†è¿™äº›è¯å¯¹ã€‚</li>
</ol>
<h3 id="å®Œæ•´ä»£ç ">å®Œæ•´ä»£ç </h3>
<p>ä¸‹é¢æ˜¯æˆ‘ä»¬å®Œæ•´çš„ä»£ç ï¼Œä½ å¯ä»¥æƒ³è±¡è¿™æ˜¯ä¸€ä¸ªè¶…çº§æœºå™¨äººï¼Œå¸®æˆ‘ä»¬åšæ‰€æœ‰è¿™äº›å·¥ä½œï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># å¯¼å…¥å¿…è¦çš„å·¥å…·</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> stopwords
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.tokenize <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.stem <span style="color:#f92672">import</span> PorterStemmer
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># åœç”¨è¯åˆ—è¡¨å’Œè¯å¹²æå–å™¨</span>
</span></span><span style="display:flex;"><span>stop_words <span style="color:#f92672">=</span> set(stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#34;english&#34;</span>))
</span></span><span style="display:flex;"><span>stemmer <span style="color:#f92672">=</span> PorterStemmer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># å®šä¹‰æ¸…ç†æ–‡æœ¬çš„å‡½æ•°</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(text):
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>lower()  <span style="color:#75715e"># å˜æˆå°å†™å­—æ¯</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\S*@\S*\s?&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># å»æ‰é‚®ä»¶åœ°å€</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;http\S+&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>, text)  <span style="color:#75715e"># å»æ‰ç½‘å€</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\W&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># å»æ‰æ ‡ç‚¹ç¬¦å·</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># å»æ‰æ•°å­—</span>
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\s\s+&#39;</span>, <span style="color:#e6db74">&#39; &#39;</span>, text)  <span style="color:#75715e"># å»æ‰å¤šä½™çš„ç©ºæ ¼</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    tokenized_text <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>    filtered_text <span style="color:#f92672">=</span> [stemmer<span style="color:#f92672">.</span>stem(word) <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> tokenized_text <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> word <span style="color:#f92672">in</span> stop_words]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34; &#34;</span><span style="color:#f92672">.</span>join(filtered_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ä¸€äº›ç®€å•çš„çŸ­å¥</span>
</span></span><span style="display:flex;"><span>text1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;I love studying data science&#34;</span>
</span></span><span style="display:flex;"><span>text2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Science is a field I am passionate about&#34;</span>
</span></span><span style="display:flex;"><span>text3 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Algorithms fascinate me&#34;</span>
</span></span><span style="display:flex;"><span>text4 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;It is a joy to work on data algorithms&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># æ¸…ç†å’Œå¤„ç†æ–‡æœ¬</span>
</span></span><span style="display:flex;"><span>cleaned_text_1 <span style="color:#f92672">=</span> clean_text(text1)
</span></span><span style="display:flex;"><span>cleaned_text_2 <span style="color:#f92672">=</span> clean_text(text2)
</span></span><span style="display:flex;"><span>cleaned_text_3 <span style="color:#f92672">=</span> clean_text(text3)
</span></span><span style="display:flex;"><span>cleaned_text_4 <span style="color:#f92672">=</span> clean_text(text4)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>cleaned_data <span style="color:#f92672">=</span> [cleaned_text_1, cleaned_text_2, cleaned_text_3, cleaned_text_4]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># è®¾ç½®CountVectorizeråªç”ŸæˆäºŒå…ƒç»„</span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer(ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># åº”ç”¨CountVectorizeråˆ°æ¸…ç†åçš„æ•°æ®ä¸Šï¼Œç”ŸæˆäºŒå…ƒç»„</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(cleaned_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># æ˜¾ç¤ºXçš„å½¢çŠ¶å’Œä¸€äº›ç‰¹å¾</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Xçš„å½¢çŠ¶: &#34;</span>, X<span style="color:#f92672">.</span>shape)
</span></span><span style="display:flex;"><span>features <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;ç‰¹å¾: &#34;</span>, features)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;çŸ©é˜µX: &#34;</span>, X<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><p>å¸Œæœ›è¿™ä¸ªè§£é‡Šå¯¹ä½ æœ‰å¸®åŠ©ï¼è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ç”¨è¿™äº›å·¥å…·æ¥åˆ†æå’Œç†è§£æ–‡æœ¬ä¸­çš„è¯å¯¹å•¦ï¼</p>
<h5 id="introduction-and-overview">Introduction and Overview</h5>
<p>å¼•è¨€ä¸æ¦‚è¿°</p>
<p>Ready for our next lesson? Today, we&rsquo;re delving intoÂ <strong>quantiles</strong>Â and theÂ <strong>Interquartile Range</strong>Â (IQR). Quantiles divide our data into equal parts, and the IQR reveals where half of our data lies. These tools aid us in understanding the distribution of our data and in identifying outliers. With Python&rsquo;sÂ <code>pandas</code>Â andÂ <code>NumPy</code>Â libraries, we&rsquo;ll explore how to calculate these measures.<br>
å‡†å¤‡å¥½ä¸‹ä¸€è¯¾äº†å—ï¼Ÿä»Šå¤©ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨åˆ†ä½æ•°å’Œå››åˆ†ä½è· (IQR)ã€‚åˆ†ä½æ•°å°†æˆ‘ä»¬çš„æ•°æ®åˆ†æˆç›¸ç­‰çš„éƒ¨åˆ†ï¼Œè€Œ IQR æ­ç¤ºäº†æˆ‘ä»¬æ•°æ®çš„ä¸€åŠä½äºä½•å¤„ã€‚è¿™äº›å·¥å…·å¸®åŠ©æˆ‘ä»¬ç†è§£æ•°æ®çš„åˆ†å¸ƒå¹¶è¯†åˆ«å¼‚å¸¸å€¼ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Python çš„Â <code>pandas</code>Â å’ŒÂ <code>NumPy</code>Â åº“æ¥æ¢ç´¢å¦‚ä½•è®¡ç®—è¿™äº›æŒ‡æ ‡ã€‚</p>
<h5 id="defining-quantilesåˆ†ä½æ•°çš„å®šä¹‰">Defining QuantilesÂ åˆ†ä½æ•°çš„å®šä¹‰</h5>
<p>Quantiles segment data into equal intervals. For example, when we divide a group of student grades into four equal parts, we employ quartiles (Q1 - 25th percentile, Q2 - 50th percentile or median, and Q3 - 75th percentile).<br>
åˆ†ä½æ•°å°†æ•°æ®åˆ†å‰²æˆç›¸ç­‰çš„åŒºé—´ã€‚ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬å°†ä¸€ç»„å­¦ç”Ÿæˆç»©åˆ†æˆå››ä¸ªç›¸ç­‰çš„éƒ¨åˆ†æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯å››åˆ†ä½æ•°ï¼ˆQ1 - ç¬¬ 25 ç™¾åˆ†ä½æ•°ï¼ŒQ2 - ç¬¬ 50 ç™¾åˆ†ä½æ•°æˆ–ä¸­ä½æ•°ï¼Œä»¥åŠ Q3 - ç¬¬ 75 ç™¾åˆ†ä½æ•°ï¼‰ã€‚</p>
<h5 id="understanding-the-interquartile-range">Understanding the Interquartile Range</h5>
<p>ç†è§£å››åˆ†ä½è·</p>
<p>TheÂ <strong>Interquartile Range</strong>Â (IQR) shows where half of our data lies. It&rsquo;s resistant to outliers; for instance, when analyzing salaries, the IQR omits extreme values, thereby depicting the range where most salaries fall.<br>
å››åˆ†ä½è·ï¼ˆIQRï¼‰æ˜¾ç¤ºäº†æˆ‘ä»¬æ•°æ®ä¸­ä¸€åŠæ•°æ®çš„ä½ç½®ã€‚å®ƒä¸å—å¼‚å¸¸å€¼çš„å½±å“ï¼›ä¾‹å¦‚ï¼Œåœ¨åˆ†æå·¥èµ„æ—¶ï¼ŒIQR ä¼šå¿½ç•¥æç«¯å€¼ï¼Œä»è€Œæè¿°å¤§å¤šæ•°å·¥èµ„æ‰€åœ¨çš„èŒƒå›´ã€‚</p>
<h5 id="calculating-quantiles-with-python">Calculating Quantiles with Python</h5>
<p>ä½¿ç”¨ Python è®¡ç®—åˆ†ä½æ•°</p>
<p>Python&rsquo;sÂ <code>NumPy</code>Â function,Â <code>percentile()</code>, calculates quantiles.<br>
Python çš„Â <code>NumPy</code>Â å‡½æ•°Â <code>percentile()</code>Â ç”¨äºè®¡ç®—åˆ†ä½æ•°ã€‚</p>
<p>Quantiles are essentially just cuts at specific points in your data when it&rsquo;s sorted in ascending order. The first quartile (Q1) is the point below which 25% of the data falls, while the third quartile (Q3) is the point below which 75% of the data falls. The second quartile or the median is the mid-point of the data when it&rsquo;s sorted in ascending order.<br>
åˆ†ä½æ•°æœ¬è´¨ä¸Šæ˜¯åœ¨æŒ‰å‡åºæ’åºçš„æ•°æ®ä¸­ç‰¹å®šç‚¹çš„åˆ‡å‰²ã€‚ç¬¬ä¸€ä¸ªå››åˆ†ä½æ•° (Q1) æ˜¯æŒ‡ä½äºè¯¥ç‚¹çš„æ•°æ®å  25%ï¼Œè€Œç¬¬ä¸‰ä¸ªå››åˆ†ä½æ•° (Q3) æ˜¯æŒ‡ä½äºè¯¥ç‚¹çš„æ•°æ®å  75%ã€‚ç¬¬äºŒä¸ªå››åˆ†ä½æ•°æˆ–ä¸­ä½æ•°æ˜¯æ•°æ®æŒ‰å‡åºæ’åºæ—¶çš„ä¸­é—´ç‚¹ã€‚</p>
<p>These values are important in identifying the spread and skewness of your data. Let&rsquo;s consider a dataset of student scores:<br>
è¿™äº›å€¼å¯¹äºç¡®å®šæ•°æ®çš„ç¦»æ•£ç¨‹åº¦å’Œååº¦éå¸¸é‡è¦ã€‚è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªå­¦ç”Ÿåˆ†æ•°æ•°æ®é›†ï¼š</p>
<p>Python</p>
<p>CopyPlay</p>
<p><code>1import numpy as np 2 3scores = np.array([76, 85, 67, 45, 89, 70, 92, 82]) 4 5# Calculate median 6median_w1 = np.percentile(scores, 50) 7print(median_w1)  # Output: 79.0 8# Check if it is the same as median 9median_w2 = np.median(scores) 10print(median_w2)  # Output 79.0 11 12# Calculate Q1 and Q3 13Q1 = np.percentile(scores, 25) 14print(Q1)  # Output: 69.25 15Q3 = np.percentile(scores, 75) 16print(Q3)  # Output: 86.0</code></p>
<p>Here,Â <code>percentile()</code>Â is used to calculate the 1st, 2nd and 3rd quartiles. When we input 25, the function gives us the value below which 25% of the data lies, i.e., the first quartile Q1. Similarly, when we input 75, it gives the third quartile Q3. The 50th percentile is the median of the dataset.<br>
è¿™é‡Œï¼ŒÂ <code>percentile()</code>Â è¢«ç”¨æ¥è®¡ç®—ç¬¬ä¸€ã€ç¬¬äºŒå’Œç¬¬ä¸‰å››åˆ†ä½æ•°ã€‚å½“æˆ‘ä»¬è¾“å…¥ 25 æ—¶ï¼Œå‡½æ•°ç»™å‡ºçš„æ˜¯æ•°æ®ä¸­ 25%ä½äºè¯¥å€¼çš„å€¼ï¼Œå³ç¬¬ä¸€å››åˆ†ä½æ•° Q1ã€‚åŒæ ·ï¼Œå½“æˆ‘ä»¬è¾“å…¥ 75 æ—¶ï¼Œå®ƒç»™å‡ºçš„æ˜¯ç¬¬ä¸‰å››åˆ†ä½æ•° Q3ã€‚ç¬¬ 50 ä¸ªç™¾åˆ†ä½æ•°æ˜¯æ•°æ®é›†çš„ä¸­ä½æ•°ã€‚</p>
<h5 id="calculating-the-interquartile-range-with-python">Calculating the Interquartile Range with Python</h5>
<p>ä½¿ç”¨ Python è®¡ç®—å››åˆ†ä½è·</p>
<p>TheÂ <strong>Interquartile Range</strong>Â (<code>IQR</code>) is computed asÂ <code>Q3 - Q1</code>.<br>
å››åˆ†ä½è·ï¼ˆÂ <code>IQR</code>Â ï¼‰è®¡ç®—å…¬å¼ä¸ºÂ <code>Q3 - Q1</code>Â ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>math_scores <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#39;Name&#39;</span>: [<span style="color:#e6db74">&#39;Jerome&#39;</span>, <span style="color:#e6db74">&#39;Jessica&#39;</span>, <span style="color:#e6db74">&#39;Jeff&#39;</span>, <span style="color:#e6db74">&#39;Jennifer&#39;</span>, <span style="color:#e6db74">&#39;Jackie&#39;</span>, <span style="color:#e6db74">&#39;Jimmy&#39;</span>, <span style="color:#e6db74">&#39;Joshua&#39;</span>, <span style="color:#e6db74">&#39;Julia&#39;</span>],
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#39;Score&#39;</span>: [<span style="color:#ae81ff">56</span>, <span style="color:#ae81ff">13</span>, <span style="color:#ae81ff">54</span>, <span style="color:#ae81ff">48</span>, <span style="color:#ae81ff">49</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">62</span>, <span style="color:#ae81ff">55</span>]
</span></span><span style="display:flex;"><span>})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># IQR for scores</span>
</span></span><span style="display:flex;"><span>Q1 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>percentile(math_scores[<span style="color:#e6db74">&#39;Score&#39;</span>], <span style="color:#ae81ff">25</span>)
</span></span><span style="display:flex;"><span>Q3 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>percentile(math_scores[<span style="color:#e6db74">&#39;Score&#39;</span>], <span style="color:#ae81ff">75</span>)
</span></span><span style="display:flex;"><span>IQR <span style="color:#f92672">=</span> Q3 <span style="color:#f92672">-</span> Q1
</span></span><span style="display:flex;"><span>print(IQR_score)  <span style="color:#75715e"># Output: 8.75</span>
</span></span></code></pre></div><p>The IQR represents the range within which the middle half of the scores fall. It exposes potential outliers, defined as values that either lie belowÂ <code>Q1 - 1.5 * IQR</code>Â or aboveÂ <code>Q3 + 1.5 * IQR</code>. Multiplying theÂ <code>IQR</code>Â byÂ <code>1.5</code>Â roughly sets a boundary that encapsulatesÂ <code>99.3</code>% of the data assuming a normal distribution. So anything outside this range could be viewed as potential outliers.<br>
IQR è¡¨ç¤ºä¸€åŠæ•°æ®æ‰€åœ¨çš„èŒƒå›´ã€‚å®ƒæ­ç¤ºäº†æ½œåœ¨çš„å¼‚å¸¸å€¼ï¼Œå®šä¹‰ä¸ºä½äºÂ <code>Q1 - 1.5 * IQR</code>Â æˆ–é«˜äºÂ <code>Q3 + 1.5 * IQR</code>Â çš„å€¼ã€‚å°†Â <code>IQR</code>Â ä¹˜ä»¥Â <code>1.5</code>Â å¤§è‡´è®¾å®šäº†ä¸€ä¸ªè¾¹ç•Œï¼Œåœ¨å‡è®¾æ•°æ®å‘ˆæ­£æ€åˆ†å¸ƒçš„æƒ…å†µä¸‹ï¼Œè¯¥è¾¹ç•ŒåŒ…å«äº†Â <code>99.3</code>Â %çš„æ•°æ®ã€‚å› æ­¤ï¼Œè¶…å‡ºæ­¤èŒƒå›´çš„ä»»ä½•æ•°æ®ç‚¹éƒ½å¯èƒ½è¢«è§†ä¸ºæ½œåœ¨çš„å¼‚å¸¸å€¼ã€‚</p>
<p>This boundary ofÂ <code>1.5</code>Â times theÂ <code>IQR</code>Â is a generally accepted rule of thumb and helps to balance between being overly sensitive to slight deviations in the data versus not being sensitive enough to detect potential anomalies or outliers. This rule is particularly useful when data is large and complex when it&rsquo;s hard to discern outliers just by observation.<br>
<code>1.5</code>Â å€Â <code>IQR</code>Â çš„è¾¹ç•Œæ˜¯ä¸€æ¡æ™®éæ¥å—çš„ç»éªŒæ³•åˆ™ï¼Œå®ƒæœ‰åŠ©äºåœ¨å¯¹æ•°æ®çš„è½»å¾®åå·®è¿‡äºæ•æ„Ÿå’Œå¯¹æ£€æµ‹æ½œåœ¨å¼‚å¸¸å€¼æˆ–ç¦»ç¾¤å€¼ä¸å¤Ÿæ•æ„Ÿä¹‹é—´å–å¾—å¹³è¡¡ã€‚å½“æ•°æ®é‡å¤§ä¸”å¤æ‚ï¼Œä»…å‡­è§‚å¯Ÿéš¾ä»¥è¯†åˆ«å¼‚å¸¸å€¼æ—¶ï¼Œè¿™æ¡è§„åˆ™ç‰¹åˆ«æœ‰ç”¨ã€‚</p>
<h5 id="finding-outliersæŸ¥æ‰¾å¼‚å¸¸å€¼">Finding OutliersÂ æŸ¥æ‰¾å¼‚å¸¸å€¼</h5>
<p>Let&rsquo;s select and print out all the outliers using the rule above. We will applyÂ <code>NumPy</code>&rsquo;s boolean selection, which works just fine withÂ <code>pandas</code>:<br>
è®©æˆ‘ä»¬ä½¿ç”¨ä¸Šè¿°è§„åˆ™é€‰æ‹©å¹¶æ‰“å°å‡ºæ‰€æœ‰å¼‚å¸¸å€¼ã€‚æˆ‘ä»¬å°†åº”ç”¨Â <code>NumPy</code>Â çš„å¸ƒå°”é€‰æ‹©ï¼Œå®ƒä¸Â <code>pandas</code>Â å¯ä»¥å¾ˆå¥½åœ°é…åˆä½¿ç”¨ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scores <span style="color:#f92672">=</span> math_scores[<span style="color:#e6db74">&#39;Score&#39;</span>]  <span style="color:#75715e"># to simplify next expression</span>
</span></span><span style="display:flex;"><span>outliers_scores <span style="color:#f92672">=</span> scores[(scores <span style="color:#f92672">&lt;</span> Q1 <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> IQR) <span style="color:#f92672">|</span> (scores <span style="color:#f92672">&gt;</span> Q3 <span style="color:#f92672">+</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> IQR)]
</span></span><span style="display:flex;"><span>print(outliers_scores)  <span style="color:#75715e"># Outputs 13 and 100</span>
</span></span></code></pre></div><h5 id="summary-and-look-aheadæ€»ç»“ä¸å±•æœ›">Summary and Look AheadÂ æ€»ç»“ä¸å±•æœ›</h5>
<p>Congratulations! You&rsquo;ve learned about two key statistical measures: quantiles and theÂ <strong>Interquartile Range</strong>, as well as how to calculate them using Python.<br>
æ­å–œï¼æ‚¨å·²ç»å­¦ä¹ äº†ä¸¤ä¸ªå…³é”®çš„ç»Ÿè®¡æŒ‡æ ‡ï¼šåˆ†ä½æ•°å’Œå››åˆ†ä½è·ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ Python è®¡ç®—å®ƒä»¬ã€‚</p>
<p>In the next lesson, we&rsquo;ll practice these concepts; prepare for some hands-on exercises. Practice aids in mastering these concepts. Let&rsquo;s get started. Are you ready for the next lesson? Happy learning!<br>
ä¸‹ä¸€è¯¾æˆ‘ä»¬å°†ç»ƒä¹ è¿™äº›æ¦‚å¿µï¼Œå‡†å¤‡å¥½è¿›è¡Œä¸€äº›å®è·µç»ƒä¹ ã€‚ç»ƒä¹ æœ‰åŠ©äºæŒæ¡è¿™äº›æ¦‚å¿µã€‚è®©æˆ‘ä»¬å¼€å§‹å§ã€‚ä½ å‡†å¤‡å¥½ä¸‹ä¸€è¯¾äº†å—ï¼Ÿç¥ä½ å­¦ä¹ æ„‰å¿«ï¼</p>
<h5 id="introduction-1">Introduction</h5>
<p>Welcome to our lesson onÂ <strong>Named Entity Recognition</strong>! Today, we&rsquo;ll be diving deep into the world ofÂ <strong>NLP</strong>Â and discovering how we can identify informative chunks of text, namely &ldquo;Named Entities&rdquo;. The goal of this lesson is to learn aboutÂ <strong>Part of Speech (POS) tagging</strong>Â andÂ <strong>Named Entity Recognition (NER)</strong>. By the end, you&rsquo;ll be able to gather specific types of data from text and get a few steps closer to mastering text classification.</p>
<h1 id="lesson-1">lesson</h1>
<h5 id="introductionå¼•è¨€-1">IntroductionÂ å¼•è¨€</h5>
<p>Welcome to our lesson onÂ <strong>Named Entity Recognition</strong>! Today, we&rsquo;ll be diving deep into the world ofÂ <strong>NLP</strong>Â and discovering how we can identify informative chunks of text, namely &ldquo;Named Entities&rdquo;. The goal of this lesson is to learn aboutÂ <strong>Part of Speech (POS) tagging</strong>Â andÂ <strong>Named Entity Recognition (NER)</strong>. By the end, you&rsquo;ll be able to gather specific types of data from text and get a few steps closer to mastering text classification.<br>
æ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„å‘½åå®ä½“è¯†åˆ«è¯¾ç¨‹ï¼ä»Šå¤©ï¼Œæˆ‘ä»¬å°†æ·±å…¥ NLP çš„ä¸–ç•Œï¼Œæ¢ç´¢å¦‚ä½•è¯†åˆ«ä¿¡æ¯ä¸°å¯Œçš„æ–‡æœ¬å—ï¼Œå³â€œå‘½åå®ä½“â€ã€‚æœ¬è¯¾ç¨‹çš„ç›®æ ‡æ˜¯å­¦ä¹ è¯æ€§ (POS) æ ‡æ³¨å’Œå‘½åå®ä½“è¯†åˆ« (NER)ã€‚åœ¨æœ¬è¯¾ç¨‹ç»“æŸæ—¶ï¼Œæ‚¨å°†èƒ½å¤Ÿä»æ–‡æœ¬ä¸­æ”¶é›†ç‰¹å®šç±»å‹çš„æ•°æ®ï¼Œå¹¶å‘æŒæ¡æ–‡æœ¬åˆ†ç±»è¿ˆè¿›å‡ æ­¥ã€‚</p>
<h5 id="what-is-named-entity-recognition">What is Named Entity Recognition?</h5>
<p>å‘½åå®ä½“è¯†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ</p>
<p>Imagine we have a piece of text and we want to get some quick insights. What are the main subjects? Are there any specific locations or organizations being talked about? This is where Named Entity Recognition (NER) comes in handy.<br>
å‡è®¾æˆ‘ä»¬æœ‰ä¸€æ®µæ–‡æœ¬ï¼Œæˆ‘ä»¬æƒ³å¿«é€Ÿäº†è§£å®ƒã€‚ä¸»è¦ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿæœ‰æ²¡æœ‰æåˆ°å…·ä½“çš„åœ°ç‚¹æˆ–ç»„ç»‡ï¼Ÿè¿™å°±æ˜¯å‘½åå®ä½“è¯†åˆ« (NER) çš„ç”¨æ­¦ä¹‹åœ°ã€‚
In natural language processing (NLP), NER is a subtask of information extraction that seeks to locate and classify named entities in text into pre-defined categories such as names of persons, organizations, locations, expressions of times, quantities, monetary values, and percentages.<br>
åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­ï¼Œå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰æ˜¯ä¿¡æ¯æå–çš„ä¸€ä¸ªå­ä»»åŠ¡ï¼Œæ—¨åœ¨å®šä½æ–‡æœ¬ä¸­å‡ºç°çš„å‘½åå®ä½“ï¼Œå¹¶å°†å…¶åˆ†ç±»åˆ°é¢„å…ˆå®šä¹‰çš„ç±»åˆ«ä¸­ï¼Œä¾‹å¦‚äººåã€ç»„ç»‡æœºæ„åã€åœ°ç‚¹ã€æ—¶é—´è¡¨è¾¾å¼ã€æ•°é‡ã€è´§å¸å€¼å’Œç™¾åˆ†æ¯”ã€‚
For instance, consider the sentence: &ldquo;Apple Inc. is planning to open a new store in San Francisco.&rdquo; Using NER, we could identify that &ldquo;Apple Inc.&rdquo; is an organization and &ldquo;San Francisco&rdquo; is a location. Such information can be incredibly valuable for numerous NLP tasks.<br>
ä¾‹å¦‚ï¼Œè€ƒè™‘è¿™å¥è¯ï¼šâ€œè‹¹æœå…¬å¸è®¡åˆ’åœ¨æ—§é‡‘å±±å¼€è®¾ä¸€å®¶æ–°åº—ã€‚â€ ä½¿ç”¨ NERï¼Œæˆ‘ä»¬å¯ä»¥è¯†åˆ«å‡ºâ€œè‹¹æœå…¬å¸â€æ˜¯ä¸€ä¸ªç»„ç»‡ï¼Œâ€œæ—§é‡‘å±±â€æ˜¯ä¸€ä¸ªåœ°ç‚¹ã€‚ è¿™äº›ä¿¡æ¯å¯¹äºä¼—å¤š NLP ä»»åŠ¡æ¥è¯´éå¸¸å®è´µã€‚</p>
<h5 id="part-of-speech-pos-tagging">Part of Speech (POS) Tagging</h5>
<p>è¯æ€§æ ‡æ³¨ (POS)</p>
<p>Every word in a sentence has a particular role. Some words are objects, some are verbs, some are adjectives, and so on. Tagging these parts of speech, or POS tagging, can be a critical component to many NLP tasks. It can help answer many questions, like what are the main objects in a sentence, what actions are being taken, and what&rsquo;s the context of these actions?<br>
å¥å­ä¸­çš„æ¯ä¸ªè¯éƒ½æœ‰ç‰¹å®šçš„è¯æ€§ã€‚æœ‰äº›è¯æ˜¯å®¾è¯­ï¼Œæœ‰äº›è¯æ˜¯åŠ¨è¯ï¼Œæœ‰äº›è¯æ˜¯å½¢å®¹è¯ï¼Œç­‰ç­‰ã€‚å¯¹è¿™äº›è¯æ€§è¿›è¡Œæ ‡è®°ï¼Œæˆ–è€…è¯´è¯æ€§æ ‡æ³¨ï¼Œæ˜¯è®¸å¤šè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚å®ƒå¯ä»¥å¸®åŠ©å›ç­”è®¸å¤šé—®é¢˜ï¼Œä¾‹å¦‚å¥å­ä¸­çš„ä¸»è¦å®¾è¯­æ˜¯ä»€ä¹ˆï¼Œæ­£åœ¨é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ï¼Œä»¥åŠè¿™äº›è¡ŒåŠ¨çš„èƒŒæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ
Let&rsquo;s start with a sentence example: &ldquo;Apple Inc. is planning to open a new store in San Francisco.&rdquo; We are going to useÂ <code>NLTK</code>&lsquo;sÂ <code>pos_tag</code>Â function to tag the part of speech for each word in this sentence.<br>
è®©æˆ‘ä»¬ä»ä¸€ä¸ªä¾‹å¥å¼€å§‹ï¼šâ€œè‹¹æœå…¬å¸è®¡åˆ’åœ¨æ—§é‡‘å±±å¼€è®¾ä¸€å®¶æ–°åº—ã€‚â€æˆ‘ä»¬å°†ä½¿ç”¨Â <code>NLTK</code>Â çš„Â <code>pos_tag</code>Â å‡½æ•°æ¥æ ‡è®°è¿™ä¸ªå¥å­ä¸­æ¯ä¸ªè¯çš„è¯æ€§ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> pos_tag, word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>example_sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Apple Inc. is planning to open a new store in San Francisco.&#34;</span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#f92672">=</span> word_tokenize(example_sentence)
</span></span><span style="display:flex;"><span>pos_tags <span style="color:#f92672">=</span> pos_tag(tokens)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;The first 5 POS tags are: </span><span style="color:#e6db74">{</span>pos_tags[:<span style="color:#ae81ff">5</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><p>The output of the above code will be:<br>
ä»¥ä¸Šä»£ç çš„è¾“å‡ºå°†æ˜¯ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>The first <span style="color:#ae81ff">5</span> POS tags are: [(<span style="color:#e6db74">&#39;Apple&#39;</span>, <span style="color:#e6db74">&#39;NNP&#39;</span>), (<span style="color:#e6db74">&#39;Inc.&#39;</span>, <span style="color:#e6db74">&#39;NNP&#39;</span>), (<span style="color:#e6db74">&#39;is&#39;</span>, <span style="color:#e6db74">&#39;VBZ&#39;</span>), (<span style="color:#e6db74">&#39;planning&#39;</span>, <span style="color:#e6db74">&#39;VBG&#39;</span>), (<span style="color:#e6db74">&#39;to&#39;</span>, <span style="color:#e6db74">&#39;TO&#39;</span>)]
</span></span></code></pre></div><p>Here, every word from our sentence gets tagged with a corresponding part of speech. This is the first step towards performing Named Entity Recognition.<br>
åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¥å­ä¸­çš„æ¯ä¸ªè¯éƒ½è¢«æ ‡è®°äº†ç›¸åº”çš„è¯æ€§ã€‚è¿™æ˜¯è¿›è¡Œå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰çš„ç¬¬ä¸€æ­¥ã€‚</p>
<h5 id="named-entity-recognition-with-nltk">Named Entity Recognition with NLTK</h5>
<p>ä½¿ç”¨ NLTK è¿›è¡Œå‘½åå®ä½“è¯†åˆ«</p>
<p>Now, what about Named Entity Recognition? Well, Named Entity Recognition (or NER) can be considered a step beyond regular POS tagging. It groups together one or more words that signify a named entity such as &ldquo;San Francisco&rdquo; or &ldquo;Apple Inc.&rdquo; into a single category, i.e., location or organization in this case.<br>
é‚£ä¹ˆï¼Œå‘½åå®ä½“è¯†åˆ«å‘¢ï¼Ÿå‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰å¯ä»¥è¢«è§†ä¸ºæ¯”å¸¸è§„è¯æ€§æ ‡æ³¨æ›´è¿›ä¸€æ­¥çš„æŠ€æœ¯ã€‚å®ƒå°†è¡¨ç¤ºå‘½åå®ä½“çš„ä¸€ä¸ªæˆ–å¤šä¸ªå•è¯ï¼ˆä¾‹å¦‚â€œæ—§é‡‘å±±â€æˆ–â€œè‹¹æœå…¬å¸â€ï¼‰å½’ç±»åˆ°å•ä¸ªç±»åˆ«ä¸­ï¼Œåœ¨æœ¬ä¾‹ä¸­åˆ†åˆ«æ˜¯åœ°ç‚¹æˆ–ç»„ç»‡ã€‚
We can use theÂ <code>ne_chunk</code>Â function in NLTK to perform NER on our POS-tagged sentence, like so:<br>
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ NLTK ä¸­çš„Â <code>ne_chunk</code>Â å‡½æ•°å¯¹æˆ‘ä»¬ POS æ ‡æ³¨çš„å¥å­æ‰§è¡Œ NERï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> ne_chunk
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>named_entities <span style="color:#f92672">=</span> ne_chunk(pos_tags)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;The named entities in our example sentences are:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>named_entities<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><p>The output of the above code will be:<br>
ä»¥ä¸Šä»£ç çš„è¾“å‡ºå°†æ˜¯ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>The named entities <span style="color:#f92672">in</span> our example sentences are:
</span></span><span style="display:flex;"><span>(S
</span></span><span style="display:flex;"><span>  (PERSON Apple<span style="color:#f92672">/</span>NNP)
</span></span><span style="display:flex;"><span>  (ORGANIZATION Inc<span style="color:#f92672">./</span>NNP)
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">is</span><span style="color:#f92672">/</span>VBZ
</span></span><span style="display:flex;"><span>  planning<span style="color:#f92672">/</span>VBG
</span></span><span style="display:flex;"><span>  to<span style="color:#f92672">/</span>TO
</span></span><span style="display:flex;"><span>  open<span style="color:#f92672">/</span>VB
</span></span><span style="display:flex;"><span>  a<span style="color:#f92672">/</span>DT
</span></span><span style="display:flex;"><span>  new<span style="color:#f92672">/</span>JJ
</span></span><span style="display:flex;"><span>  store<span style="color:#f92672">/</span>NN
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">in</span><span style="color:#f92672">/</span>IN
</span></span><span style="display:flex;"><span>  (GPE San<span style="color:#f92672">/</span>NNP Francisco<span style="color:#f92672">/</span>NNP)
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">./.</span>)  
</span></span></code></pre></div><p>Let&rsquo;s break down this output:<br>
è®©æˆ‘ä»¬åˆ†æä¸€ä¸‹è¿™ä¸ªè¾“å‡ºï¼š</p>
<ul>
<li>The &lsquo;S&rsquo; at the beginning signifies the start of a sentence.<br>
å¥é¦–çš„â€œSâ€è¡¨ç¤ºä¸€ä¸ªå¥å­çš„å¼€å§‹ã€‚</li>
<li>Words inside paretheses, prefixed with labels such as PERSON, ORGANIZATION, or GPE are recognized named entities. For example, &lsquo;(PERSON Apple/NNP)&rsquo; indicates that &lsquo;Apple&rsquo; is recognized as a named entity representing a Person and &lsquo;Apple&rsquo; has been POS tagged as &lsquo;NNP&rsquo; (Proper Noun, Singular).<br>
æ‹¬å·ä¸­çš„è¯è¯­ï¼Œå¦‚æœå¸¦æœ‰è¯¸å¦‚ PERSONã€ORGANIZATION æˆ– GPE ç­‰æ ‡ç­¾ï¼Œåˆ™è¡¨ç¤ºè¯†åˆ«å‡ºçš„å‘½åå®ä½“ã€‚ä¾‹å¦‚ï¼Œ&rsquo;(PERSON Apple/NNP)&rsquo; è¡¨ç¤ºâ€œAppleâ€è¢«è¯†åˆ«ä¸ºä»£è¡¨äººç‰©çš„å‘½åå®ä½“ï¼Œå¹¶ä¸”â€œAppleâ€å·²è¢«è¯æ€§æ ‡æ³¨ä¸ºâ€œNNPâ€ï¼ˆä¸“æœ‰åè¯ï¼Œå•æ•°ï¼‰ã€‚
<ul>
<li>Words outside parentheses are not recognized as part of a named entity but are part of the sentence and each of them is associated with a POS tag. For instance, &lsquo;is/VBZ&rsquo; means that &lsquo;is&rsquo; is recognized as a verb in present tense, 3rd person singular form.<br>
åœ†æ‹¬å·å¤–çš„å•è¯ä¸è¢«è¯†åˆ«ä¸ºå‘½åå®ä½“çš„ä¸€éƒ¨åˆ†ï¼Œè€Œæ˜¯å¥å­çš„ä¸€éƒ¨åˆ†ï¼Œå¹¶ä¸”æ¯ä¸ªå•è¯éƒ½ä¸ä¸€ä¸ªè¯æ€§æ ‡ç­¾ç›¸å…³è”ã€‚ä¾‹å¦‚ï¼Œâ€œis/VBZâ€è¡¨ç¤ºâ€œisâ€è¢«è¯†åˆ«ä¸ºç°åœ¨æ—¶ã€ç¬¬ä¸‰äººç§°å•æ•°å½¢å¼çš„åŠ¨è¯ã€‚</li>
<li>&lsquo;(GPE San/NNP Francisco/NNP)&rsquo; indicates that &lsquo;San Francisco&rsquo;, a two-word entity, is recognized as a geopolitical entity, such as a city, state, or country.<br>
&lsquo;(GPE San/NNP Francisco/NNP)&rsquo; è¡¨ç¤ºâ€œæ—§é‡‘å±±â€è¿™ä¸ªç”±ä¸¤ä¸ªè¯ç»„æˆçš„å®ä½“è¢«è¯†åˆ«ä¸ºä¸€ä¸ªåœ°ç¼˜æ”¿æ²»å®ä½“ï¼Œä¾‹å¦‚åŸå¸‚ã€å·æˆ–å›½å®¶ã€‚
While Named Entity Recognition offers richer insights than simple POS tagging, it might not always be perfectly accurate due to the ambiguity and context-dependent nature of language. Despite this, it&rsquo;s a powerful tool in any NLP practitioner&rsquo;s arsenal.<br>
è™½ç„¶å‘½åå®ä½“è¯†åˆ«æ¯”ç®€å•çš„è¯æ€§æ ‡æ³¨æä¾›äº†æ›´ä¸°å¯Œçš„è§è§£ï¼Œä½†ç”±äºè¯­è¨€çš„æ­§ä¹‰æ€§å’Œè¯­å¢ƒä¾èµ–æ€§ï¼Œå®ƒå¯èƒ½å¹¶ä¸æ€»æ˜¯å®Œå…¨å‡†ç¡®ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒä»ç„¶æ˜¯ä»»ä½•è‡ªç„¶è¯­è¨€å¤„ç†ä»ä¸šè€…æ­¦å™¨åº“ä¸­çš„æœ‰åŠ›å·¥å…·ã€‚</li>
</ul>
</li>
</ul>
<h5 id="applying-pos-tagging-and-ner-to-a-real-dataset">Applying PoS Tagging and NER to a Real Dataset</h5>
<p>å°†è¯æ€§æ ‡æ³¨å’Œå‘½åå®ä½“è¯†åˆ«åº”ç”¨äºçœŸå®æ•°æ®é›†</p>
<p>Examining these NLP techniques in action on larger, more complex datasets allows us to understand the power of Natural Language Processing better. To this end, let&rsquo;s use POS tagging and Named Entity Recognition on a real-world dataset - the 20 Newsgroups dataset.<br>
åœ¨æ›´å¤§ã€æ›´å¤æ‚çš„æ•°æ®é›†ä¸Šè€ƒå¯Ÿè¿™äº› NLP æŠ€æœ¯çš„å®é™…åº”ç”¨ï¼Œå¯ä»¥è®©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£è‡ªç„¶è¯­è¨€å¤„ç†çš„å¼ºå¤§åŠŸèƒ½ã€‚ä¸ºæ­¤ï¼Œè®©æˆ‘ä»¬åœ¨çœŸå®ä¸–ç•Œçš„æ•°æ®é›†â€”â€”20 Newsgroups æ•°æ®é›†â€”â€”ä¸Šä½¿ç”¨è¯æ€§æ ‡æ³¨å’Œå‘½åå®ä½“è¯†åˆ«æŠ€æœ¯ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> fetch_20newsgroups
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> pos_tag, ne_chunk, word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Loading the data with metadata removed</span>
</span></span><span style="display:flex;"><span>newsgroups_data <span style="color:#f92672">=</span> fetch_20newsgroups(subset<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>, remove<span style="color:#f92672">=</span>(<span style="color:#e6db74">&#39;headers&#39;</span>, <span style="color:#e6db74">&#39;footers&#39;</span>, <span style="color:#e6db74">&#39;quotes&#39;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Selecting the first document </span>
</span></span><span style="display:flex;"><span>first_doc <span style="color:#f92672">=</span> newsgroups_data<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Trimming the document&#39;s text down to the first 67 characters</span>
</span></span><span style="display:flex;"><span>first_doc <span style="color:#f92672">=</span> first_doc[:<span style="color:#ae81ff">67</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Tokenizing the text</span>
</span></span><span style="display:flex;"><span>tokens_first_doc <span style="color:#f92672">=</span> word_tokenize(first_doc)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Applying POS tagging</span>
</span></span><span style="display:flex;"><span>pos_tags_first_doc <span style="color:#f92672">=</span> pos_tag(tokens_first_doc)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Applying Named Entity Recognition</span>
</span></span><span style="display:flex;"><span>named_entities <span style="color:#f92672">=</span> ne_chunk(pos_tags_first_doc)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;The first chunk of named entities in the first document are:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>named_entities<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span></code></pre></div><p>Here&rsquo;s the output you can expect:<br>
è¯·æä¾›æ‚¨éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬å†…å®¹ã€‚æˆ‘å°†å°½åŠ›å°†å…¶å‡†ç¡®åœ°ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡ï¼Œå¹¶ä¿æŒåŸæ–‡çš„å­¦æœ¯è¯­æ°”ï¼Œä¸æ·»åŠ ä»»ä½•è§£é‡Šã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>The first chunk of named entities <span style="color:#f92672">in</span> the first document are:
</span></span><span style="display:flex;"><span>(S
</span></span><span style="display:flex;"><span>  I<span style="color:#f92672">/</span>PRP
</span></span><span style="display:flex;"><span>  was<span style="color:#f92672">/</span>VBD
</span></span><span style="display:flex;"><span>  wondering<span style="color:#f92672">/</span>VBG
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">if</span><span style="color:#f92672">/</span>IN
</span></span><span style="display:flex;"><span>  anyone<span style="color:#f92672">/</span>NN
</span></span><span style="display:flex;"><span>  out<span style="color:#f92672">/</span>IN
</span></span><span style="display:flex;"><span>  there<span style="color:#f92672">/</span>RB
</span></span><span style="display:flex;"><span>  could<span style="color:#f92672">/</span>MD
</span></span><span style="display:flex;"><span>  enlighten<span style="color:#f92672">/</span>VB
</span></span><span style="display:flex;"><span>  me<span style="color:#f92672">/</span>PRP
</span></span><span style="display:flex;"><span>  on<span style="color:#f92672">/</span>IN
</span></span><span style="display:flex;"><span>  this<span style="color:#f92672">/</span>DT
</span></span><span style="display:flex;"><span>  car<span style="color:#f92672">/</span>NN)
</span></span></code></pre></div><p>As you can see, even when we&rsquo;re working with a slimmed-down text input, both POS tagging and NER deliver valuable insights. We&rsquo;ve applied these techniques to just a portion of a complex, real-world dataset, demonstrating how NLP can uncover important information from vast amounts of textual data. This highlights the critical role NLP plays in fields ranging from data analysis to AI and machine learning.<br>
æ­£å¦‚æ‚¨æ‰€è§ï¼Œå³ä½¿æˆ‘ä»¬å¤„ç†çš„æ˜¯ç²¾ç®€çš„æ–‡æœ¬è¾“å…¥ï¼Œè¯æ€§æ ‡æ³¨å’Œå‘½åå®ä½“è¯†åˆ«ä¹Ÿèƒ½æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚æˆ‘ä»¬å·²å°†è¿™äº›æŠ€æœ¯åº”ç”¨äºå¤æ‚ã€çœŸå®çš„æ•°æ®åº“çš„ä¸€éƒ¨åˆ†ï¼Œå±•ç¤ºäº†è‡ªç„¶è¯­è¨€å¤„ç†å¦‚ä½•ä»æµ·é‡æ–‡æœ¬æ•°æ®ä¸­å‘ç°é‡è¦ä¿¡æ¯ã€‚è¿™å‡¸æ˜¾äº†è‡ªç„¶è¯­è¨€å¤„ç†åœ¨ä»æ•°æ®åˆ†æåˆ°äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ç­‰å„ä¸ªé¢†åŸŸçš„å…³é”®ä½œç”¨ã€‚</p>
<h5 id="lesson-summary-and-practice">Lesson Summary and Practice</h5>
<p>è¯¾ç¨‹æ€»ç»“ä¸ç»ƒä¹ </p>
<p>In this lesson, we have coveredÂ <strong>Part of Speech (POS) tagging</strong>,Â <strong>Named Entity Recognition (NER)</strong>, and even applied these techniques to a real-world dataset! These concepts are fundamental to text preprocessing in Natural Language Processing (NLP). Having a grasp over these will allow you to approach more advanced topics in NLP with ease.<br>
åœ¨æœ¬è¯¾ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†è¯æ€§æ ‡æ³¨ (POS)ã€å‘½åå®ä½“è¯†åˆ« (NER)ï¼Œç”šè‡³å°†è¿™äº›æŠ€æœ¯åº”ç”¨åˆ°äº†çœŸå®çš„æ•°æ®é›†ï¼è¿™äº›æ¦‚å¿µæ˜¯è‡ªç„¶è¯­è¨€å¤„ç† (NLP) ä¸­æ–‡æœ¬é¢„å¤„ç†çš„åŸºç¡€ã€‚æŒæ¡è¿™äº›å°†ä½¿æ‚¨èƒ½å¤Ÿè½»æ¾åœ°å¤„ç† NLP ä¸­æ›´é«˜çº§çš„ä¸»é¢˜ã€‚
You have the upcoming tasks to practice these techniques, reinforcing your understanding and improving your Natural Language Processing skills. Let&rsquo;s head onto them and keep learning! Practice is key when it comes to mastering these techniques. Enjoy the hands-on session. Keep Learning!<br>
ä½ æ¥ä¸‹æ¥å°†è¦å®Œæˆçš„ä»»åŠ¡å¯ä»¥å¸®åŠ©ä½ ç»ƒä¹ è¿™äº›æŠ€å·§ï¼Œå·©å›ºç†è§£å¹¶æå‡è‡ªç„¶è¯­è¨€å¤„ç†æŠ€èƒ½ã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼ŒæŒç»­å­¦ä¹ ï¼ç†Ÿç»ƒæŒæ¡è¿™äº›æŠ€å·§çš„å…³é”®åœ¨äºç»ƒä¹ ã€‚äº«å—å®è·µçš„è¿‡ç¨‹å§ï¼æŒç»­å­¦ä¹ ï¼</p>
<h2 id="practice-8">ã€ŒPracticeã€</h2>
<p>Great job! Now, let&rsquo;s shift our focus to another set of student scores, this time inÂ <strong>Math</strong>. The given code calculates upper outlier bound, using theÂ <strong>Interquartile Range (IQR)</strong>Â method, described in the lesson.</p>
<p>Your goal is to update code to calculate lower outlier bound instead, using the same principle.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>math_scores <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">92</span>, <span style="color:#ae81ff">75</span>, <span style="color:#ae81ff">88</span>, <span style="color:#ae81ff">78</span>, <span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">88</span>, <span style="color:#ae81ff">80</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate Q1 and Q3 for math scores</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Q1_math <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>percentile(math_scores, <span style="color:#ae81ff">25</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Q3_math <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>percentile(math_scores, <span style="color:#ae81ff">75</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate the Interquartile Range for math scores</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>IQR_math <span style="color:#f92672">=</span> Q3_math <span style="color:#f92672">-</span> Q1_math
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>upper_outlier_bound <span style="color:#f92672">=</span> Q3_math <span style="color:#f92672">+</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> IQR_math
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(upper_outlier_bound)
</span></span></code></pre></div><p>è§£é‡Š
To update the given code to calculate the lower outlier bound using the Interquartile Range (IQR) method, we need to follow these steps:</p>
<ol>
<li>Calculate the first quartile (Q1) and the third quartile (Q3) for the math scores.</li>
<li>Calculate the Interquartile Range (IQR) by subtracting Q1 from Q3.</li>
<li>Use the IQR to calculate the lower outlier bound by subtracting (1.5 \times \text{IQR}) from Q1.</li>
</ol>
<p>Here is the updated code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Given math scores</span>
</span></span><span style="display:flex;"><span>math_scores <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">92</span>, <span style="color:#ae81ff">75</span>, <span style="color:#ae81ff">88</span>, <span style="color:#ae81ff">78</span>, <span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">88</span>, <span style="color:#ae81ff">80</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate Q1 and Q3 for math scores</span>
</span></span><span style="display:flex;"><span>Q1_math <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>percentile(math_scores, <span style="color:#ae81ff">25</span>)
</span></span><span style="display:flex;"><span>Q3_math <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>percentile(math_scores, <span style="color:#ae81ff">75</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate the Interquartile Range for math scores</span>
</span></span><span style="display:flex;"><span>IQR_math <span style="color:#f92672">=</span> Q3_math <span style="color:#f92672">-</span> Q1_math
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate the lower outlier bound</span>
</span></span><span style="display:flex;"><span>lower_outlier_bound <span style="color:#f92672">=</span> Q1_math <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.5</span> <span style="color:#f92672">*</span> IQR_math
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(lower_outlier_bound)
</span></span></code></pre></div><p>Explanation:</p>
<ul>
<li>We first calculate the first quartile ((Q1)) and the third quartile ((Q3)) using <code>np.percentile</code>.</li>
<li>Then, we find the Interquartile Range ((IQR)) by subtracting (Q1) from (Q3).</li>
<li>Finally, we calculate the lower outlier bound by subtracting (1.5 \times \text{IQR}) from (Q1), which is the standard method to detect lower outliers.</li>
</ul>
<p>This code will output the lower outlier bound for the given math scores.</p>
<h2 id="practice-9">ã€ŒPracticeã€</h2>
<p>Great work, Space Voyager!</p>
<p>Now, change the sentence in the provided code to &ldquo;Microsoft Corporation aims to reach 95% global coverage by 2025.&rdquo; and observe how the named entities identified by theÂ <strong>Named Entity Recognition (NER)</strong>Â change.</p>
<p>Keep advancing!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> pos_tag, word_tokenize, ne_chunk
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Given sentence</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sample_sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Apple Inc. planned to open a new store in San Francisco in 82</span><span style="color:#e6db74">% o</span><span style="color:#e6db74">f time by 2020.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get tokens</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#f92672">=</span> word_tokenize(sample_sentence)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get POS tags</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pos_tags <span style="color:#f92672">=</span> pos_tag(tokens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform NER</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>named_entities <span style="color:#f92672">=</span> ne_chunk(pos_tags)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the identified named entities</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(named_entities)
</span></span></code></pre></div><p>To change the sentence and observe how the named entities identified by the Named Entity Recognition (NER) change, we&rsquo;ll modify the given sentence to &ldquo;Microsoft Corporation aims to reach 95% global coverage by 2025.&rdquo; and then run the NER process.</p>
<p>Here&rsquo;s the updated code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> pos_tag, word_tokenize, ne_chunk
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Updated sentence</span>
</span></span><span style="display:flex;"><span>sample_sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Microsoft Corporation aims to reach 95</span><span style="color:#e6db74">% g</span><span style="color:#e6db74">lobal coverage by 2025.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get tokens</span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#f92672">=</span> word_tokenize(sample_sentence)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get POS tags</span>
</span></span><span style="display:flex;"><span>pos_tags <span style="color:#f92672">=</span> pos_tag(tokens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform NER</span>
</span></span><span style="display:flex;"><span>named_entities <span style="color:#f92672">=</span> ne_chunk(pos_tags)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the identified named entities</span>
</span></span><span style="display:flex;"><span>print(named_entities)
</span></span></code></pre></div><p>The expected output will show the named entities identified by NER. Let&rsquo;s break down the process and what changes we can expect:</p>
<ol>
<li><strong>Tokenization</strong>: The sentence will be split into individual words (tokens).</li>
<li><strong>POS Tagging</strong>: Each token will be tagged with its part of speech.</li>
<li><strong>NER</strong>: The part-of-speech tagged tokens will be analyzed to identify named entities such as organizations, locations, and dates.</li>
</ol>
<p>The initial sentence, &ldquo;Apple Inc. planned to open a new store in San Francisco in 82% of time by 2020,&rdquo; identifies &ldquo;Apple Inc.&rdquo; as an organization, &ldquo;San Francisco&rdquo; as a location, and &ldquo;2020&rdquo; as a date.</p>
<p>For the updated sentence, &ldquo;Microsoft Corporation aims to reach 95% global coverage by 2025,&rdquo; the expected named entities are:</p>
<ul>
<li>&ldquo;Microsoft Corporation&rdquo; as an organization.</li>
<li>&ldquo;2025&rdquo; as a date.</li>
</ul>
<p>Running the code will confirm the exact output. Here&rsquo;s a mock-up of what we can expect:</p>
<pre tabindex="0"><code>(S
  (ORGANIZATION Microsoft/NNP Corporation/NNP)
  aims/VBZ
  to/TO
  reach/VB
  95/CD
  %/NN
  global/JJ
  coverage/NN
  by/IN
  2025/CD)
</code></pre><p>This output indicates that &ldquo;Microsoft Corporation&rdquo; is recognized as an organization, and &ldquo;2025&rdquo; is recognized as a date, as expected. The NER process using <code>ne_chunk</code> from NLTK helps in identifying and categorizing these entities.</p>
<h2 id="practice-10">ã€ŒPracticeã€</h2>
<p>Excellent work, Space Explorer!</p>
<p>Let&rsquo;s reinforce your learning by inserting the missing code. Fill in the appropriate functions to perform tokenization and POS tagging. Use nltk&rsquo;s powerful tools to achieve this. Happy learning!from nltk import ____, word_tokenize</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Given sentence</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sample_sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;The quick brown fox jumps over the lazy dog.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get tokens</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#f92672">=</span> word_tokenize(sample_sentence)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get POS tags</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pos_tags <span style="color:#f92672">=</span> ____(tokens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the POS tags</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(pos_tags)
</span></span></code></pre></div><p>è§£é‡Š
Certainly, here is the completed code with the appropriate functions from the NLTK library to perform tokenization and POS tagging:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> pos_tag, word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Given sentence</span>
</span></span><span style="display:flex;"><span>sample_sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;The quick brown fox jumps over the lazy dog.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get tokens</span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#f92672">=</span> word_tokenize(sample_sentence)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get POS tags</span>
</span></span><span style="display:flex;"><span>pos_tags <span style="color:#f92672">=</span> pos_tag(tokens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the POS tags</span>
</span></span><span style="display:flex;"><span>print(pos_tags)
</span></span></code></pre></div><h3 id="explanation-2">Explanation:</h3>
<ol>
<li>
<p><strong>Importing the necessary functions</strong>:</p>
<ul>
<li><code>pos_tag</code>: This function is used to perform part-of-speech (POS) tagging.</li>
<li><code>word_tokenize</code>: This function is used to split the sentence into individual words or tokens.</li>
</ul>
</li>
<li>
<p><strong>Tokenization</strong>:</p>
<ul>
<li><code>tokens = word_tokenize(sample_sentence)</code>: This line splits the given sentence into tokens.</li>
</ul>
</li>
<li>
<p><strong>POS Tagging</strong>:</p>
<ul>
<li><code>pos_tags = pos_tag(tokens)</code>: This line assigns POS tags to each token.</li>
</ul>
</li>
<li>
<p><strong>Printing the POS tags</strong>:</p>
<ul>
<li><code>print(pos_tags)</code>: This prints out the tokens along with their corresponding POS tags.</li>
</ul>
</li>
</ol>
<p>When you run this code, you should see an output where each word in the sentence is paired with its POS tag, like this:</p>
<pre tabindex="0"><code>[(&#39;The&#39;, &#39;DT&#39;), (&#39;quick&#39;, &#39;JJ&#39;), (&#39;brown&#39;, &#39;JJ&#39;), (&#39;fox&#39;, &#39;NN&#39;), (&#39;jumps&#39;, &#39;VBZ&#39;), (&#39;over&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;lazy&#39;, &#39;JJ&#39;), (&#39;dog&#39;, &#39;NN&#39;)]
</code></pre><h3 id="explanation-of-pos-tags-in-the-output">Explanation of POS tags in the output:</h3>
<ul>
<li><strong>DT</strong>: Determiner</li>
<li><strong>JJ</strong>: Adjective</li>
<li><strong>NN</strong>: Noun, singular or mass</li>
<li><strong>VBZ</strong>: Verb, 3rd person singular present</li>
<li><strong>IN</strong>: Preposition or subordinating conjunction</li>
</ul>
<p>This way, the code effectively tokenizes the sentence and performs POS tagging using NLTK&rsquo;s powerful tools.</p>
<h1 id="lesson-2">lesson</h1>
<h2 id="introduction-2">Introduction</h2>
<p>Hello and welcome! Today&rsquo;s lesson will introduce a crucial component of text feature engineering:Â <em>tokenization</em>. Used in text classification, tokenization is a pre-processing step that transforms raw text into units of meaning known as tokens. By breaking down text into these consumable pieces, we can provide feeding material for machine learning models to understand the text better. Our goal in this lesson is to apply tokenization on a raw text dataset (<em>IMDB movie review dataset</em>) and understand how it can be beneficial in the process of text classification.</p>
<h2 id="understanding-the-concept-and-importance-of-text-tokenization">Understanding the Concept and Importance of Text Tokenization</h2>
<p>Text tokenization is a type of pre-processing step where a text string is split up into individual units (tokens). In most cases, these tokens are words, digits, or punctuation marks. For instance, consider this text: &ldquo;I love Python.&rdquo; After tokenization, this sentence is split intoÂ <code>['I', 'love', 'Python', '.']</code>, with each word and punctuation mark becoming a separate token.</p>
<p>Text tokenization plays a foundational role in text classification and many Natural Language Processing (NLP) tasks. Consider the fact that most machine learning algorithms prefer numerical input. But when dealing with text data, we can&rsquo;t feed raw text directly into these algorithms. This is where tokenization steps in. It breaks down the text into individual tokens, which can then be transformed into some numerical form (via techniques like Bag-of-Words, TF-IDF, etc.). This transformed form can then be processed by the machine learning algorithms.</p>
<h2 id="applying-tokenization-on-a-text-example-using-nltk">Applying Tokenization on a Text Example Using NLTK</h2>
<p>Before we tackle our dataset, let&rsquo;s understand how tokenization works with a simple example. Python and theÂ <code>NLTK</code>Â (Natural Language Toolkit) library, a comprehensive library built specifically for NLP tasks, make tokenization simple and efficient. For our example, suppose we have a sentence: &ldquo;The cat is on the mat.&rdquo; Let&rsquo;s tokenize it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;The cat is on the mat.&#34;</span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#f92672">=</span> word_tokenize(text)
</span></span><span style="display:flex;"><span>print(tokens)
</span></span></code></pre></div><p>The output of the above code will be:</p>
<pre tabindex="0"><code>[&#39;The&#39;, &#39;cat&#39;, &#39;is&#39;, &#39;on&#39;, &#39;the&#39;, &#39;mat&#39;, &#39;.&#39;]
</code></pre><h5 id="text-classification-dataset-overview">Text Classification Dataset Overview</h5>
<p>For the purpose of this lesson, we&rsquo;ll use theÂ <strong>IMDB movie reviews dataset</strong>Â (provided in the NLTK corpus). This dataset contains movie reviews along with their associated binary sentiment polarity labels. The core dataset has 50,000 reviews split evenly into 25k for training and 25k for testing. Each set has 12.5k positive and 12.5k negative reviews. However, for the purpose of these lessons, we will focus on using the first 100 reviews.</p>
<p>It&rsquo;s important to note that the IMDB dataset provided in the NLTK corpus has been preprocessed. The text is already lowercased, and common punctuation is typically separated from the words. This pre-cleaning makes the dataset well-suited for the tokenization process we&rsquo;ll be exploring.</p>
<p>Let&rsquo;s get these reviews and print a few of them:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> movie_reviews
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;movie_reviews&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>movie_reviews_ids <span style="color:#f92672">=</span> movie_reviews<span style="color:#f92672">.</span>fileids()[:<span style="color:#ae81ff">100</span>]
</span></span><span style="display:flex;"><span>review_texts <span style="color:#f92672">=</span> [movie_reviews<span style="color:#f92672">.</span>raw(fileid) <span style="color:#66d9ef">for</span> fileid <span style="color:#f92672">in</span> movie_reviews_ids]
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;First movie review:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, review_texts[<span style="color:#ae81ff">0</span>][:<span style="color:#ae81ff">260</span>])
</span></span></code></pre></div><p>Note that we&rsquo;re only printing the first 260 characters of the first review to prevent lengthy output.</p>
<p>The output of the above code will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>First movie review:
</span></span><span style="display:flex;"><span> plot : two teen couples go to a church party , drink <span style="color:#f92672">and</span> then drive <span style="color:#f92672">.</span> 
</span></span><span style="display:flex;"><span>they get into an accident <span style="color:#f92672">.</span> 
</span></span><span style="display:flex;"><span>one of the guys dies , but his girlfriend continues to see him <span style="color:#f92672">in</span> her life , <span style="color:#f92672">and</span> has nightmares <span style="color:#f92672">.</span> 
</span></span><span style="display:flex;"><span>what<span style="color:#e6db74">&#39;s the deal ? </span>
</span></span><span style="display:flex;"><span>watch the movie <span style="color:#f92672">and</span> <span style="color:#e6db74">&#34; sorta &#34;</span> find out <span style="color:#f92672">.</span> <span style="color:#f92672">.</span>
</span></span></code></pre></div><h5 id="applying-tokenization-on-the-dataset">Applying Tokenization on the Dataset</h5>
<p>Now it&rsquo;s time to transform our data. For this, we will apply tokenization on all our 100 movie reviews.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>tokenized_reviews <span style="color:#f92672">=</span> [word_tokenize(review) <span style="color:#66d9ef">for</span> review <span style="color:#f92672">in</span> review_texts]
</span></span></code></pre></div><p>So, what changes did tokenization bring to our data? Each review, which was initially a long string of text, is now a list of individual tokens (words, punctuation, etc), which collectively represent the review. In other words, our dataset evolved from being a list of strings to being a list of lists.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i, review <span style="color:#f92672">in</span> enumerate(tokenized_reviews[:<span style="color:#ae81ff">3</span>]):
</span></span><span style="display:flex;"><span>  print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> Review </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> first 10 tokens:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, review[:<span style="color:#ae81ff">10</span>])
</span></span></code></pre></div><p>The output of the above code will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Review <span style="color:#ae81ff">1</span> first <span style="color:#ae81ff">10</span> tokens:
</span></span><span style="display:flex;"><span> [<span style="color:#e6db74">&#39;plot&#39;</span>, <span style="color:#e6db74">&#39;:&#39;</span>, <span style="color:#e6db74">&#39;two&#39;</span>, <span style="color:#e6db74">&#39;teen&#39;</span>, <span style="color:#e6db74">&#39;couples&#39;</span>, <span style="color:#e6db74">&#39;go&#39;</span>, <span style="color:#e6db74">&#39;to&#39;</span>, <span style="color:#e6db74">&#39;a&#39;</span>, <span style="color:#e6db74">&#39;church&#39;</span>, <span style="color:#e6db74">&#39;party&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Review <span style="color:#ae81ff">2</span> first <span style="color:#ae81ff">10</span> tokens:
</span></span><span style="display:flex;"><span> [<span style="color:#e6db74">&#39;the&#39;</span>, <span style="color:#e6db74">&#39;happy&#39;</span>, <span style="color:#e6db74">&#39;bastard&#39;</span>, <span style="color:#e6db74">&#34;&#39;s&#34;</span>, <span style="color:#e6db74">&#39;quick&#39;</span>, <span style="color:#e6db74">&#39;movie&#39;</span>, <span style="color:#e6db74">&#39;review&#39;</span>, <span style="color:#e6db74">&#39;damn&#39;</span>, <span style="color:#e6db74">&#39;that&#39;</span>, <span style="color:#e6db74">&#39;y2k&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Review <span style="color:#ae81ff">3</span> first <span style="color:#ae81ff">10</span> tokens:
</span></span><span style="display:flex;"><span> [<span style="color:#e6db74">&#39;it&#39;</span>, <span style="color:#e6db74">&#39;is&#39;</span>, <span style="color:#e6db74">&#39;movies&#39;</span>, <span style="color:#e6db74">&#39;like&#39;</span>, <span style="color:#e6db74">&#39;these&#39;</span>, <span style="color:#e6db74">&#39;that&#39;</span>, <span style="color:#e6db74">&#39;make&#39;</span>, <span style="color:#e6db74">&#39;a&#39;</span>, <span style="color:#e6db74">&#39;jaded&#39;</span>, <span style="color:#e6db74">&#39;movie&#39;</span>]
</span></span></code></pre></div><h5 id="lesson-summary-and-next-steps">Lesson Summary and Next Steps</h5>
<p>Well done! Today, you learned about the fundamental concept of text tokenization and its importance in text classification. You also applied tokenization to the IMDB movie reviews dataset using Python and NLTK. Your text data is now effectively transformed into a form that machine learning models can digest better.</p>
<p>As you advance in the course, you will refine this dataset further for your text classification objectives. We are laying the foundation one brick at a time, and tokenization was a sturdy one! Upcoming lessons will build upon this understanding. You&rsquo;ll harness this tokenized data to generate Bag-of-Words representations, implement TF-IDF representations, handle sparse features, and apply dimensionality reduction.</p>
<p>Remember, practice consolidates learning. Make sure to reinforce your knowledge by practicing the code samples and applying these concepts contextually. Don&rsquo;t forget to use your creativity to manipulate codes and see the outcomes. Happy learning!</p>
<h2 id="practice-11">ã€ŒPracticeã€</h2>
<p>Good job, Space Voyager! The existing code is intended to tokenize a movie review and filter out punctuation, leaving only word tokens. However, there&rsquo;s a bug causing it to act incorrectly.<br>
å¹²å¾—å¥½ï¼Œå¤ªç©ºæ—…è¡Œè€…ï¼ç°æœ‰ä»£ç æ—¨åœ¨å°†ç”µå½±è¯„è®ºæ ‡è®°åŒ–å¹¶è¿‡æ»¤æ‰æ ‡ç‚¹ç¬¦å·ï¼Œä»…ä¿ç•™å•è¯æ ‡è®°ã€‚ä½†æ˜¯ï¼Œå…¶ä¸­å­˜åœ¨ä¸€ä¸ªé”™è¯¯ï¼Œå¯¼è‡´å…¶è¡Œä¸ºä¸æ­£ç¡®ã€‚</p>
<p>Can you locate the error and adjust the code to correctly execute the task? After your revision, the code should tokenize the first movie review from the dataset, omit any punctuation, and print the first 10 word tokens.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> movie_reviews
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;movie_reviews&#39;</span>, quiet<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the first movie review</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>review_text <span style="color:#f92672">=</span> movie_reviews<span style="color:#f92672">.</span>raw(movie_reviews<span style="color:#f92672">.</span>fileids()[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply tokenization on the review</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenized_review <span style="color:#f92672">=</span> word_tokenize(review_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Should keep only word tokens</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>current_tokens <span style="color:#f92672">=</span> [token <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokenized_review <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> token<span style="color:#f92672">.</span>isalpha()]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the first 10 tokens</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">The first 10 tokens are:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, current_tokens[:<span style="color:#ae81ff">10</span>])
</span></span></code></pre></div><p>è§£é‡Š
ä½ å·²ç»å¾ˆæ¥è¿‘æ­£ç¡®ç­”æ¡ˆäº†ï¼ä»£ç ä¸­åªæœ‰ä¸€ä¸ªå°é”™è¯¯éœ€è¦ä¿®æ­£ã€‚è®©æˆ‘ä»¬ä»”ç»†çœ‹çœ‹è¿™è¡Œä»£ç ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>current_tokens <span style="color:#f92672">=</span> [token <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokenized_review <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> token<span style="color:#f92672">.</span>isalpha()]
</span></span></code></pre></div><p>è¿™è¡Œä»£ç ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æ¥è¿‡æ»¤æ ‡è®°ï¼Œä½†æ¡ä»¶ <code>if not token.isalpha()</code> çš„é€»è¾‘æ˜¯ç›¸åçš„ã€‚<code>isalpha()</code> æ–¹æ³•æ£€æŸ¥ä¸€ä¸ªå­—ç¬¦ä¸²æ˜¯å¦åªåŒ…å«å­—æ¯å­—ç¬¦ã€‚é€šè¿‡ä½¿ç”¨ <code>not</code>ï¼Œå®ƒå®é™…ä¸Šä¿ç•™äº†éå­—æ¯çš„æ ‡è®°ï¼ˆå¦‚æ ‡ç‚¹ç¬¦å·ï¼‰ï¼Œè€Œä¸¢å¼ƒäº†æ‰€æœ‰å•è¯æ ‡è®°ã€‚</p>
<p>ä¸ºäº†ä¿®å¤è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ç§»é™¤ <code>not</code> å…³é”®å­—ï¼Œåƒè¿™æ ·ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>current_tokens <span style="color:#f92672">=</span> [token <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokenized_review <span style="color:#66d9ef">if</span> token<span style="color:#f92672">.</span>isalpha()]
</span></span></code></pre></div><p>ç°åœ¨ï¼Œæ¡ä»¶ <code>if token.isalpha()</code> å°†åªä¿ç•™å­—æ¯å­—ç¬¦çš„æ ‡è®°ï¼Œæœ‰æ•ˆåœ°è¿‡æ»¤æ‰æ ‡ç‚¹ç¬¦å·ã€‚</p>
<p>ä¿®æ”¹åçš„å®Œæ•´ä»£ç å¦‚ä¸‹ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> movie_reviews
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;movie_reviews&#39;</span>, quiet<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the first movie review</span>
</span></span><span style="display:flex;"><span>review_text <span style="color:#f92672">=</span> movie_reviews<span style="color:#f92672">.</span>raw(movie_reviews<span style="color:#f92672">.</span>fileids()[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply tokenization on the review </span>
</span></span><span style="display:flex;"><span>tokenized_review <span style="color:#f92672">=</span> word_tokenize(review_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Should keep only word tokens</span>
</span></span><span style="display:flex;"><span>current_tokens <span style="color:#f92672">=</span> [token <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokenized_review <span style="color:#66d9ef">if</span> token<span style="color:#f92672">.</span>isalpha()]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the first 10 tokens</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">The first 10 tokens are:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, current_tokens[:<span style="color:#ae81ff">10</span>])
</span></span></code></pre></div><p>è¿è¡Œä¿®æ”¹åçš„ä»£ç ï¼Œä½ åº”è¯¥ä¼šçœ‹åˆ°å‰10ä¸ªå•è¯æ ‡è®°æ­£ç¡®åœ°æ‰“å°å‡ºæ¥ï¼Œä¸åŒ…å«ä»»ä½•æ ‡ç‚¹ç¬¦å·ã€‚è¿™æ ·å°±æˆåŠŸåœ°æ ‡è®°åŒ–äº†ç”µå½±è¯„è®ºï¼Œå¹¶è¿‡æ»¤æ‰äº†éå•è¯æ ‡è®°ã€‚</p>
<pre tabindex="0"><code>The first 10 tokens are:  
 [&#39;plot&#39;, &#39;two&#39;, &#39;teen&#39;, &#39;couples&#39;, &#39;go&#39;, &#39;to&#39;, &#39;a&#39;, &#39;church&#39;, &#39;party&#39;, &#39;drink&#39;]
</code></pre><h2 id="practice-12">ã€ŒPracticeã€</h2>
<p>Hey Space Voyager, you&rsquo;re doing great!<br>
å˜¿ï¼Œå¤ªç©ºæ—…è¡Œè€…ï¼Œä½ åšå¾—å¾ˆå¥½ï¼</p>
<p>In the provided starter code, fill in the blanks (<code>____</code>) to convert a given sentence into individual tokens using theÂ <code>nltk</code>Â library. Then, filter out the word tokens, leaving out the punctuation marks.Â è¯·æä¾›éœ€è¦ç¿»è¯‘çš„å®Œæ•´å¥å­ï¼Œæˆ‘æ‰èƒ½å¸®æ‚¨ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡ã€‚ç›®å‰æ‚¨åªæä¾›äº†å¥å­çš„å¼€å¤´ &ldquo;In the p&rdquo;ï¼Œä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç¿»è¯‘ã€‚<br>
åœ¨æä¾›çš„åˆå§‹ä»£ç ä¸­ï¼Œå¡«å†™ç©ºæ ¼ (Â <code>____</code>Â )ï¼Œä½¿ç”¨Â <code>nltk</code>Â åº“å°†ç»™å®šçš„å¥å­è½¬æ¢ä¸ºå•ç‹¬çš„æ ‡è®°ã€‚ç„¶åï¼Œè¿‡æ»¤æ‰å•è¯æ ‡è®°ï¼Œå»æ‰æ ‡ç‚¹ç¬¦å·ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> ____
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Given text</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Who doesn&#39;t enjoy studying Feature Engineering for Text Classification?&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Tokenize the text</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#f92672">=</span> ____(text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Filter out the words</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>words <span style="color:#f92672">=</span> [token <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokens <span style="color:#66d9ef">if</span> token<span style="color:#f92672">.</span>____()]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> Word Tokens:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, words)
</span></span></code></pre></div><h2 id="practice-13">ã€ŒPracticeã€</h2>
<p>Hey Space Voyager, you&rsquo;re doing great!</p>
<p>In the provided starter code, fill in the blanks (<code>____</code>) to convert a given sentence into individual tokens using theÂ <code>nltk</code>Â library. Then, filter out the word tokens, leaving out the punctuation marks.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> ____
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Given text</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Who doesn&#39;t enjoy studying Feature Engineering for Text Classification?&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Tokenize the text</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#f92672">=</span> ____(text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Filter out the words</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>words <span style="color:#f92672">=</span> [token <span style="color:#66d9ef">for</span> token <span style="color:#f92672">in</span> tokens <span style="color:#66d9ef">if</span> token<span style="color:#f92672">.</span>____()]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74"> Word Tokens:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, words)
</span></span></code></pre></div><p>è§£é‡Š</p>
<pre tabindex="0"><code>You&#39;re diving into natural language processing (NLP) with the NLTK library, which is a powerful tool for text analysis! To complete the provided Python code, you need to fill in the blanks to tokenize a given sentence and filter out non-word tokens such as punctuation. Here&#39;s how you can do it:

1. **Import Tokenizer**: First, you need to import the appropriate tokenizer from NLTK. A commonly used tokenizer is `word_tokenize`.

2. **Tokenize the Text**: Use the `word_tokenize` function to split the text into tokens.

3. **Filter Non-Word Tokens**: You&#39;ll need to check if each token is alphabetic to filter out punctuation. The string method `isalpha()` is useful here, as it returns `True` if all characters in the string are alphabetic.

Here&#39;s the completed script:


```python
from nltk import word_tokenize

# Given text
text = &#34;Who doesn&#39;t enjoy studying Feature Engineering for Text Classification?&#34;

# Tokenize the text
tokens = word_tokenize(text)

# Filter out the words
words = [token for token in tokens if token.isalpha()]

print(&#34;\n Word Tokens:\n&#34;, words)
</code></pre><p><strong>Explanation</strong>:</p>
<ul>
<li><strong><code>word_tokenize</code></strong>: This function from NLTK breaks the text into individual words and punctuation.</li>
<li><strong><code>token.isalpha()</code></strong>: This method checks if the token consists only of alphabetic characters, thus effectively filtering out punctuation and numbers.</li>
</ul>
<p>When you run this script, it will print the list of word tokens from the given text, excluding any punctuation marks.</p>
<pre tabindex="0"><code>## ã€ŒPracticeã€
Great job, Voyager! Now, you&#39;re tasked with fine-tuning our weather simulation. Could you modify the initial parameters in theÂ `np.random.normal()`Â function to simulate temperature values that have an average ofÂ `35`Â and a standard deviation ofÂ `10`?

Observe how this alteration impacts theÂ _skewness_Â andÂ _kurtosis_Â of the weather data distribution. Keep up the good work!
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy <span style="color:#f92672">import</span> stats
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>weather_data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, size<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>) <span style="color:#75715e"># A populated weather data (secured from a suitable weather database)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Compute skewness - representing the direction of skew (departure from horizontal symmetry)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>weather_skewness <span style="color:#f92672">=</span> stats<span style="color:#f92672">.</span>skew(weather_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Compute kurtosis - shows the height and sharpness of the data at the center</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>weather_kurtosis <span style="color:#f92672">=</span> stats<span style="color:#f92672">.</span>kurtosis(weather_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Weather Data Skewness: </span><span style="color:#e6db74">{</span>weather_skewness<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Weather Data Kurtosis: </span><span style="color:#e6db74">{</span>weather_kurtosis<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>æ ¹æ®ä½ çš„è¦æ±‚ï¼Œæˆ‘å·²ç»ä¿®æ”¹äº†ä»£ç ï¼Œå°†æ­£æ€åˆ†å¸ƒçš„å‚æ•°ä» <code>loc=30</code>, <code>scale=5</code> è°ƒæ•´åˆ° <code>loc=35</code>, <code>scale=10</code>ã€‚ä¸‹é¢æ˜¯ä¿®æ­£åçš„å®Œæ•´ä»£ç æ®µï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy <span style="color:#f92672">import</span> stats
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># æ›´æ–°å‚æ•°ä»¥æ¨¡æ‹Ÿå¹³å‡å€¼ä¸º35ï¼Œæ ‡å‡†å·®ä¸º10çš„æ¸©åº¦å€¼</span>
</span></span><span style="display:flex;"><span>weather_data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(loc<span style="color:#f92672">=</span><span style="color:#ae81ff">35</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, size<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># è®¡ç®—ååº¦ - è¡¨ç¤ºåç¦»æ°´å¹³å¯¹ç§°çš„æ–¹å‘</span>
</span></span><span style="display:flex;"><span>weather_skewness <span style="color:#f92672">=</span> stats<span style="color:#f92672">.</span>skew(weather_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># è®¡ç®—å³°åº¦ - æ˜¾ç¤ºæ•°æ®ä¸­å¿ƒçš„é«˜åº¦å’Œå°–é”åº¦</span>
</span></span><span style="display:flex;"><span>weather_kurtosis <span style="color:#f92672">=</span> stats<span style="color:#f92672">.</span>kurtosis(weather_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Weather Data Skewness: </span><span style="color:#e6db74">{</span>weather_skewness<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Weather Data Kurtosis: </span><span style="color:#e6db74">{</span>weather_kurtosis<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>è¿™æ®µä»£ç å°†ç”Ÿæˆæ–°çš„å¤©æ°”æ•°æ®ï¼Œå¹¶è®¡ç®—å…¶ååº¦å’Œå³°åº¦ï¼Œä»¥åˆ†ææ•°æ®çš„åˆ†å¸ƒç‰¹æ€§ã€‚å¦‚éœ€è¿›ä¸€æ­¥åˆ†ææˆ–è°ƒæ•´ï¼Œè¯·å‘ŠçŸ¥ï¼</p>
<h2 id="pratice">ã€ŒPraticeã€</h2>
<p>Great job so far, Space Voyager!</p>
<p>Your task now is to fill in the blanks with the correct code to load the IMDB movie reviews dataset. After loading the data, tokenize the first movie review, and print the first 10 tokens of the tokenized review.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> ____ <span style="color:#f92672">import</span> ____
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>____(<span style="color:#e6db74">&#39;movie_reviews&#39;</span>, quiet<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the first movie review</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>review_text <span style="color:#f92672">=</span> ____<span style="color:#f92672">.</span>raw(____<span style="color:#f92672">.</span>fileids()[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply tokenization on the review</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenized_review <span style="color:#f92672">=</span> word_tokenize(review_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the first 10 tokens</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">The first 10 tokens are:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, tokenized_review[:<span style="color:#ae81ff">10</span>])
</span></span></code></pre></div><p>è§£é‡Š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Here<span style="color:#e6db74">&#39;s the completed Python code snippet that correctly fills in the blanks to load the IMDB movie reviews dataset, tokenize the first movie review, and print the first 10 tokens of the tokenized review:</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">```</span>python
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> movie_reviews
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk <span style="color:#f92672">import</span> word_tokenize
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;movie_reviews&#39;</span>, quiet<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;punkt&#39;</span>, quiet<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)  <span style="color:#75715e"># Ensure the tokenizer is available</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the first movie review</span>
</span></span><span style="display:flex;"><span>review_text <span style="color:#f92672">=</span> movie_reviews<span style="color:#f92672">.</span>raw(movie_reviews<span style="color:#f92672">.</span>fileids()[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply tokenization on the review</span>
</span></span><span style="display:flex;"><span>tokenized_review <span style="color:#f92672">=</span> word_tokenize(review_text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the first 10 tokens</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">The first 10 tokens are:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, tokenized_review[:<span style="color:#ae81ff">10</span>])
</span></span></code></pre></div><p>This script downloads the <code>movie_reviews</code> dataset and the necessary tokenizer (<code>punkt</code>). It then loads the text of the first movie review, tokenizes it, and prints the first 10 tokens. If you have any further questions or need more assistance, feel free to ask!</p>
<h1 id="lesson-3">lesson</h1>
<h5 id="introducing-bag-of-words-representation">Introducing Bag-of-Words Representation</h5>
<p>In the world of text analysis, transforming raw data into a format that is both computer-friendly and preserves the essential information for further processing is crucial. One of the simplest yet versatile methods to do this is theÂ <em>Bag-of-Words Representation</em>, or BoW for short.</p>
<p>BoW is essentially a method to extract features from text. Imagine you have a big bag filled with words. These words can come from anywhere: a book, a website, or, in our case, movie reviews from the IMDB dataset. For each document or sentence, the BoW representation will contain the count of how many times each word appears. Most importantly, in this &ldquo;bag,&rdquo; we don&rsquo;t care about the order of words, only their occurrence.</p>
<p>Consider this simple example with three sentences:</p>
<ol>
<li><code>The cat sat on the mat.</code></li>
<li><code>The cat sat near the mat.</code></li>
<li><code>The cat played with a ball.</code></li>
</ol>
<p>Using a BoW representation, our table would look like this:</p>
<table>
  <thead>
      <tr>
          <th></th>
          <th>the</th>
          <th>cat</th>
          <th>sat</th>
          <th>on</th>
          <th>mat</th>
          <th>near</th>
          <th>played</th>
          <th>with</th>
          <th>a</th>
          <th>ball</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1</td>
          <td>2</td>
          <td>1</td>
          <td>1</td>
          <td>1</td>
          <td>1</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
      </tr>
      <tr>
          <td>2</td>
          <td>2</td>
          <td>1</td>
          <td>1</td>
          <td>0</td>
          <td>1</td>
          <td>1</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
      </tr>
      <tr>
          <td>3</td>
          <td>1</td>
          <td>1</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>1</td>
          <td>1</td>
          <td>1</td>
          <td>1</td>
      </tr>
  </tbody>
</table>
<p>Each sentence (document) corresponds to a row, and each unique word is a column. The values in the cells represent the word count in the given sentence.</p>
<h5 id="illustrating-bag-of-words-with-a-simple-example">Illustrating Bag-of-Words with a Simple Example</h5>
<p>We can start practising the Bag-of-Words model by using Scikit-learnÂ <code>CountVectorizer</code>Â on the exact same three sentences:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simple example sentences</span>
</span></span><span style="display:flex;"><span>sentences <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;The cat sat on the mat.&#39;</span>,
</span></span><span style="display:flex;"><span>             <span style="color:#e6db74">&#39;The cat sat near the mat.&#39;</span>,
</span></span><span style="display:flex;"><span>             <span style="color:#e6db74">&#39;The cat played with a ball.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(sentences)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Feature names:&#39;</span>)
</span></span><span style="display:flex;"><span>print(vectorizer<span style="color:#f92672">.</span>get_feature_names_out())
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Bag of Words Representation:&#39;</span>)
</span></span><span style="display:flex;"><span>print(X<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><p>The output of the above code will be:</p>
<pre tabindex="0"><code>Feature names:
[&#39;ball&#39; &#39;cat&#39; &#39;mat&#39; &#39;near&#39; &#39;on&#39; &#39;played&#39; &#39;sat&#39; &#39;the&#39; &#39;with&#39;]
Bag of Words Representation:
[[0 1 1 0 1 0 1 2 0]
 [0 1 1 1 0 0 1 2 0]
 [1 1 0 0 0 1 0 1 1]]
</code></pre><p>From the output, you&rsquo;ll notice that Scikit-learnÂ <code>CountVectorizer</code>Â has done the exact thing as our previous manual process. It&rsquo;s created a Bag-of-Words representation for our sentences where each row corresponds to a sentence and each column to a unique word.</p>
<h5 id="applying-bag-of-words-to-our-dataset">Applying Bag-of-Words to Our Dataset</h5>
<p>Now that we know what Bag-of-Words is and what it does, let&rsquo;s apply it to our dataset:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> nltk
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> nltk.corpus <span style="color:#f92672">import</span> movie_reviews
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nltk<span style="color:#f92672">.</span>download(<span style="color:#e6db74">&#39;movie_reviews&#39;</span>)  
</span></span><span style="display:flex;"><span>reviews <span style="color:#f92672">=</span> [movie_reviews<span style="color:#f92672">.</span>raw(fileid) <span style="color:#66d9ef">for</span> fileid <span style="color:#f92672">in</span> movie_reviews<span style="color:#f92672">.</span>fileids()]
</span></span></code></pre></div><p>In the code snippet above, we utilize Python&rsquo;sÂ <code>NLTK</code>Â module to download and import theÂ <code>IMDB movie reviews dataset</code>.</p>
<p>Next, we&rsquo;ll again use Scikit-learn&rsquo;sÂ <code>CountVectorizer</code>Â to apply the BoW method to our reviews:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>bag_of_words <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(reviews)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;The shape of our Bag-of-Words is: </span><span style="color:#e6db74">{</span>bag_of_words<span style="color:#f92672">.</span>shape<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>The output of the above code will be:</p>
<pre tabindex="0"><code>The shape of our Bag-of-Words is: (2000, 39659)
</code></pre><p>The output indicates that the result is a matrix where each row corresponds to a movie review and each column to a unique word. The entries in this matrix are word counts.</p>
<h5 id="understanding-the-bag-of-words-matrix-and-most-used-word">Understanding the Bag-of-Words Matrix and Most Used Word</h5>
<p>Let&rsquo;s decode what&rsquo;s inside theÂ <code>bag_of_words</code>Â matrix:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>feature_names <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>get_feature_names_out()
</span></span><span style="display:flex;"><span>first_review_word_counts <span style="color:#f92672">=</span> bag_of_words[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>toarray()[<span style="color:#ae81ff">0</span>]
</span></span></code></pre></div><p>Here, we retrieve the feature names (which are unique words in the reviews) from ourÂ <code>CountVectorizer</code>Â model. Then we get the word counts for a specific review - in our case, we chose the first one.</p>
<p>Subsequently, let&rsquo;s find out which word in the first review occurs the most:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>max_count_index <span style="color:#f92672">=</span> first_review_word_counts<span style="color:#f92672">.</span>argmax()
</span></span><span style="display:flex;"><span>most_used_word <span style="color:#f92672">=</span> feature_names[max_count_index]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;The most used word is &#39;</span><span style="color:#e6db74">{</span>most_used_word<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39; with a count of </span><span style="color:#e6db74">{</span>first_review_word_counts[max_count_index]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Running the above code would output something like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>The most used word <span style="color:#f92672">is</span> <span style="color:#e6db74">&#39;the&#39;</span> <span style="color:#66d9ef">with</span> a count of <span style="color:#ae81ff">38</span>
</span></span></code></pre></div><p>The output gives away the most used word in the first review and its count. The script finds the index of the word with the highest count in the first review. Then, it uses this index to identify the corresponding word in theÂ <code>feature_names</code>. This demonstrates how we can identify the most used word in a specific review using the Bag-of-Words model.</p>
<h5 id="lesson-summary-2">Lesson Summary</h5>
<p>Congratulations! You&rsquo;ve successfully made it through this lesson. Today, you&rsquo;ve learned how to implement a significant concept in the world of text classification, theÂ <code>Bag-of-Words</code>Â method. You&rsquo;ve not only understood the theoretical aspect of it, but you also applied it on a real-world dataset using Python. You even used it to extract insights about word frequency, a crucial aspect of many text classification problems.</p>
<p>As we move forward in the upcoming lessons, we&rsquo;ll take what you&rsquo;ve learned today, build on top of it, and continue our journey to understand and apply more advanced text classification techniques. Remember, practice makes perfect, so try to apply what you&rsquo;ve learned today on different text data on your own. Happy coding, and see you in the next lesson!</p>
<p>Start practice</p>
<h2 id="practice-14">ã€ŒPracticeã€</h2>
<p>Great job! Now, let&rsquo;s play around with theÂ <strong>text</strong>. Change the provided sentences to any three sentences of your choice. Then, observe how this affects theÂ <strong>Bag-of-Words</strong>Â representation. Remember, the output should be aÂ <strong>matrix</strong>, with each row representing one of your sentences and each column representing a unique word.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Custom sentences</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sentences <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;The cat sat on the mat.&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;The cat sat near the mat.&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;The cat played with a ball.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(sentences)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Feature names:&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(vectorizer<span style="color:#f92672">.</span>get_feature_names_out())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Bag of Words Representation:&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(X<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><p>è§£é‡Š
Certainly! I&rsquo;ll modify the sentences and show you how it affects the Bag-of-Words representation. Here&rsquo;s the updated code with new sentences:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simple example sentences</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sentences <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Machine learning is fascinating.&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;Deep learning is a subset of machine learning.&#39;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;We use Python for machine learning.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(sentences)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Feature names:&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(vectorizer<span style="color:#f92672">.</span>get_feature_names_out())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;Bag of Words Representation:&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(X<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><p>Let&rsquo;s break down the filled-in parts:</p>
<ol>
<li>
<p>We import <code>CountVectorizer</code> from <code>sklearn.feature_extraction.text</code>.</p>
</li>
<li>
<p>We create an instance of <code>CountVectorizer</code> with <code>vectorizer = CountVectorizer()</code>.</p>
</li>
<li>
<p>We use <code>fit_transform(sentences)</code> to both fit the vectorizer to our sentences (learning the vocabulary) and transform the sentences into a Bag-of-Words representation in one step.</p>
</li>
</ol>
<p>When you run this code, you&rsquo;ll see output similar to this:</p>
<pre tabindex="0"><code>Feature names:
[&#39;deep&#39; &#39;fascinating&#39; &#39;for&#39; &#39;is&#39; &#39;learning&#39; &#39;machine&#39; &#39;of&#39; &#39;python&#39; &#39;subset&#39; &#39;use&#39; &#39;we&#39;]

Bag of Words Representation:
[[0 1 0 1 1 1 0 0 0 0 0]
 [1 0 0 1 2 1 1 0 1 0 0]
 [0 0 1 0 1 1 0 1 0 1 1]]
</code></pre><p>This output shows:</p>
<ol>
<li>The unique words (features) extracted from all sentences.</li>
<li>A matrix where each row represents a sentence, and each column represents a word. The numbers in the matrix indicate how many times each word appears in each sentence.</li>
</ol>
<p>For example, in the second sentence, &rsquo;learning&rsquo; appears twice, which is reflected in the matrix.</p>
<p>This Bag-of-Words representation is a fundamental technique in natural language processing and is often used as a starting point for more complex text analysis tasks. Great job on exploring this concept!</p>
<h1 id="introduction-to-sparse-matrices">Introduction to Sparse Matrices</h1>
<p>Hello and welcome to this lesson onÂ <strong>&ldquo;Efficient Text Data Representation with Sparse Matrices&rdquo;</strong>. As you recall, in our previous lessons, we transformed raw text data into numerical features, for example, using theÂ <em>Bag-of-Words</em>Â (BoW) orÂ <em>Term Frequency-Inverse Document Frequency</em>Â (TF-IDF) techniques. These transformation methods often create what we call &ldquo;Sparse Matrices,&rdquo; an incredibly memory-efficient way of storing high-dimensional data.</p>
<p>Let&rsquo;s break this down a bit. In the context of text data, each unique word across all documents could be treated as a distinct feature. However, each document will only include a small subset of these available features or unique words. Meaning, most entries in our feature matrix end up being 0s, hence resulting in a sparse matrix.</p>
<p>We&rsquo;ll begin with a simple non-text matrix to illustrate sparse matrices and later connect this knowledge to our journey on text data transformation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.sparse <span style="color:#f92672">import</span> csr_matrix, csc_matrix, coo_matrix
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simple example matrix</span>
</span></span><span style="display:flex;"><span>vectors <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">0</span>],
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">6</span>],
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>],
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>],
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>])
</span></span></code></pre></div><h5 id="sparse-matrix-formats-csr">Sparse Matrix Formats: CSR</h5>
<p>In this section, we&rsquo;ll investigate how we can handle sparse matrices in different formats including:Â <em>Compressed Sparse Row</em>Â (CSR),Â <em>Compressed Sparse Column</em>Â (CSC), and theÂ <em>Coordinate</em>Â (COO) formats.</p>
<p>We&rsquo;ll start with the CSR format, a common format for sparse matrices that is excellent for quick arithmetic operations and matrix vector calculations.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># CSR format</span>
</span></span><span style="display:flex;"><span>sparse_csr <span style="color:#f92672">=</span> csr_matrix(vectors)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Compressed Sparse Row (CSR) Matrix:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, sparse_csr)
</span></span></code></pre></div><p>The output of the above code will be:</p>
<pre tabindex="0"><code>Compressed Sparse Row (CSR) Matrix:
   (0, 2)	2
  (0, 3)	3
  (1, 0)	4
  (1, 4)	6
  (4, 1)	7
  (4, 3)	8
Observe that in the output of the Compressed Sparse Row representation, it records the values in the matrix row-wise, starting from the top. Each entry (0, 2), for example, tells us that the element in the 0th row and 2nd column is 2.
</code></pre><p>##Sparse Matrix Formats: CSC</p>
<p>Next, let&rsquo;s convert ourÂ <code>vectors</code>Â matrix to the CSC format. This format, like the CSR format, also forms the backbone of many operations we perform on sparse matrices. But it stores the non-zero entries column-wise, and is especially efficient for column slicing operations.</p>
<pre tabindex="0"><code># CSC format
sparse_csc = csc_matrix(vectors)
print(&#34;Compressed Sparse Column (CSC) Matrix:\n&#34;, sparse_csc)
</code></pre><p>The output of the above code will be:</p>
<pre tabindex="0"><code>Compressed Sparse Column (CSC) Matrix:
   (1, 0)	4
  (4, 1)	7
  (0, 2)	2
  (0, 3)	3
  (4, 3)	8
  (1, 4)	6
</code></pre><p>In this Compressed Sparse Column output, the non-zero entries are stored column-wise. Essentially, CSC format is a transpose of the CSR format.</p>
<h5 id="sparse-matrix-formats-coo">Sparse Matrix Formats: COO</h5>
<p>Lastly, let&rsquo;s convert our example to the COO format or Coordinate List format. The COO format is another useful way to represent a sparse matrix and is simpler compared to CSR or CSC formats.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># COO format</span>
</span></span><span style="display:flex;"><span>sparse_coo <span style="color:#f92672">=</span> coo_matrix(vectors)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Coordinate Format (COO) Matrix:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, sparse_coo)
</span></span></code></pre></div><p>The output of the above code will be:</p>
<pre tabindex="0"><code>Coordinate Format (COO) Matrix:
   (0, 2)	2
  (0, 3)	3
  (1, 0)	4
  (1, 4)	6
  (4, 1)	7
  (4, 3)	8
</code></pre><p>In the COO format, or Coordinate format, the non-zero entries are represented by their own coordinates (row, column). Unlike CSC or CSR, the COO format can contain duplicate entries. This can be particularly useful when data is being accumulated in several passes and there might be instances where duplicate entries are generated. These duplicates are not immediately merged in the COO format, providing you with flexibility for subsequent processing like duplicate resolution.</p>
<h5 id="vectorized-operations-csr-and-csc">Vectorized Operations: CSR and CSC</h5>
<p>Sparse matrices are not just memory-efficient storage mechanisms, but they also allow us to conduct operations directly on them. Specifically, the CSR and CSC formats support these operations directly, whereas the COO format requires converting back to CSR or CSC first.</p>
<p>Let&rsquo;s see this in practice when performing a multiplication operation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Running operations on CSR <span style="color:#f92672">and</span> CSC matrices
</span></span><span style="display:flex;"><span>weighted_csr <span style="color:#f92672">=</span> sparse_csr<span style="color:#f92672">.</span>multiply(<span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Weighted CSR:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, weighted_csr<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><p>The output of the code block above will be:</p>
<pre tabindex="0"><code>Weighted CSR:
 [[0.  0.  1.  1.5 0. ]
 [2.  0.  0.  0.  3. ]
 [0.  3.5 0.  4.  0. ]
 [0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0. ]]
</code></pre><p>We can see the impressive CSR format efficiency in vectorized operations, which becomes crucial when performing calculations with large text data.</p>
<h5 id="vectorized-operations-coo">Vectorized Operations: COO</h5>
<p>And now let&rsquo;s demonstrate the process of performing the same multiplication operation on the COO format, but this time requiring conversion to CSR or CSC first.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Operation on COO requires conversion to CSR or CSC first</span>
</span></span><span style="display:flex;"><span>weighted_coo <span style="color:#f92672">=</span> sparse_coo<span style="color:#f92672">.</span>tocsr()<span style="color:#f92672">.</span>multiply(<span style="color:#ae81ff">0.5</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Weighted COO:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, weighted_coo<span style="color:#f92672">.</span>toarray())
</span></span></code></pre></div><p>The output of the above code will be:</p>
<pre tabindex="0"><code>Weighted COO:
 [[0.  0.  1.  1.5 0. ]
 [2.  0.  0.  0.  3. ]
 [0.  3.5 0.  4.  0. ]
 [0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0. ]]
</code></pre><h5 id="the-connection-between-sparse-matrices-and-nlp">The Connection Between Sparse Matrices and NLP</h5>
<p>After going through the concepts and code, you might ask - what does all this have to do with NLP? Well, remember when we transformed raw text data into either aÂ <em>Bag-of-Words</em>Â or aÂ <em>TF-IDF</em>Â representation in the previous lessons? Each unique word across all documents was treated as a distinct feature. Given the high dimensionality and inherent sparsity of the resulting feature representation, we used sparse matrices for efficient storage.</p>
<p>Handling of sparse matrices becomes crucial in large NLP tasks, as they allow us to operate on large datasets while maintaining computational efficiency and optimal memory usage. Therefore, understanding these different formats of sparse matrices is an essential part of your feature engineering skills for text classification.</p>
<h5 id="lesson-summary-3">Lesson Summary</h5>
<p>Congratulations! Today, you gained an insight into sparse matrices and their different formats, how they help efficiently storing and operating on high dimensional data like that of text records in NLP. You also explored the implications of implementing vectorized operations on different sparse matrix formats. Structuring your learning and understanding these formats is paramount to efficiently handle large datasets in NLP and other machine learning tasks. In the upcoming exercises, you&rsquo;ll get hands-on experience with these concepts, reinforcing your understanding further. Keep up the momentum and dive into practice!</p>
<h5 id="topic-overview-and-actualization">Topic Overview and Actualization</h5>
<p>ä¸»é¢˜æ¦‚è¿°ä¸ç°å®åŒ–</p>
<p>Today, we target duplicates and outliers to clean our data for more accurate analysis.<br>
ä»Šå¤©ï¼Œæˆ‘ä»¬å°†é’ˆå¯¹é‡å¤æ•°æ®å’Œå¼‚å¸¸å€¼è¿›è¡Œæ¸…ç†ï¼Œä»¥ä¾¿è¿›è¡Œæ›´å‡†ç¡®çš„åˆ†æã€‚</p>
<h5 id="understanding-duplicates-in-data">Understanding Duplicates in Data</h5>
<p>ç†è§£æ•°æ®ä¸­çš„é‡å¤é¡¹</p>
<p>Let&rsquo;s consider a dataset from a school containing students&rsquo; details. If a student&rsquo;s information appears more than once, that is regarded as a duplicate. Duplicates distort data, leading to inaccurate statistics.<br>
è€ƒè™‘ä¸€ä¸ªåŒ…å«å­¦ç”Ÿè¯¦ç»†ä¿¡æ¯çš„å­¦æ ¡æ•°æ®é›†ã€‚å¦‚æœä¸€ä¸ªå­¦ç”Ÿçš„èµ„è®¯å‡ºç°å¤šæ¬¡ï¼Œåˆ™è¢«è§†ä¸ºé‡å¤æ•°æ®ã€‚é‡å¤æ•°æ®ä¼šæ‰­æ›²æ•°æ®ï¼Œå¯¼è‡´ç»Ÿè®¡æ•°æ®ä¸å‡†ç¡®ã€‚</p>
<h2 id="practice-15">ã€ŒPracticeã€</h2>
<p>Greetings, Stellar Navigator! For this assignment, we&rsquo;re focusing on model initialization and training. You will find a TODO comment in the provided starter code. Fill it in to define the Naive Bayes model and train it! You&rsquo;ll be able to see the difference between your model&rsquo;s prediction and the actual results visually on a scatter plot. Let&rsquo;s dive in!
ä½ å¥½ï¼Œæ˜Ÿé™…é¢†èˆªå‘˜ï¼æœ¬æ¬¡ä½œä¸šçš„é‡ç‚¹æ˜¯æ¨¡å‹åˆå§‹åŒ–å’Œè®­ç»ƒã€‚ä½ ä¼šåœ¨æä¾›çš„åˆå§‹ä»£ç ä¸­æ‰¾åˆ°ä¸€ä¸ª TODO æ³¨é‡Šã€‚è¯·å®Œæˆæ³¨é‡Šå†…å®¹ï¼Œå®šä¹‰æœ´ç´ è´å¶æ–¯æ¨¡å‹å¹¶å¯¹å…¶è¿›è¡Œè®­ç»ƒï¼ä½ å°†èƒ½å¤Ÿåœ¨æ•£ç‚¹å›¾ä¸Šç›´è§‚åœ°çœ‹åˆ°ä½ çš„æ¨¡å‹é¢„æµ‹ç»“æœä¸å®é™…ç»“æœä¹‹é—´çš„å·®å¼‚ã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import the necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.naive_bayes <span style="color:#f92672">import</span> MultinomialNB
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_dataset(<span style="color:#e6db74">&#39;codesignal/sms-spam-collection&#39;</span>, split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(spam_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define X (input features) and Y (output labels)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;message&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;label&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform the train test split using stratified cross-validation</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train, X_test, Y_train, Y_test <span style="color:#f92672">=</span> train_test_split(X, Y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, stratify<span style="color:#f92672">=</span>Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the CountVectorizer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>count_vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit and transform the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>fit_transform(X_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Transform the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_test_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>transform(X_test)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Initialize the MultinomialNB model and fit it on the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>naive_bayes_model <span style="color:#f92672">=</span> MultinomialNB()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>naive_bayes_model<span style="color:#f92672">.</span>fit(X_train_count, Y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make predictions on the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Y_pred <span style="color:#f92672">=</span> naive_bayes_model<span style="color:#f92672">.</span>predict(X_test_count)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a DataFrame with actual and predicted labels</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>results_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#34;Actual&#34;</span>: Y_test, <span style="color:#e6db74">&#34;Predicted&#34;</span>: Y_pred})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># We now generate indices for our scatter plot for clarity</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>indices <span style="color:#f92672">=</span> range(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">51</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plotting the comparison scatter plot for the first 50 messages</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot actual labels</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(indices, results_df[<span style="color:#e6db74">&#34;Actual&#34;</span>]<span style="color:#f92672">.</span>values[:<span style="color:#ae81ff">50</span>], edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;b&#39;</span>, facecolors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;none&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Actual&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot predicted labels</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(indices, results_df[<span style="color:#e6db74">&#34;Predicted&#34;</span>]<span style="color:#f92672">.</span>values[:<span style="color:#ae81ff">50</span>], edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;none&#39;</span>,color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;r&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Predicted&#39;</span>, marker<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;x&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>yticks([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], [<span style="color:#e6db74">&#39;Ham&#39;</span>, <span style="color:#e6db74">&#39;Spam&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Category&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;Message Number&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Actual vs Predicted Labels for First 50 Messages&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><h2 id="practice-16">ã€ŒPracticeã€</h2>
<p>äº²çˆ±çš„å¤ªç©ºæ—…è¡Œè€…ï¼Œä½ çš„æŠ€èƒ½å†æ¬¡è¢«éœ€è¦ï¼åˆ©ç”¨ä½ æ‰€å­¦åˆ°çš„å…³äºæœ´ç´ è´å¶æ–¯æ¨¡å‹çš„çŸ¥è¯†ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä½¿ç”¨æ··æ·†çŸ©é˜µè¯„ä¼°ä½ çš„æ¨¡å‹ã€‚å®ç°æœ´ç´ è´å¶æ–¯æ¨¡å‹ï¼Œè¿›è¡Œé¢„æµ‹ï¼Œç„¶åä½¿ç”¨æµ‹è¯•æ•°æ®ä¸ºæ¨¡å‹ç”Ÿæˆæ··æ·†çŸ©é˜µã€‚ç»˜åˆ¶æ··æ·†çŸ©é˜µçš„ç»“æœä»¥è¿›è¡Œè§†è§‰è¯„ä¼°ã€‚Dear Space Voyager, your skills are needed once again! Using what you&rsquo;ve learned about theÂ <strong>Naive Bayes Model</strong>, your mission is to evaluate your model using aÂ <strong>confusion matrix</strong>. Implement theÂ <strong>Naive Bayes model</strong>, make predictions, and then generate a confusion matrix for the model using the test data. Plot the results of the confusion matrix for visual assessment.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import the necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.naive_bayes <span style="color:#f92672">import</span> MultinomialNB
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> seaborn <span style="color:#66d9ef">as</span> sns
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_dataset(<span style="color:#e6db74">&#39;codesignal/sms-spam-collection&#39;</span>, split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(spam_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define X (input features) and Y (output labels)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;message&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;label&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform the train test split using stratified cross-validation</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train, X_test, Y_train, Y_test <span style="color:#f92672">=</span> train_test_split(X, Y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, stratify<span style="color:#f92672">=</span>Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Initialize the CountVectorizer and fit and transform the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Transform the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Initialize the MultinomialNB model</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Fit the model on the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Make predictions on the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate confusion matrix</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(Y_test, Y_pred)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a DataFrame with confusion matrix</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>confusion_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(confusion_matrix, index<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;ham&#39;</span>, <span style="color:#e6db74">&#39;spam&#39;</span>], columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;ham&#39;</span>, <span style="color:#e6db74">&#39;spam&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the confusion DataFrame</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(confusion_df)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot the confusion matrix</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sns<span style="color:#f92672">.</span>heatmap(confusion_df, annot<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, fmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;d&#39;</span>, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Blues&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p>è§£é‡Š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import the necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.naive_bayes <span style="color:#f92672">import</span> MultinomialNB
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> seaborn <span style="color:#66d9ef">as</span> sns
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_dataset(<span style="color:#e6db74">&#39;codesignal/sms-spam-collection&#39;</span>, split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(spam_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define X (input features) and Y (output labels)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;message&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;label&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform the train test split using stratified cross-validation</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train, X_test, Y_train, Y_test <span style="color:#f92672">=</span> train_test_split(X, Y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, stratify<span style="color:#f92672">=</span>Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Initialize the CountVectorizer and fit and transform the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>count_vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>fit_transform(X_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Transform the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_test_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>transform(X_test)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Initialize the MultinomialNB model</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>naive_bayes_model <span style="color:#f92672">=</span> MultinomialNB()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Fit the model on the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>naive_bayes_model<span style="color:#f92672">.</span>fit(X_train_count, Y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># TODO: Make predictions on the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Y_pred <span style="color:#f92672">=</span> naive_bayes_model<span style="color:#f92672">.</span>predict(X_test_count)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate confusion matrix</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>confusion_matrix <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>confusion_matrix(Y_test, Y_pred)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a DataFrame with confusion matrix</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>confusion_df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(confusion_matrix, index<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;ham&#39;</span>, <span style="color:#e6db74">&#39;spam&#39;</span>], columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;ham&#39;</span>, <span style="color:#e6db74">&#39;spam&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the confusion DataFrame</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(confusion_df)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot the confusion matrix</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sns<span style="color:#f92672">.</span>heatmap(confusion_df, annot<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, fmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;d&#39;</span>, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Blues&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p>å¥½çš„,è®©æˆ‘ä»¬ç”¨æ›´ç®€å•çš„æ–¹å¼,ç»™5å²çš„å°æœ‹å‹è§£é‡Šè¿™ä¸ªæœ‰è¶£çš„æ¸¸æˆ: 1. æƒ³è±¡ä½ æœ‰ä¸€å¤§å †ä¿¡ä»¶ã€‚æœ‰äº›æ˜¯å¥½æœ‹å‹å†™çš„,æœ‰äº›æ˜¯åäººå¯„æ¥çš„éª—äººçš„ä¿¡ã€‚ 2. æˆ‘ä»¬è¦æ•™ä¸€ä¸ªæœºå™¨äººæœ‹å‹åˆ†è¾¨å“ªäº›æ˜¯å¥½ä¿¡,å“ªäº›æ˜¯åä¿¡ã€‚ 3. é¦–å…ˆ,æˆ‘ä»¬ç»™æœºå™¨äººä¸€äº›ä¿¡çœ‹,å‘Šè¯‰å®ƒå“ªäº›æ˜¯å¥½çš„,å“ªäº›æ˜¯åçš„ã€‚è¿™å°±åƒæ•™ä½ åˆ†è¾¨è‹¹æœå’Œæ©˜å­ã€‚ 4. ç„¶å,æˆ‘ä»¬ç»™æœºå™¨äººä¸€äº›æ–°çš„ä¿¡,çœ‹å®ƒèƒ½ä¸èƒ½çŒœå¯¹æ˜¯å¥½ä¿¡è¿˜æ˜¯åä¿¡ã€‚ 5. æœ€å,æˆ‘ä»¬ç”»äº†ä¸€ä¸ªæœ‰é¢œè‰²çš„å›¾ç”»: - è“è‰²çš„æ ¼å­è¶Šæ·±,è¯´æ˜æœºå™¨äººçŒœå¯¹çš„æ¬¡æ•°è¶Šå¤šã€‚ - æµ…è‰²çš„æ ¼å­è¯´æ˜æœºå™¨äººæœ‰æ—¶å€™ä¼šçŒœé”™ã€‚ 6. å¦‚æœå›¾ç”»ä¸Šæ·±è“è‰²çš„æ ¼å­å¤š,æµ…è‰²çš„æ ¼å­å°‘,å°±è¯´æ˜æˆ‘ä»¬çš„æœºå™¨äººæœ‹å‹å­¦å¾—å¾ˆå¥½! è¿™å°±åƒæ•™ä½ çš„ç©å…·æœºå™¨äººåˆ†è¾¨å¥½ä¸œè¥¿å’Œåä¸œè¥¿ã€‚å¦‚æœå®ƒå­¦å¾—å¥½,å°±èƒ½å¸®æˆ‘ä»¬æ‰¾å‡ºé‚£äº›éª—äººçš„åä¿¡,ä¿æŠ¤æˆ‘ä»¬ä¸å—éª—ã€‚æ˜¯ä¸æ˜¯å¾ˆç¥å¥‡å‘€?</p>
<pre tabindex="0"><code>å¥½çš„,æˆ‘æ¥å°è¯•ç”¨ç®€å•çš„è¯­è¨€è§£é‡Šè¿™æ®µä»£ç ,è®©ä¸‰å¹´çº§çš„å°æœ‹å‹ä¹Ÿèƒ½ç†è§£: 1. é¦–å…ˆ,æˆ‘ä»¬æœ‰ä¸€å †çŸ­ä¿¡ã€‚æœ‰äº›æ˜¯æ­£å¸¸çš„çŸ­ä¿¡,æœ‰äº›æ˜¯åƒåœ¾çŸ­ä¿¡ã€‚æˆ‘ä»¬æƒ³æ•™ç”µè„‘åˆ†è¾¨å“ªäº›æ˜¯åƒåœ¾çŸ­ä¿¡ã€‚ 2. æˆ‘ä»¬æŠŠè¿™äº›çŸ­ä¿¡åˆ†æˆä¸¤ç»„:ä¸€ç»„ç”¨æ¥æ•™ç”µè„‘,å¦ä¸€ç»„ç”¨æ¥æµ‹è¯•ç”µè„‘å­¦å¾—æ€ä¹ˆæ ·ã€‚ 3. æ¥ä¸‹æ¥,æˆ‘ä»¬è¦æŠŠçŸ­ä¿¡å˜æˆæ•°å­—,å› ä¸ºç”µè„‘æ›´æ“…é•¿å¤„ç†æ•°å­—ã€‚æˆ‘ä»¬æ•°ä¸€æ•°æ¯ä¸ªçŸ­ä¿¡é‡Œæœ‰å“ªäº›è¯,å‡ºç°äº†å¤šå°‘æ¬¡ã€‚ 4. ç„¶å,æˆ‘ä»¬ç”¨ä¸€ç§å«&#34;æœ´ç´ è´å¶æ–¯&#34;çš„æ–¹æ³•æ¥æ•™ç”µè„‘ã€‚è¿™å°±åƒæ•™ç”µè„‘ç©ä¸€ä¸ªçŒœè°œæ¸¸æˆã€‚ 5. æ•™å®Œä¹‹å,æˆ‘ä»¬è®©ç”µè„‘çŒœæµ‹é‚£äº›æµ‹è¯•ç”¨çš„çŸ­ä¿¡æ˜¯ä¸æ˜¯åƒåœ¾çŸ­ä¿¡ã€‚ 6. æœ€å,æˆ‘ä»¬çœ‹çœ‹ç”µè„‘çŒœå¾—å¯¹ä¸å¯¹ã€‚æˆ‘ä»¬ç”»äº†ä¸€ä¸ªè¡¨æ ¼: - å·¦ä¸Šè§’çš„æ•°å­—æ˜¯ç”µè„‘æ­£ç¡®åœ°è¯´&#34;è¿™ä¸æ˜¯åƒåœ¾çŸ­ä¿¡&#34;çš„æ¬¡æ•°ã€‚ - å³ä¸Šè§’æ˜¯ç”µè„‘é”™è¯¯åœ°è¯´&#34;è¿™æ˜¯åƒåœ¾çŸ­ä¿¡&#34;çš„æ¬¡æ•°ã€‚ - å·¦ä¸‹è§’æ˜¯ç”µè„‘é”™è¯¯åœ°è¯´&#34;è¿™ä¸æ˜¯åƒåœ¾çŸ­ä¿¡&#34;çš„æ¬¡æ•°ã€‚ - å³ä¸‹è§’æ˜¯ç”µè„‘æ­£ç¡®åœ°è¯´&#34;è¿™æ˜¯åƒåœ¾çŸ­ä¿¡&#34;çš„æ¬¡æ•°ã€‚ 7. æˆ‘ä»¬è¿˜ç”»äº†ä¸€ä¸ªå½©è‰²çš„å›¾,é¢œè‰²è¶Šæ·±çš„åœ°æ–¹,æ•°å­—è¶Šå¤§ã€‚è¿™æ ·æˆ‘ä»¬ä¸€çœ¼å°±èƒ½çœ‹å‡ºç”µè„‘å­¦å¾—å¥½ä¸å¥½ã€‚ é€šè¿‡è¿™ä¸ªæ¸¸æˆ,æˆ‘ä»¬æ•™ä¼šäº†ç”µè„‘åˆ†è¾¨åƒåœ¾çŸ­ä¿¡,å°±åƒæ•™å°æœ‹å‹åˆ†è¾¨å¥åº·é£Ÿç‰©å’Œåƒåœ¾é£Ÿå“ä¸€æ ·!

##A Brief Introduction to Support Vector Machines (SVM)  
æ”¯æŒå‘é‡æœº (SVM) ç®€ä»‹

In machine learning,Â **Support Vector Machines**Â (SVMs) are classification algorithms that you can use to label data into different classes. TheÂ `SVM`Â algorithm segregates data into two groups by finding a hyperplane in a high-dimensional space (or surface, in case of more than two features) that distinctly classifies the data points. The algorithm chooses the hyperplane that represents the largest separation, or margin, between classes.  
åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæ”¯æŒå‘é‡æœº (SVM) æ˜¯ä¸€ç§åˆ†ç±»ç®—æ³•ï¼Œå¯ç”¨äºå°†æ•°æ®æ ‡è®°åˆ°ä¸åŒçš„ç±»åˆ«ä¸­ã€‚SVM ç®—æ³•é€šè¿‡åœ¨é«˜ç»´ç©ºé—´ï¼ˆå¦‚æœç‰¹å¾è¶…è¿‡ä¸¤ä¸ªï¼Œåˆ™ä¸ºæ›²é¢ï¼‰ä¸­æ‰¾åˆ°ä¸€ä¸ªèƒ½å¤Ÿæ¸…æ™°åœ°åŒºåˆ†æ•°æ®ç‚¹çš„è¶…å¹³é¢ï¼Œå°†æ•°æ®åˆ†æˆä¸¤ç»„ã€‚è¯¥ç®—æ³•é€‰æ‹©èƒ½å¤Ÿä»£è¡¨ç±»åˆ«ä¹‹é—´æœ€å¤§é—´éš”ï¼ˆæˆ–ç§°â€œè¾¹é™…â€ï¼‰çš„è¶…å¹³é¢ã€‚

`SVM`Â is extremely useful for solving nonlinear text classification problems. It can efficiently perform a non-linear classification using theÂ _&#34;kernel trick,&#34;_Â implicitly mapping the inputs into high-dimensional feature spaces.  
æ”¯æŒå‘é‡æœº (SVM) å¯¹äºè§£å†³éçº¿æ€§æ–‡æœ¬åˆ†ç±»é—®é¢˜éå¸¸æœ‰æ•ˆã€‚å®ƒå¯ä»¥é€šè¿‡â€œæ ¸æŠ€å·§â€æœ‰æ•ˆåœ°æ‰§è¡Œéçº¿æ€§åˆ†ç±»ï¼Œå°†è¾“å…¥éšå¼æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ç©ºé—´ã€‚

In summary,Â `SVM`&#39;s distinguishing factors are:  
ç»¼ä¸Šæ‰€è¿°ï¼Œæ”¯æŒå‘é‡æœºçš„æ˜¾è‘—ç‰¹ç‚¹æ˜¯ï¼š

- **Hyperplanes**: These are decision boundaries that helpÂ `SVM`Â separate data into different classes.  
    è¶…å¹³é¢ï¼šè¿™äº›æ˜¯å¸®åŠ© SVM å°†æ•°æ®åˆ†æˆä¸åŒç±»åˆ«çš„å†³ç­–è¾¹ç•Œã€‚
- **Support Vectors**: These are the data points that lie closest to the decision surface (or hyperplane). They are critical elements ofÂ `SVM`Â because they help maximize the margin of the classifier.  
    æ”¯æŒå‘é‡ï¼šè¿™äº›æ•°æ®ç‚¹æœ€æ¥è¿‘å†³ç­–é¢ï¼ˆæˆ–è¶…å¹³é¢ï¼‰ã€‚å®ƒä»¬æ˜¯æ”¯æŒå‘é‡æœºçš„å…³é”®è¦ç´ ï¼Œå› ä¸ºå®ƒä»¬æœ‰åŠ©äºæœ€å¤§åŒ–åˆ†ç±»å™¨çš„è¾¹ç•Œã€‚
- **Kernel Trick**: The kernel helpsÂ `SVM`Â to deal with non-linear input spaces by using a higher dimension space.  
    æ ¸æŠ€å·§ï¼šæ ¸å‡½æ•°é€šè¿‡å°†æ•°æ®æ˜ å°„åˆ°æ›´é«˜ç»´ç©ºé—´ï¼Œå¸®åŠ©æ”¯æŒå‘é‡æœºå¤„ç†éçº¿æ€§è¾“å…¥ç©ºé—´ã€‚
- **Soft Margin**:Â `SVM`Â allows some misclassifications in its model for better performance. This flexibility is introduced through a concept called Soft Margin.  
    è½¯é—´éš”ï¼šä¸ºäº†è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼ŒSVM å…è®¸æ¨¡å‹ä¸­å­˜åœ¨ä¸€äº›é”™è¯¯åˆ†ç±»ã€‚è¿™ç§çµæ´»æ€§æ˜¯é€šè¿‡ç§°ä¸ºè½¯é—´éš”çš„æ¦‚å¿µå¼•å…¥çš„ã€‚```
    ### Loading and Preprocessing the Data

This section is a quick revisit of the code you are already familiar with. We are just loading and preprocessing theÂ _SMS Spam Collection_Â dataset.
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import the necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.svm <span style="color:#f92672">import</span> SVC
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_dataset(<span style="color:#e6db74">&#39;codesignal/sms-spam-collection&#39;</span>, split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(spam_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define X (input features) and Y (output labels)</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;message&#34;</span>]
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;label&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform the train test split using stratified cross-validation</span>
</span></span><span style="display:flex;"><span>X_train, X_test, Y_train, Y_test <span style="color:#f92672">=</span> train_test_split(X, Y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, stratify<span style="color:#f92672">=</span>Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the CountVectorizer</span>
</span></span><span style="display:flex;"><span>count_vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit and transform the training data </span>
</span></span><span style="display:flex;"><span>X_train_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>fit_transform(X_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Transform the test data</span>
</span></span><span style="display:flex;"><span>X_test_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>transform(X_test)
</span></span></code></pre></div><h5 id="implementing-support-vector-machines-for-text-classification">Implementing Support Vector Machines for Text Classification</h5>
<p>Let&rsquo;s delve into the practical implementation ofÂ <code>SVM</code>Â for text classification using theÂ <code>Scikit-learn</code>Â library. We are going to introduce a newÂ <code>Scikit-learn</code>Â function,Â <code>SVC()</code>. This function is used to fit theÂ <code>SVM</code>Â model according to the given training data.</p>
<p>In the following Python code, we initialize theÂ <code>SVC</code>Â model, fit it with our training data, and then make predictions on the test dataset.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Initialize the SVC model</span>
</span></span><span style="display:flex;"><span>svm_model <span style="color:#f92672">=</span> SVC()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit the model on the training data</span>
</span></span><span style="display:flex;"><span>svm_model<span style="color:#f92672">.</span>fit(X_train_count, Y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make predictions on the test data</span>
</span></span><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> svm_model<span style="color:#f92672">.</span>predict(X_test_count)
</span></span></code></pre></div><p>TheÂ <code>SVC</code>Â function takes several parameters, with the key ones being:</p>
<ul>
<li><code>C</code>: This is the penalty parameter of the error term. It controls the trade off between smooth decision boundary and classifying training points correctly.</li>
<li><code>kernel</code>: Specifies the kernel type to be used in the algorithm. It can be &rsquo;linear&rsquo;, &lsquo;poly&rsquo;, &lsquo;rbf&rsquo;, &lsquo;sigmoid&rsquo;, &lsquo;precomputed&rsquo; or a callable.</li>
<li><code>degree</code>: Degree of the polynomial kernel function (&lsquo;poly&rsquo;). Ignored by all other kernels.</li>
<li>
<h5 id="making-predictions-and-evaluating-the-svm-model">Making Predictions and Evaluating the SVM Model</h5>
</li>
</ul>
<p>è¿›è¡Œé¢„æµ‹å’Œè¯„ä¼°æ”¯æŒå‘é‡æœºæ¨¡å‹</p>
<p>After building the model, the next step is to use it on unseen data and evaluate its performance. The python code for this step is shown below:<br>
æ¨¡å‹æ„å»ºå®Œæˆåï¼Œä¸‹ä¸€æ­¥æ˜¯åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šä½¿ç”¨è¯¥æ¨¡å‹å¹¶è¯„ä¼°å…¶æ€§èƒ½ã€‚ä¸‹é¢å±•ç¤ºäº†æ­¤æ­¥éª¤çš„ Python ä»£ç ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Make predictions on the test data</span>
</span></span><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> svm_model<span style="color:#f92672">.</span>predict(X_test_count)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate the accuracy of the model</span>
</span></span><span style="display:flex;"><span>accuracy <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>accuracy_score(Y_test, y_pred)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the accuracy</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Accuracy of Support Vector Machines Classifier: </span><span style="color:#e6db74">{</span>accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>The output of the above code will be:<br>
ä»¥ä¸Šä»£ç çš„è¾“å‡ºç»“æœä¸ºï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Accuracy of Support Vector Machines Classifier: <span style="color:#ae81ff">0.98</span>
</span></span></code></pre></div><p>This output signifies that ourÂ <code>SVM</code>Â model has achieved a high accuracy, specifically 98%, in classifying messages as spam or ham, highlighting its effectiveness in text classification tasks.<br>
æ­¤ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ”¯æŒå‘é‡æœº (SVM) æ¨¡å‹åœ¨å°†é‚®ä»¶åˆ†ç±»ä¸ºåƒåœ¾é‚®ä»¶æˆ–éåƒåœ¾é‚®ä»¶æ–¹é¢è¾¾åˆ°äº† 98% çš„é«˜å‡†ç¡®ç‡ï¼Œå‡¸æ˜¾äº†å…¶åœ¨æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<h5 id="lesson-summary-and-upcoming-practice">Lesson Summary and Upcoming Practice</h5>
<p>è¯¾ç¨‹æ€»ç»“å’Œå³å°†è¿›è¡Œçš„ç»ƒä¹ </p>
<p>Congratulations on making it to the end of this lesson! You have now learned the theory behindÂ <strong>Support Vector Machines</strong>Â (SVMs) and how to use them to perform text classification in Python. You&rsquo;ve also learned to load and preprocess the data, build theÂ <code>SVM</code>Â model, and evaluate its accuracy.<br>
æ­å–œä½ å®Œæˆäº†æœ¬è¯¾çš„å­¦ä¹ ï¼ä½ ç°åœ¨å·²ç»å­¦ä¹ äº†æ”¯æŒå‘é‡æœº (SVM) èƒŒåçš„ç†è®ºï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬åœ¨ Python ä¸­æ‰§è¡Œæ–‡æœ¬åˆ†ç±»ã€‚ä½ è¿˜å­¦ä¹ äº†å¦‚ä½•åŠ è½½å’Œé¢„å¤„ç†æ•°æ®ã€æ„å»º SVM æ¨¡å‹ä»¥åŠè¯„ä¼°å…¶å‡†ç¡®æ€§ã€‚
Remember, like any other skill, programming requires practice. The upcoming practice exercises will allow you to reinforce the knowledge you&rsquo;ve acquired in this lesson. They have been carefully designed to give you further expertise inÂ <code>SVM</code>Â and text classification. Good luck! You&rsquo;re doing a great job, and I&rsquo;m excited to see you in the next lesson on Decision Trees for text classification.<br>
è®°ä½ï¼Œç¼–ç¨‹å’Œå…¶ä»–æŠ€èƒ½ä¸€æ ·ï¼Œéƒ½éœ€è¦ç»ƒä¹ ã€‚æ¥ä¸‹æ¥çš„ç»ƒä¹ å°†å¸®åŠ©ä½ å·©å›ºåœ¨æœ¬èŠ‚è¯¾ä¸­å­¦åˆ°çš„çŸ¥è¯†ã€‚è¿™äº›ç»ƒä¹ ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œæ—¨åœ¨è®©ä½ è¿›ä¸€æ­¥æŒæ¡æ”¯æŒå‘é‡æœºå’Œæ–‡æœ¬åˆ†ç±»æ–¹é¢çš„çŸ¥è¯†ã€‚ç¥ä½ å¥½è¿ï¼ä½ åšå¾—å¾ˆå¥½ï¼Œæˆ‘æœŸå¾…åœ¨ä¸‹ä¸€èŠ‚å…³äºå†³ç­–æ ‘æ–‡æœ¬åˆ†ç±»çš„è¯¾ç¨‹ä¸­è§åˆ°ä½ ã€‚</p>
<p>Certainly! I&rsquo;ll modify the code to use the polynomial kernel (&lsquo;poly&rsquo;) instead of the linear kernel for the SVM model. Here&rsquo;s the adjusted code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import the necessary libraries </span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd 
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer <span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics <span style="color:#f92672">from</span> sklearn.svm <span style="color:#f92672">import</span> SVC <span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split <span style="color:#f92672">import</span> datasets <span style="color:#75715e"># Load the dataset spam_dataset = datasets.load_dataset(&#39;codesignal/sms-spam-collection&#39;, split=&#39;train&#39;) spam_dataset = pd.DataFrame(spam_dataset) # Define X (input features) and Y (output labels) X = spam_dataset[&#34;message&#34;] Y = spam_dataset[&#34;label&#34;] # Perform the train test split using stratified cross-validation X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y) # Initialize the CountVectorizer count_vectorizer = CountVectorizer() # Fit and transform the training data X_train_count = count_vectorizer.fit_transform(X_train) # Transform the test data X_test_count = count_vectorizer.transform(X_test) # Initialize the SVC model with &#39;poly&#39; kernel svm_model = SVC(kernel=&#39;poly&#39;) # Fit the model on the training data svm_model.fit(X_train_count, Y_train) # Make predictions on the test data y_pred = svm_model.predict(X_test_count) # Calculate the accuracy of the model accuracy = metrics.accuracy_score(Y_test, y_pred) # Print the accuracy print(f&#34;Accuracy of Support Vector Machines Classifier with polynomial kernel: {accuracy:.2f}&#34;)</span>
</span></span></code></pre></div><p>å¥½çš„,æˆ‘ä¼šå°è¯•ç”¨ç®€å•çš„è¯­è¨€æ¥è§£é‡Šè¿™æ®µä»£ç ,å°±åƒæ˜¯åœ¨è·Ÿ6å²çš„å°æœ‹å‹è®²æ•…äº‹ä¸€æ ·ã€‚ æƒ³è±¡ä¸€ä¸‹,æˆ‘ä»¬æœ‰ä¸€ä¸ªç¥å¥‡çš„æœºå™¨äººæœ‹å‹,å®ƒå¯ä»¥å¸®æˆ‘ä»¬åˆ†è¾¨çŸ­ä¿¡æ˜¯ä¸æ˜¯åƒåœ¾çŸ­ä¿¡ã€‚æˆ‘ä»¬è¦æ•™è¿™ä¸ªæœºå™¨äººæ€ä¹ˆåšåˆ°è¿™ä¸€ç‚¹ã€‚è¿™å°±æ˜¯è¿™æ®µä»£ç è¦åšçš„äº‹æƒ…ã€‚ 1. é¦–å…ˆ,æˆ‘ä»¬éœ€è¦ç»™æœºå™¨äººä¸€äº›å·¥å…·ã€‚è¿™äº›å·¥å…·å°±åƒæ˜¯æœºå™¨äººçš„çœ¼ç›å’Œå¤§è„‘,å¸®å®ƒçœ‹ä¸œè¥¿å’Œæ€è€ƒã€‚ 2. ç„¶å,æˆ‘ä»¬ç»™æœºå™¨äººä¸€å¤§å †çŸ­ä¿¡ã€‚æœ‰äº›æ˜¯å¥½çŸ­ä¿¡,æœ‰äº›æ˜¯åçŸ­ä¿¡(åƒåœ¾çŸ­ä¿¡)ã€‚ 3. æˆ‘ä»¬æŠŠè¿™äº›çŸ­ä¿¡åˆ†æˆä¸¤éƒ¨åˆ†:ä¸€éƒ¨åˆ†ç”¨æ¥æ•™æœºå™¨äºº,å¦ä¸€éƒ¨åˆ†ç”¨æ¥æµ‹è¯•æœºå™¨äººå­¦å¾—æ€ä¹ˆæ ·ã€‚ 4. æ¥ä¸‹æ¥,æˆ‘ä»¬æ•™æœºå™¨äººçœ‹çŸ­ä¿¡ã€‚æˆ‘ä»¬å‘Šè¯‰å®ƒè¦æ³¨æ„çŸ­ä¿¡é‡Œçš„æ¯ä¸ªå­—,å°±åƒä½ åœ¨å­¦ä¹ è®¤å­—ä¸€æ ·ã€‚ 5. ç°åœ¨,æˆ‘ä»¬è¦æ•™æœºå™¨äººä¸€ä¸ªç‰¹æ®Šçš„æŠ€èƒ½,å«åš&quot;å¤šé¡¹å¼æ ¸&quot;ã€‚è¿™ä¸ªæŠ€èƒ½å¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£æ›´å¤æ‚çš„çŸ­ä¿¡å†…å®¹ã€‚ 6. æœºå™¨äººå¼€å§‹å­¦ä¹ äº†!å®ƒä»”ç»†çœ‹æ¯ä¸€æ¡æ•™å®ƒçš„çŸ­ä¿¡,åŠªåŠ›è®°ä½å“ªäº›æ˜¯å¥½çŸ­ä¿¡,å“ªäº›æ˜¯åçŸ­ä¿¡ã€‚ 7. å­¦ä¹ å®Œå,æˆ‘ä»¬ç»™æœºå™¨äººä¸€äº›æ–°çš„çŸ­ä¿¡,çœ‹å®ƒèƒ½ä¸èƒ½æ­£ç¡®åˆ†è¾¨å‡ºå“ªäº›æ˜¯åƒåœ¾çŸ­ä¿¡ã€‚ 8. æœ€å,æˆ‘ä»¬è¦ç»™æœºå™¨äººæ‰“åˆ†ã€‚å¦‚æœå®ƒçŒœå¯¹äº†å¾ˆå¤š,å°±è¯´æ˜å®ƒå­¦å¾—å¾ˆå¥½! 9. æˆ‘ä»¬æŠŠæœºå™¨äººçš„åˆ†æ•°æ‰“å°å‡ºæ¥,çœ‹çœ‹å®ƒå­¦å¾—æ€ä¹ˆæ ·ã€‚ è¿™å°±æ˜¯æ•´ä¸ªè¿‡ç¨‹å•¦!æˆ‘ä»¬æ•™ä¼šäº†æœºå™¨äººæœ‹å‹ä¸€ä¸ªæ–°æŠ€èƒ½,è®©å®ƒå¯ä»¥å¸®æˆ‘ä»¬åˆ†è¾¨åƒåœ¾çŸ­ä¿¡ã€‚æ˜¯ä¸æ˜¯å¾ˆç¥å¥‡å‘€?</p>
<h3 id="topic-overview-and-actualization-1">Topic Overview and Actualization</h3>
<p>Hello and welcome! In today&rsquo;s lesson, we dive into the world ofÂ <strong>Decision Trees</strong>Â in text classification. Decision Trees are simple yet powerful supervised learning algorithms used for classification and regression problems. In this lesson, our focus will be on understanding the Decision Tree algorithm and implementing it for a text classification problem. Let&rsquo;s get started!</p>
<h3 id="understanding-decision-trees-for-classification">Understanding Decision Trees for Classification</h3>
<p><strong>Decision Trees</strong>Â are a type of flowchart-like structure in which each internal node represents a feature, each branch represents a decision rule, and each leaf node represents an outcome or a class label. The topmost node in a Decision Tree is known as the root node, which best splits the dataset.</p>
<p>Splitting is a process of dividing a node into two or more sub-nodes, and a Decision Tree uses certain metrics during this training phase to find the best split. These includeÂ <strong>Entropy</strong>,Â <strong>Gini Index</strong>, andÂ <strong>Information Gain</strong>.</p>
<p>The advantage of Decision Trees is that they require relatively little effort for data preparation yet can handle both categorical and numeric data. They are visually intuitive and easy to interpret.</p>
<p>Let&rsquo;s see how this interprets to our spam detection problem.</p>
<h5 id="loading-and-preprocessing-the-data">Loading and Preprocessing the Data</h5>
<p>Before we dive into implementing Decision Trees, let&rsquo;s quickly load and preprocess our text dataset. This step will transform our dataset into a format that can be input into our machine learning models. This code block is being included for completeness:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import the necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> tree
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_dataset(<span style="color:#e6db74">&#39;codesignal/sms-spam-collection&#39;</span>, split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(spam_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define X (input features) and Y (output labels)</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;message&#34;</span>]
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;label&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform the train test split using stratified cross-validation</span>
</span></span><span style="display:flex;"><span>X_train, X_test, Y_train, Y_test <span style="color:#f92672">=</span> train_test_split(X, Y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, stratify<span style="color:#f92672">=</span>Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the CountVectorizer</span>
</span></span><span style="display:flex;"><span>count_vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit and transform the training data </span>
</span></span><span style="display:flex;"><span>X_train_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>fit_transform(X_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Transform the test data</span>
</span></span><span style="display:flex;"><span>X_test_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>transform(X_test)
</span></span></code></pre></div><p>With our data now prepared, let&rsquo;s move on to implementing Decision Trees using the Scikit-learn library.</p>
<h5 id="implementing-decision-trees-for-text-classification">Implementing Decision Trees for Text Classification</h5>
<p>In this section, we create our Decision Trees model using the Scikit-learn library:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Initialize the DecisionTreeClassifier model</span>
</span></span><span style="display:flex;"><span>decision_tree_model <span style="color:#f92672">=</span> tree<span style="color:#f92672">.</span>DecisionTreeClassifier()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit the model on the training data</span>
</span></span><span style="display:flex;"><span>decision_tree_model<span style="color:#f92672">.</span>fit(X_train_count, Y_train)
</span></span></code></pre></div><p>Here, we initialize the model using theÂ <code>DecisionTreeClassifier()</code>Â class and then fit it to our training data with theÂ <code>fit()</code>Â method.</p>
<h5 id="prediction-and-model-evaluation">Prediction and Model Evaluation</h5>
<p>After our model has been trained, it&rsquo;s time to make predictions on the test data and evaluate the model&rsquo;s performance:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Make predictions on the test data</span>
</span></span><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> decision_tree_model<span style="color:#f92672">.</span>predict(X_test_count)
</span></span></code></pre></div><p>Lastly, we calculate the accuracy score, which is the ratio of the number of correct predictions to the total number of predictions. The closer this number is to 1, the better our model:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Calculate the accuracy of the model</span>
</span></span><span style="display:flex;"><span>accuracy <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>accuracy_score(Y_test, y_pred)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the accuracy</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Accuracy of Decision Tree Classifier: </span><span style="color:#e6db74">{</span>accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>The output of the above code will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Accuracy of Decision Tree Classifier: <span style="color:#ae81ff">0.97</span>
</span></span></code></pre></div><p>This high accuracy score indicates that our Decision Tree model is performing exceptionally well in classifying messages as spam or not spam.</p>
<h5 id="lesson-summary-and-practice-1">Lesson Summary and Practice</h5>
<p>Great job! You&rsquo;ve learned the theory of Decision Trees, successfully applied it to a text classification problem, and evaluated the performance of your model. Understanding and mastering Decision Trees is an essential step in your journey to becoming skilled inÂ <strong>Natural Language Processing and Machine Learning</strong>.
To reinforce what we&rsquo;ve learned, the next step is to tackle some exercises that will give you hands-on experience with Decision Trees. This practical experience will reinforce your learning and deepen your understanding.</p>
<p>Looking forward to delving even deeper into natural language processing? Let&rsquo;s proceed to our next lesson:Â <strong>Random Forest for Text Classification</strong>. Happy Learning!</p>
<h2 id="practice1-3">ã€ŒPractice1ã€</h2>
<p>Great work! Now, let&rsquo;s adjust theÂ <code>max_depth</code>Â of our Decision Tree model and observe any potential changes in accuracy. Change the value of theÂ <code>max_depth</code>Â parameter inÂ <code>DecisionTreeClassifier</code>Â fromÂ <code>5</code>Â toÂ <code>10</code>. After adjusting your code, run it and compare the accuracy score to that of the original model. Good luck, Stellar Navigator!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> tree
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_dataset(<span style="color:#e6db74">&#39;codesignal/sms-spam-collection&#39;</span>, split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(spam_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define X (input features) and Y (output labels)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;message&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;label&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform the train test split using stratified cross-validation</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train, X_test, Y_train, Y_test <span style="color:#f92672">=</span> train_test_split(X, Y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, stratify<span style="color:#f92672">=</span>Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the CountVectorizer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>count_vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit and transform the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>fit_transform(X_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Transform the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_test_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>transform(X_test)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the DecisionTreeClassifier model with a max_depth parameter</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>decision_tree_model_v2 <span style="color:#f92672">=</span> tree<span style="color:#f92672">.</span>DecisionTreeClassifier(max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit the model on the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>decision_tree_model_v2<span style="color:#f92672">.</span>fit(X_train_count, Y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make predictions on the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y_pred_v2 <span style="color:#f92672">=</span> decision_tree_model_v2<span style="color:#f92672">.</span>predict(X_test_count)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate the accuracy of the model</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>accuracy_v2 <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>accuracy_score(Y_test, y_pred_v2)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the accuracy</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Accuracy of Decision Tree Classifier with max_depth=5: </span><span style="color:#e6db74">{</span>accuracy_v2<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Certainly! I&rsquo;ll adjust the <code>max_depth</code> parameter of the DecisionTreeClassifier from 5 to 10 and run the code to compare the accuracy scores. Here&rsquo;s the modified code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import necessary libraries</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> tree
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_dataset(<span style="color:#e6db74">&#39;codesignal/sms-spam-collection&#39;</span>, split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(spam_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define X (input features) and Y (output labels)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;message&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;label&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform the train test split using stratified cross-validation</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train, X_test, Y_train, Y_test <span style="color:#f92672">=</span> train_test_split(X, Y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, stratify<span style="color:#f92672">=</span>Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the CountVectorizer</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>count_vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit and transform the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>fit_transform(X_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Transform the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_test_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>transform(X_test)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the DecisionTreeClassifier model</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>decision_tree_model <span style="color:#f92672">=</span> ____(max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit the model on the training data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>____<span style="color:#f92672">.</span>fit(____, ____)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make predictions on the test data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> decision_tree_model<span style="color:#f92672">.</span>___(____)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate the accuracy of the model</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>accuracy <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>accuracy_score(Y_test, y_pred)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the accuracy</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Accuracy of Decision Tree Classifier: </span><span style="color:#e6db74">{</span>accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Now, let&rsquo;s run this code and compare the accuracy to the original model with <code>max_depth=5</code>. After running the code, we should see the accuracy score for the Decision Tree Classifier with <code>max_depth=10</code>. Let&rsquo;s compare this to the previous accuracy score: 1. Original model (max_depth=5): 0.96 (from the previous output) 2. New model (max_depth=10): [The new accuracy score will be displayed here] By increasing the <code>max_depth</code> from 5 to 10, we&rsquo;ve allowed the decision tree to create more complex decision boundaries. This can potentially lead to better accuracy on the training data, but it may also increase the risk of overfitting. If the new accuracy is higher, it suggests that the model benefited from the increased complexity and was able to capture more nuanced patterns in the data. However, if the accuracy is similar or lower, it might indicate that the additional depth didn&rsquo;t provide significant improvements or possibly led to overfitting. To further analyze the impact of changing the <code>max_depth</code>, you could consider: 1. Comparing the training accuracy to the test accuracy to check for overfitting. 2. Trying different <code>max_depth</code> values to find the optimal depth for this dataset. 3. Implementing cross-validation to get a more robust estimate of the model&rsquo;s performance. Remember, the goal is to find the right balance between model complexity and generalization ability. The optimal <code>max_depth</code> will depend on the specific characteristics of your dataset. Execution Error: ModuleNotFoundError Traceback (most recent call last) Cell In[3], line 6 4 from sklearn.feature_extraction.text import CountVectorizer 5 from sklearn.model_selection import train_test_split &mdash;-&gt; 6 import datasets 7 import pandas as pd 9 # Load the dataset ModuleNotFoundError: No module named &lsquo;datasets&rsquo;</p>
<p>å“¦,æˆ‘æ˜ç™½äº†ã€‚è®©æˆ‘ä»¬è¯•ç€ç”¨æ›´ç®€å•çš„æ–¹å¼æ¥è§£é‡Šè¿™ä¸ªæƒ…å†µ: æƒ³è±¡ä½ æœ‰ä¸€ä¸ªå¾ˆé…·çš„ç©å…·æœºå™¨äººã€‚è¿™ä¸ªæœºå™¨äººå¯ä»¥å­¦ä¹ åšä¸åŒçš„äº‹æƒ…,æ¯”å¦‚åˆ†è¾¨è‹¹æœå’Œæ©˜å­ã€‚ æœ‰æ—¶å€™,æˆ‘ä»¬æƒ³è®©æœºå™¨äººå˜å¾—æ›´èªæ˜ã€‚æ‰€ä»¥æˆ‘ä»¬ç»™å®ƒä¸€ä¸ªæ–°çš„&quot;å¤§è„‘&quot;ã€‚è¿™ä¸ªæ–°&quot;å¤§è„‘&quot;å¯ä»¥è®©æœºå™¨äººæ€è€ƒå¾—æ›´å¤šã€‚ ä½†æ˜¯,æœ‰è¶£çš„æ˜¯,è®©æœºå™¨äººæ€è€ƒæ›´å¤šå¹¶ä¸æ€»æ˜¯è®©å®ƒå˜å¾—æ›´èªæ˜ã€‚æœ‰æ—¶å€™,å®ƒå¯èƒ½ä¼šå˜å¾—æœ‰ç‚¹ç³Šæ¶‚,å› ä¸ºå®ƒæƒ³å¾—å¤ªå¤šäº†! å°±åƒä½ ç©æ¸¸æˆä¸€æ ·,æœ‰æ—¶å€™ç®€å•çš„è§„åˆ™åè€Œæ›´å®¹æ˜“èµ¢ã€‚æœºå™¨äººä¹Ÿæ˜¯è¿™æ ·,æœ‰æ—¶å€™ç®€å•ä¸€ç‚¹åè€Œèƒ½åšå¾—æ›´å¥½ã€‚ æ‰€ä»¥,æˆ‘ä»¬æ€»æ˜¯è¦è¯•è¯•çœ‹,åˆ°åº•æ˜¯è®©æœºå™¨äººæ€è€ƒå¤šä¸€ç‚¹å¥½,è¿˜æ˜¯æ€è€ƒå°‘ä¸€ç‚¹å¥½ã€‚è¿™å°±æ˜¯å¤§äººä»¬åœ¨åšçš„äº‹æƒ… - ä»–ä»¬åœ¨å¸®åŠ©æœºå™¨äººæ‰¾åˆ°æœ€å¥½çš„&quot;æ€è€ƒæ–¹å¼&quot;,è®©å®ƒå˜å¾—æ—¢èªæ˜åˆä¸ä¼šç³Šæ¶‚ã€‚ ä½ è§‰å¾—æ€ä¹ˆæ ·?è¿™æ ·è§£é‡Šæ˜¯ä¸æ˜¯æ›´å®¹æ˜“ç†è§£äº†å‘¢?</p>
<h1 id="lesson-4">lesson</h1>
<h5 id="introduction-to-the-random-forest-for-text-classification-lesson">Introduction to the Random Forest for Text Classification Lesson</h5>
<p>Welcome to the lesson onÂ <strong>Random Forest for Text Classification</strong>. As we continue our journey into the world of text classification techniques in Natural Language Processing (NLP), this lesson brings us to the powerful ensemble learning method - the Random Forest algorithm.</p>
<p>In this lesson, we will:</p>
<ul>
<li>Broaden our understanding of the Random Forest algorithm.</li>
<li>Apply it using Python&rsquo;s scikit-learn package, on the SMS Spam Collection dataset.</li>
<li>Evaluate our model&rsquo;s accuracy in classifying whether a text message is spam or not.</li>
</ul>
<p>By the end of this lesson, you will have gained hands-on experience in implementing a Random Forest classifier, equipping you with another versatile tool in your NLP modeling toolkit.</p>
<p>Let the learning begin!</p>
<h5 id="introduction-to-the-random-forest-for-text-classification-lesson-1">Introduction to the Random Forest for Text Classification Lesson</h5>
<p>Welcome to the lesson onÂ <strong>Random Forest for Text Classification</strong>. As we continue our journey into the world of text classification techniques in Natural Language Processing (NLP), this lesson brings us to the powerful ensemble learning method - the Random Forest algorithm.</p>
<p>In this lesson, we will:</p>
<ul>
<li>Broaden our understanding of the Random Forest algorithm.</li>
<li>Apply it using Python&rsquo;s scikit-learn package, on the SMS Spam Collection dataset.</li>
<li>Evaluate our model&rsquo;s accuracy in classifying whether a text message is spam or not.</li>
</ul>
<p>By the end of this lesson, you will have gained hands-on experience in implementing a Random Forest classifier, equipping you with another versatile tool in your NLP modeling toolkit.</p>
<p>Let the learning begin!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import the necessary libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.feature_extraction.text <span style="color:#f92672">import</span> CountVectorizer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> metrics
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestClassifier
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datasets
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Load the dataset</span>
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_dataset(<span style="color:#e6db74">&#39;codesignal/sms-spam-collection&#39;</span>, split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;train&#39;</span>)
</span></span><span style="display:flex;"><span>spam_dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(spam_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define X (input features) and Y (output labels)</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;message&#34;</span>]
</span></span><span style="display:flex;"><span>Y <span style="color:#f92672">=</span> spam_dataset[<span style="color:#e6db74">&#34;label&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform the train test split using stratified cross-validation</span>
</span></span><span style="display:flex;"><span>X_train, X_test, Y_train, Y_test <span style="color:#f92672">=</span> train_test_split(X, Y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>, stratify<span style="color:#f92672">=</span>Y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the CountVectorizer</span>
</span></span><span style="display:flex;"><span>count_vectorizer <span style="color:#f92672">=</span> CountVectorizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit and transform the training data </span>
</span></span><span style="display:flex;"><span>X_train_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>fit_transform(X_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Transform the test data</span>
</span></span><span style="display:flex;"><span>X_test_count <span style="color:#f92672">=</span> count_vectorizer<span style="color:#f92672">.</span>transform(X_test)
</span></span></code></pre></div><p>Remember, theÂ <code>CountVectorizer</code>Â transforms the text data into vectors of token occurrence counts (also known as bag of words), which is required for processing by machine learning models. We also use a stratified train-test split to ensure a balanced representation of different classes within both our training and test data.</p>
<h5 id="random-forest-classification-overview">Random Forest Classification: Overview</h5>
<p><strong>Random Forest</strong>Â is a type of ensemble learning method, where a group of weak models work together to form a stronger predictive model. A Random Forest operates by constructing numerous decision trees during training time and outputting the class that is the mode of the classes (classification) of the individual trees.</p>
<p>Random Forest has several advantages over a single decision tree. Most significant among these is that by building and averaging multiple deep decision trees trained on different parts of the same training data, the Random Forest algorithm reduces the problem of overfitting.</p>
<p>Random Forests also handle imbalanced data well, making them a good option for our text classification task.</p>
<h5 id="implementing-random-forest-classifier-with-scikit-learn">Implementing Random Forest Classifier with Scikit-learn</h5>
<p>Now that we have a basic understanding of the Random Forest algorithm, let&rsquo;s train our model.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Initialize the RandomForestClassifier model</span>
</span></span><span style="display:flex;"><span>random_forest_model <span style="color:#f92672">=</span> RandomForestClassifier(n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Fit the model on the training data</span>
</span></span><span style="display:flex;"><span>random_forest_model<span style="color:#f92672">.</span>fit(X_train_count, Y_train)
</span></span></code></pre></div><p>Here, the parameterÂ <code>n_estimators</code>Â defines the number of trees in the forest of the model whileÂ <code>random_state</code>Â sets a seed to the random generator, ensuring that the split you generate is replicable. The random forest model inherently handles multi-class tasks, hence we don&rsquo;t have to use the &lsquo;one-vs-all&rsquo; method to extend it to multi-class.
è¿™é‡Œï¼Œå‚æ•° n_estimators å®šä¹‰äº†æ¨¡å‹æ£®æ—ä¸­æ ‘çš„æ•°é‡ï¼Œè€Œ random_state ä¸ºéšæœºç”Ÿæˆå™¨è®¾ç½®äº†ä¸€ä¸ªç§å­ï¼Œç¡®ä¿ç”Ÿæˆçš„åˆ’åˆ†æ˜¯å¯å¤åˆ¶çš„ã€‚éšæœºæ£®æ—æ¨¡å‹æœ¬èº«å°±èƒ½å¤„ç†å¤šåˆ†ç±»ä»»åŠ¡ï¼Œå› æ­¤æˆ‘ä»¬ä¸å¿…ä½¿ç”¨â€œä¸€å¯¹å¤šâ€æ–¹æ³•å°†å…¶æ‰©å±•åˆ°å¤šåˆ†ç±»ã€‚</p>
<h5 id="evaluating-the-modelæ¨¡å‹è¯„ä¼°">Evaluating the ModelÂ æ¨¡å‹è¯„ä¼°</h5>
<p>Once our model is trained, we can use it to make predictions on our test data. By comparing these predictions against the actual labels in the test set, we can evaluate how well our model is performing. One of the most straightforward metrics we can use to achieve this is accuracy, calculated as the proportion of true results among the total number of cases examined.<br>
æ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒå¯¹æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚é€šè¿‡å°†è¿™äº›é¢„æµ‹ç»“æœä¸æµ‹è¯•é›†ä¸­å®é™…æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å¯ä»¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚å‡†ç¡®ç‡æ˜¯æœ€ç›´è§‚çš„è¯„ä¼°æŒ‡æ ‡ä¹‹ä¸€ï¼Œå®ƒæŒ‡çš„æ˜¯åœ¨æ‰€æœ‰æ ·æœ¬ä¸­é¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Make predictions on the test data</span>
</span></span><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> random_forest_model<span style="color:#f92672">.</span>predict(X_test_count)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Calculate the accuracy of the model</span>
</span></span><span style="display:flex;"><span>accuracy <span style="color:#f92672">=</span> metrics<span style="color:#f92672">.</span>accuracy_score(Y_test, y_pred)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print the accuracy</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Accuracy of Random Forest Classifier: </span><span style="color:#e6db74">{</span>accuracy<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>The output of the above code will be:<br>
ä»¥ä¸Šä»£ç çš„è¾“å‡ºç»“æœä¸ºï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Accuracy of Random Forest Classifier: <span style="color:#ae81ff">0.97</span>
</span></span></code></pre></div><p>This indicates that our Random Forest model was able to accurately classify 97% of the messages in the test set as spam or ham, showcasing a high level of performance.<br>
è¿™è¡¨æ˜æˆ‘ä»¬çš„éšæœºæ£®æ—æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®åœ°å°†æµ‹è¯•é›†ä¸­ 97% çš„æ¶ˆæ¯åˆ†ç±»ä¸ºåƒåœ¾é‚®ä»¶æˆ–éåƒåœ¾é‚®ä»¶ï¼Œå±•ç°å‡ºå¾ˆé«˜çš„æ€§èƒ½æ°´å¹³ã€‚</p>
<h5 id="lesson-summary-and-next-steps-1">Lesson Summary and Next Steps</h5>
<p>è¯¾ç¨‹æ€»ç»“å’Œåç»­æ­¥éª¤</p>
<p>We successfully explored the Random Forest algorithm, learned how it works, and implemented it in Python to classify messages as spam or ham. Remember, choosing and training a model is just part of the machine learning pipeline. Evaluating your model&rsquo;s performance, and selecting the best one, is also integral to any successfulÂ <strong>Machine Learning project</strong>.<br>
æˆ‘ä»¬æˆåŠŸæ¢ç´¢äº†éšæœºæ£®æ—ç®—æ³•ï¼Œå­¦ä¹ äº†å®ƒçš„å·¥ä½œåŸç†ï¼Œå¹¶åœ¨ Python ä¸­å®ç°äº†å®ƒï¼Œä»¥å°†æ¶ˆæ¯åˆ†ç±»ä¸ºåƒåœ¾é‚®ä»¶æˆ–éåƒåœ¾é‚®ä»¶ã€‚è¯·è®°ä½ï¼Œé€‰æ‹©å’Œè®­ç»ƒæ¨¡å‹åªæ˜¯æœºå™¨å­¦ä¹ æµç¨‹çš„ä¸€éƒ¨åˆ†ã€‚è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½å¹¶é€‰æ‹©æœ€ä½³æ¨¡å‹ä¹Ÿæ˜¯ä»»ä½•æˆåŠŸçš„æœºå™¨å­¦ä¹ é¡¹ç›®çš„ç»„æˆéƒ¨åˆ†ã€‚
In our upcoming exercises, you will get the opportunity to apply the concepts you&rsquo;ve learned and further familiarize yourself with the Random Forest algorithm. These tasks will help you solidify your understanding and ensure you are able to apply these techniques to your future data science projects. Happy learning!<br>
åœ¨æ¥ä¸‹æ¥çš„ç»ƒä¹ ä¸­ï¼Œæ‚¨å°†æœ‰æœºä¼šè¿ç”¨æ‰€å­¦æ¦‚å¿µï¼Œå¹¶è¿›ä¸€æ­¥ç†Ÿæ‚‰éšæœºæ£®æ—ç®—æ³•ã€‚è¿™äº›ä»»åŠ¡å°†å¸®åŠ©æ‚¨å·©å›ºç†è§£ï¼Œç¡®ä¿æ‚¨èƒ½å¤Ÿå°†è¿™äº›æŠ€æœ¯åº”ç”¨åˆ°æœªæ¥çš„æ•°æ®ç§‘å­¦é¡¹ç›®ä¸­ã€‚ç¥å­¦ä¹ æ„‰å¿«ï¼</p>

    </div>
</article>

    </main>

    <footer class="u-container u-py-xl u-text-center">
    <div class="u-mb-md">
        <span class="u-text-2xl">ğŸŒ±</span>
    </div>
    <p class="u-text-light">
        Â© 2025 Mengxi&#39;s Blog. Cultivated with intention.
    </p>
</footer>
</body>

</html>